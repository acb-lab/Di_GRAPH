#!/bin/bash

AUTHORS="Lydia Iglesias, Narciso M. Quijada, Andrés Clemente-Blanco"
LASTMODIF="2026-01-31"
VERSION="0.2.0"


DiGRAPH=$0
while [ -h "$DiGRAPH" ]; do # resolve $DiGRAPH until the file is no longer a symlink
  DiGRAPHDIR="$( cd -P "$( dirname "$0" )" && pwd )"
  DiGRAPH="$(readlink "$DiGRAPH")"
  [[ $DiGRAPH != /* ]] && DiGRAPH="$DiGRAPHDIR/$DiGRAPH" # if $DiGRAPH is a symlink, resolve it relative to the path where the symlink file was located
done
DiGRAPHDIR="$( cd -P "$( dirname "$DiGRAPH" )" && pwd )"

# WORKING VARIABLES
CATEGORY_PATH=
MYBLAST=
MYREF=
MYREPORT=
MYWD=
N_CPU=$(nproc)

current_time=
log_file=
stats=

#MYREF=/home/ibfg/GWSL/RG # Replace with the path to your MYREF directory: path/to/RG
#MYWD=/home/ibfg/GWSL/WD/ # Replace with the path to your MYWD directory: path/to/WD
#CATEGORY_PATH=/home/ibfg/GWSL/Categories # Replace with the path to your CATEGORY_PATH directory: path/to/Categories
#MYBLAST=/home/ibfg/GWSL/BLAST/features_extraction # Replace with the path to your MYBLAST directory: path/to/BLAST/features_extraction
#MYREPORT=/home/ibfg/GWSL/Report_files # Replace with the path to your MYREPORT directory: path/to/Report_files

# Message colors
COL_RESET=$(tput sgr 0)
COL_blue=$(tput setaf 4)
COL_cyan=$(tput setaf 6)
COL_green=$(tput setaf 2)
COL_magenta=$(tput setaf 5)
COL_purple=$(tput setaf 5)
COL_red=$(tput setaf 1)
COL_white=$(tput setaf 7)
COL_yellow=$(tput setaf 3)

usage () {

cat << EOF

=============================================================

██████╗               ██████╗ ██████╗  █████╗ ██████╗ ██╗  ██╗
██╔══██╗  ██╗        ██╔════╝ ██╔══██╗██╔══██╗██╔══██╗██║  ██║
██║  ██║  ╚═╝  ███╗  ██║  ███╗██████╔╝███████║██████╔╝███████║  
██║  ██║  ██╗  ╚══╝  ██║   ██║██╔╚██╗ ██╔══██║██╔═══╝ ██╔══██║  
██████╔╝  ██║        ╚██████╔╝██║ ╚██╗██║  ██║██║     ██║  ██║
╚═════╝   ╚═╝         ╚═════╝ ╚═╝  ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝  ╚═╝

      DSB-induced Genome-wide Repair Analysis 
     and Profiling of Homologous recombination
                   ${VERSION}
=============================================================

Description:
This tool performs genome-wide analysis of DNA repair following an HO-induced break. 
Di-GRAPH integrates:
  - MAT repair profiling
  - Genome instability evaluation based on coverage 
  - Recombination analysis based on inter-chromosomal discordant reads
Input files are gzipped paired-end fastq files.

OBLIGATORY OPTIONS:
    -b/--blast          Path to BLAST genomic database for cross-validation directory (provided in GitHub)
    -c/--categories     Path to genomic categories and features annotation directory (provided in GitHub)
    -g/--genome         Path to reference genome directory (provided in GitHub)
    -i/--input          Path to input directory (working directory generated by the user)
    -r/--report         Path to report directory (provided in GitHub)


OTHER OPTIONS:
    -h/--help           Shows this help
    -t/--threads        Number of threads to use (default=${N_CPU})
    -v/--version        Show version

EOF
}

if [ $# == 0 ]; then
	usage
	exit 1
fi

# VARIABLE OPTIONS

POSITIONAL=()
while [[ $# -gt 0 ]]
do
ARGS="$1"

case $ARGS in
    -b|--blast)
    if [ "$2" ]; then
        MYBLAST=$2
        shift 2
        if [ ! -d "${MYBLAST}" ]; then
            echo -e "\n${COL_red}ERROR: ${MYBLAST} doesn't exist!${COL_RESET} Please check \n"
            exit 1
        fi
        if [ ! "$(ls -A ${MYBLAST})" ]; then
            echo -e "\n${COL_red}ERROR: ${MYBLAST} is empty!${COL_RESET} Please check \n"
            exit 1
        fi
    else
        echo -e '\nERROR: "-b/--blast" requires an argument\n'
        exit 1
    fi
    ;;
    -c|--categories)
    if [ "$2" ]; then
        CATEGORY_PATH=$2
        shift 2
        if [ ! -d "${CATEGORY_PATH}" ]; then
            echo -e "\n${COL_red}ERROR: ${CATEGORY_PATH} doesn't exist!${COL_RESET} Please check \n"
            exit 1
        fi
        if [ ! "$(ls -A ${CATEGORY_PATH})" ]; then
            echo -e "\n${COL_red}ERROR: ${CATEGORY_PATH} is empty!${COL_RESET} Please check \n"
            exit 1
        fi
    else
        echo -e '\nERROR: "-c/--categories" requires an argument\n'
        exit 1
    fi
    ;;
    -i|--input)
    if [ "$2" ]; then
        MYWD=$2
        shift 2
        if [ ! -d "${MYWD}" ]; then
            echo -e "\n${COL_red}ERROR: ${MYWD} doesn't exist!${COL_RESET} Please check \n"
            exit 1
        fi
        if [ ! "$(ls -A ${MYWD})" ]; then
            echo -e "\n${COL_red}ERROR: ${MYWD} is empty!${COL_RESET} Please check \n"
            exit 1
        fi
    else
        echo -e '\nERROR: "-i/--input" requires an argument\n'
        exit 1
    fi
    ;;
    -g|--genome)
    if [ "$2" ]; then
        MYREF=$2
        shift 2
        if [ ! -d "${MYREF}" ]; then
            echo -e "\n${COL_red}ERROR: ${MYREF} doesn't exist!${COL_RESET} Please check \n"
            exit 1
        fi
        if [ ! "$(ls -A ${MYREF})" ]; then
            echo -e "\n${COL_red}ERROR: ${MYREF} is empty!${COL_RESET} Please check \n"
            exit 1
        fi
    else
        echo -e '\nERROR: "-g/--genome" requires an argument\n'
        exit 1
    fi
    ;;
    -r|--report)
    if [ "$2" ]; then
        MYREPORT=$2
        shift 2
        if [ ! -d "${MYREPORT}" ]; then
            echo -e "\n${COL_red}ERROR: ${MYREPORT} doesn't exist!${COL_RESET} Please check \n"
            exit 1
        fi
        if [ ! "$(ls -A ${MYREPORT})" ]; then
            echo -e "\n${COL_red}ERROR: ${MYREPORT} is empty!${COL_RESET} Please check \n"
            exit 1
        fi
    else
        echo -e '\nERROR: "-r/--report" requires an argument\n'
        exit 1
    fi
    ;;
    -t|--threads)
	if [ "$2" ]; then
		if [ "$2" -eq "$2"  ] 2>/dev/null ; then
            NCPUS=$2
            shift 2
        else
            echo -e '\nERROR: "-t/--threads" requires a numeric argument'
            echo -e "argument parsed: $2 \n"
            exit 1
        fi
	else
		echo -e '\nERROR: "-t/--threads" requires a numeric argument\n'
        exit 1
    fi
	;;
    -v|--version)
        echo "${COL_yellow}Di-GRAPH version ${VERSION}${COL_RESET}"
        exit 1
    ;;
    -h|--help)
	    usage
	    exit 1
	;;
    -?*)
	    usage
        echo -e "\n${COL_red}ERROR: unknown option: ${1}${COL_RESET}\n"
	    exit 1
	;;
	*)
	    usage
        echo -e "\n${COL_red}ERROR: unknown option: ${1}${COL_RESET}\n"
        exit 1
    ;;
esac
done
set -- "${POSITIONAL[@]}" #restore positional parameters

missing=0

for var in MYBLAST CATEGORY_PATH MYWD MYREF MYREPORT; do
    if [ -z "${!var}" ]; then
        echo -e "${COL_red}ERROR:${COL_RESET} Required option for $var is missing"
        missing=1
    fi
done

if [ "$missing" -eq 1 ]; then
    usage
    exit 1
fi


#################################

######## Replace the paths with the actual paths to the directories ########
# Create a log and stat file
current_time=$(date "+%d-%m-%Y %H:%M:%S")
log_file="${MYWD}/log_file.txt"
stats="${MYWD}/stats.txt"

echo "CONCORDANT ANALYSIS - initiated at: \"$current_time\"" > "$log_file"
echo "" >> "$log_file"  # Adds a blank line

echo "=========  Bowtie Alignment ==========" >> "$stats"

# Start timer for the entire script processing
start_time_total_script=$SECONDS

# Index RG
bowtie-build "${MYREF}/RG_PMV_v9.fasta" "${MYREF}/S_cerevisiae_indexed" #NMQ --> MOVE TO INSTALL!


###########################################
### COVERAGE AND POLYMORPHISMS ANALYSIS ###
###########################################

echo "Coverage and Polymorphisms Analysis - initiated at: \"$current_time\"" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line

# Start timers for Coverage and Polymorphism Analysis processing

start_time_total_cov=$SECONDS

# Loop through each directory inside MYWD
for subdir in "$MYWD"*/; do
  echo "Processing directory: $subdir" >> "$log_file"
  echo "" >> "$log_file"  # Adds a blank line

  # Loop through sample prefixes (T0, T1, T2, etc.)
    for sample in T0 TSG TLG TLR; do
      for experiment in E1 E2 E3; do
        file1_gz="${subdir}/${sample}_${experiment}_R1.fastq.gz"
        file2_gz="${subdir}/${sample}_${experiment}_R2.fastq.gz"
       
        # Check if both compressed files exist
        if [[ -f "$file1_gz" && -f "$file2_gz" ]]; then
          echo "Processing files: $file1_gz, $file2_gz" >> "$log_file"
          echo "" >> "$log_file"  # Adds a blank line

          # Decompress the current pair
          gunzip -k "$file1_gz" "$file2_gz"
          file1_path="${subdir}/${sample}_${experiment}_R1.fastq"
          file2_path="${subdir}/${sample}_${experiment}_R2.fastq"
          
          # Concatenate the two fastq files
          cat "$file1_path" "$file2_path" > "${subdir}/${sample}_${experiment}.fastq"
                
          # Remove original fastq files
          rm "$file1_path" "$file2_path"

          if [[ -f "${subdir}/${sample}_${experiment}.fastq" ]]; then
    
            # Trim reads using cutadapt
            cutadapt -j "$N_CPU" --cut -75 -o "${subdir}/${sample}_${experiment}_1.fastq" "${subdir}/${sample}_${experiment}.fastq"
            cutadapt -j "$N_CPU" --cut 75 -o "${subdir}/${sample}_${experiment}_2.fastq" "${subdir}/${sample}_${experiment}.fastq"
                    
            # Cut 38nt from the beginning and 38nt from the end
            cutadapt -j "$N_CPU" --cut -38 -o "${subdir}/${sample}_${experiment}_1_1.fastq" "${subdir}/${sample}_${experiment}_1.fastq"
            cutadapt -j "$N_CPU" --cut 38 -o "${subdir}/${sample}_${experiment}_1_2.fastq" "${subdir}/${sample}_${experiment}_1.fastq"
            cutadapt -j "$N_CPU" --cut -38 -o "${subdir}/${sample}_${experiment}_2_1.fastq" "${subdir}/${sample}_${experiment}_2.fastq"
            cutadapt -j "$N_CPU" --cut 38 -o "${subdir}/${sample}_${experiment}_2_2.fastq" "${subdir}/${sample}_${experiment}_2.fastq"
            
            # Cut 19nt from the beginning and 19nt from the end
            cutadapt -j "$N_CPU" --cut -19 -o "${subdir}/${sample}_${experiment}_18nts_1_1_1.fastq" "${subdir}/${sample}_${experiment}_1_1.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${subdir}/${sample}_${experiment}_18nts_1_1_2.fastq" "${subdir}/${sample}_${experiment}_1_1.fastq"
            cutadapt -j "$N_CPU" --cut -19 -o "${subdir}/${sample}_${experiment}_18nts_1_2_1.fastq" "${subdir}/${sample}_${experiment}_1_2.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${subdir}/${sample}_${experiment}_18nts_1_2_2.fastq" "${subdir}/${sample}_${experiment}_1_2.fastq"
            cutadapt -j "$N_CPU" --cut -19 -o "${subdir}/${sample}_${experiment}_18nts_2_1_1.fastq" "${subdir}/${sample}_${experiment}_2_1.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${subdir}/${sample}_${experiment}_18nts_2_1_2.fastq" "${subdir}/${sample}_${experiment}_2_1.fastq"
            cutadapt -j "$N_CPU" --cut -19 -o "${subdir}/${sample}_${experiment}_18nts_2_2_1.fastq" "${subdir}/${sample}_${experiment}_2_2.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${subdir}/${sample}_${experiment}_18nts_2_2_2.fastq" "${subdir}/${sample}_${experiment}_2_2.fastq"
            
            # Remove intermediate files
            rm "${subdir}/${sample}_${experiment}_1_1.fastq" "${subdir}/${sample}_${experiment}_1_2.fastq" "${subdir}/${sample}_${experiment}_2_1.fastq" "${subdir}/${sample}_${experiment}_2_2.fastq"
            
            # Catenate processed reads into a single fastq file
            cat "${subdir}/${sample}_${experiment}_18nts"*".fastq" > "${subdir}/${sample}_${experiment}_18nt_nonfiltered.fastq"
            
                # Filter 18nt reads Q30
                fastp \
                  -i "${subdir}/${sample}_${experiment}_18nt_nonfiltered.fastq" \
                  -o "${subdir}/${sample}_${experiment}_18nt.fastq" \
                  -q 30 -u 0 -e 30 \
                  --thread "$N_CPU" \
                  --html "${subdir}/${sample}_${experiment}_18nt.fastq.html" \
                  --json "${subdir}/${sample}_${experiment}_18nt.fastq.json" 
                rm "${subdir}/${sample}_${experiment}_18nt_nonfiltered.fastq" # Remove intermediate 18nt fastq files
            
            # Remove intermediate 18nt fastq files
            rm "${subdir}/${sample}_${experiment}_18nts"*".fastq"

            # Remove intermediate fastq files
            rm "${subdir}/${sample}_${experiment}.fastq"

            # Concatenate processed 75nt reads into a single fastq file
            cat "${subdir}/${sample}_${experiment}_1.fastq" \
                "${subdir}/${sample}_${experiment}_2.fastq" \
              > "${subdir}/${sample}_${experiment}_75nt_nonfiltered.fastq"
                    
                # Filter 75nt reads Q30
                fastp \
                  -i "${subdir}/${sample}_${experiment}_75nt_nonfiltered.fastq" \
                  -o "${subdir}/${sample}_${experiment}_75nt.fastq" \
                  -q 30 -u 0 -e 30 \
                  --thread "$N_CPU" \
                  --html "${subdir}/${sample}_${experiment}_75nt.fastq.html" \
                  --json "${subdir}/${sample}_${experiment}_75nt.fastq.json"
                rm "${subdir}/${sample}_${experiment}_75nt_nonfiltered.fastq" # Remove intermediate 75nt fastq files
                
            # Remove intermediate 75nt fastq files
            rm "${subdir}/${sample}_${experiment}_1.fastq" "${subdir}/${sample}_${experiment}_2.fastq"
            
            # Bowtie mapping
            echo "### $(basename "$subdir")/${sample}/${experiment} 75nt ###" >> "$stats"
            bowtie -p "$N_CPU" -m 1 -v 0 -S -x "${MYREF}/S_cerevisiae_indexed" "${subdir}/${sample}_${experiment}_75nt.fastq" > "${subdir}/${sample}_${experiment}_75nt.sam" 2>> "$stats"
            echo "" >> "$stats"
                    
            # Aligning using 18nt reads, in -k mode
            echo "### $(basename "$subdir")/${sample}/${experiment} 18nt ###" >> "$stats"
            bowtie -p "$N_CPU" -k 1 -v 0 -S -x "${MYREF}/S_cerevisiae_indexed" "${subdir}/${sample}_${experiment}_18nt.fastq" > "${subdir}/${sample}_${experiment}_18nt.sam" 2>> "$stats"
            echo "" >> "$stats"

            # Convert SAM to sorted BAM (75nt)
            samtools sort -@ "$N_CPU" -o "${subdir}/${sample}_${experiment}_75nt.bam" "${subdir}/${sample}_${experiment}_75nt.sam"
            samtools index "${subdir}/${sample}_${experiment}_75nt.bam" "${subdir}/${sample}_${experiment}_75nt.bai"
                    
            # Convert SAM to sorted BAM (18nt)
            samtools sort -@ "$N_CPU" -o "${subdir}/${sample}_${experiment}_18nt.bam" "${subdir}/${sample}_${experiment}_18nt.sam"
            samtools index "${subdir}/${sample}_${experiment}_18nt.bam" "${subdir}/${sample}_${experiment}_18nt.bai"
                    
            # Generate BedGraphs coverage files (75nt)
            bamCoverage -b "${subdir}/${sample}_${experiment}_75nt.bam" -o "${subdir}/${sample}_${experiment}_75nt.bedgraph" -of bedgraph -p "$N_CPU" -bs 1 --normalizeUsing RPGC --effectiveGenomeSize 14272230

            # Sorting Bedgraphs files (75nt)
            samtools faidx "${MYREF}/RG_PMV_v9.fasta" # Create index file
            cut -f1,2 "${MYREF}/RG_PMV_v9.fasta.fai" > "${MYREF}/chrom_order.txt"
            bedtools sort -i "${subdir}/${sample}_${experiment}_75nt.bedgraph" -g "${MYREF}/chrom_order.txt" > "${subdir}/${sample}_${experiment}_75nt_sorted.bedgraph"
                    
            # Generate BedGraphs coverage files (18nt)
            bamCoverage -b "${subdir}/${sample}_${experiment}_18nt.bam" -o "${subdir}/${sample}_${experiment}_CHRIII_18nt.bedgraph" -of bedgraph -p "$N_CPU" -bs 1 --normalizeUsing RPGC --effectiveGenomeSize 14272230 -r CHRIII:199953:201553
            bamCoverage -b "${subdir}/${sample}_${experiment}_18nt.bam" -o "${subdir}/${sample}_${experiment}_CHRV_18nt.bedgraph" -of bedgraph -p "$N_CPU" -bs 1 --normalizeUsing RPGC --effectiveGenomeSize 14272230 -r CHRV:289025:290625

            # Sorting Bedgraphs files (18nt)            
            bedtools sort -i "${subdir}/${sample}_${experiment}_CHRIII_18nt.bedgraph" -g "${MYREF}/chrom_order.txt" > "${subdir}/${sample}_${experiment}_CHRIII_18nt_sorted.bedgraph"
            bedtools sort -i "${subdir}/${sample}_${experiment}_CHRV_18nt.bedgraph" -g "${MYREF}/chrom_order.txt" > "${subdir}/${sample}_${experiment}_CHRV_18nt_sorted.bedgraph"

            # For TSG, TLG and TLR, generate BedGraphs coverage files (18nt) nonRPGC for quantifications
            if [[ "$sample" == "TSG" || "$sample" == "TLG" || "$sample" == "TLR" ]]; then
              bamCoverage -b "${subdir}/${sample}_${experiment}_18nt.bam" -o "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC.bedgraph" -of bedgraph -p "$N_CPU" -bs 1 --effectiveGenomeSize 14272230 -r CHRIII:199953:201553
              bamCoverage -b "${subdir}/${sample}_${experiment}_18nt.bam" -o "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC.bedgraph" -of bedgraph -p "$N_CPU" -bs 1 --effectiveGenomeSize 14272230 -r CHRV:289025:290625

              # Sorting Bedgraphs files (18nt_nonRPGC)
              bedtools sort -i "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC.bedgraph" -g "${MYREF}/chrom_order.txt" > "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC_sorted.bedgraph"
              bedtools sort -i "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC.bedgraph" -g "${MYREF}/chrom_order.txt"> "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC_sorted.bedgraph"
            fi

            # Generate TSV files (75nt)
            bedtools coverage -a "${subdir}/${sample}_${experiment}_75nt_sorted.bedgraph" -b "${subdir}/${sample}_${experiment}_75nt.bam" -sorted -g "${MYREF}/chrom_order.txt" -d > "${subdir}/${sample}_${experiment}_75nt.tsv"
            
            # Generate TSV files (18nt)
            bedtools coverage -a "${subdir}/${sample}_${experiment}_CHRIII_18nt_sorted.bedgraph" -b "${subdir}/${sample}_${experiment}_18nt.bam" -sorted -g "${MYREF}/chrom_order.txt" -d > "${subdir}/${sample}_${experiment}_CHRIII_18nt.tsv"
            bedtools coverage -a "${subdir}/${sample}_${experiment}_CHRV_18nt_sorted.bedgraph" -b "${subdir}/${sample}_${experiment}_18nt.bam" -sorted -g "${MYREF}/chrom_order.txt" -d > "${subdir}/${sample}_${experiment}_CHRV_18nt.tsv"

            # For TSG, TLG and TLR, generate TSV files (18nt) nonRPGC for quantifications
            if [[ "$sample" == "TSG" || "$sample" == "TLG" || "$sample" == "TLR" ]]; then
              bedtools coverage -a "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC_sorted.bedgraph" -b "${subdir}/${sample}_${experiment}_18nt.bam" -sorted -g "${MYREF}/chrom_order.txt" -d > "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC.tsv"
              bedtools coverage -a "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC_sorted.bedgraph" -b "${subdir}/${sample}_${experiment}_18nt.bam" -sorted -g "${MYREF}/chrom_order.txt" -d > "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC.tsv"
            fi
                    
            # Reduced decimals in coverage column (4th) (75nt) # Link this file for next blocks!!
            awk -F'\t' 'BEGIN{OFS=FS} {split($4,a,"."); if(length(a)>1) $4=a[1]"."substr(a[2],1,5); print}' "${subdir}/${sample}_${experiment}_75nt.tsv" > "${subdir}/${sample}_${experiment}_75nt.tmp" && mv "${subdir}/${sample}_${experiment}_75nt.tmp" "${subdir}/${sample}_${experiment}_75nt.tsv" # Linking file for next blocks!!!

            # Reduced decimals in coverage column (4th) (18nt)
            awk -F'\t' 'BEGIN{OFS=FS} {split($4,a,"."); if(length(a)>1) $4=a[1]"."substr(a[2],1,5); print}' "${subdir}/${sample}_${experiment}_CHRIII_18nt.tsv" > "${subdir}/${sample}_${experiment}_CHRIII_18nt.tmp" && mv "${subdir}/${sample}_${experiment}_CHRIII_18nt.tmp" "${subdir}/${sample}_${experiment}_CHRIII_18nt.tsv"
            awk -F'\t' 'BEGIN{OFS=FS} {split($4,a,"."); if(length(a)>1) $4=a[1]"."substr(a[2],1,5); print}' "${subdir}/${sample}_${experiment}_CHRV_18nt.tsv" > "${subdir}/${sample}_${experiment}_CHRV_18nt.tmp" && mv "${subdir}/${sample}_${experiment}_CHRV_18nt.tmp" "${subdir}/${sample}_${experiment}_CHRV_18nt.tsv"
            
            # For TSG, TLG and TLR reduced decimals in coverage column (4th) nonRPGC for quantifications
            if [[ "$sample" == "TSG" || "$sample" == "TLG" || "$sample" == "TLR" ]]; then
              awk -F'\t' 'BEGIN{OFS=FS} {split($4,a,"."); if(length(a)>1) $4=a[1]"."substr(a[2],1,5); print}' "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC.tsv" > "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC.tmp" && mv "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC.tmp" "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC.tsv"
              awk -F'\t' 'BEGIN{OFS=FS} {split($4,a,"."); if(length(a)>1) $4=a[1]"."substr(a[2],1,5); print}' "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC.tsv" > "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC.tmp" && mv "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC.tmp" "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC.tsv"
            fi

            # Extract CHRIII and CHRV, remove columnes 2, 3, 5, 6, and add coordinates to the last column (75nt)
            for chr in CHRIII CHRV; do
              awk -F'\t' -v chr="$chr" '$1 == chr {print $1, $4}' OFS='\t' "${subdir}/${sample}_${experiment}_75nt.tsv" | awk 'BEGIN {OFS="\t"} {print $0, NR}' > "${subdir}/${sample}_${experiment}_75nt_${chr}.tsv"
                        
              # Extract MATs
              if [[ $chr == "CHRIII" ]]; then
                awk -F'\t' '$3 >= 199953 && $3 <= 201553' "${subdir}/${sample}_${experiment}_75nt_CHRIII.tsv" > "${subdir}/${sample}_${experiment}_75nt_CHRIII_MATa.tsv"
              elif [[ $chr == "CHRV" ]]; then
                awk -F'\t' '$3 >= 289025 && $3 <= 290625' "${subdir}/${sample}_${experiment}_75nt_CHRV.tsv" > "${subdir}/${sample}_${experiment}_75nt_CHRV_MATa.tsv"
              fi
            done

            # Remove columnes 2, 3, 5, 6, and add coordinates to the last column (18nt)

            awk -F'\t' 'BEGIN {OFS="\t"} {coord=199953+NR-1; print $1, $4, coord}' "${subdir}/${sample}_${experiment}_CHRIII_18nt.tsv" > "${subdir}/${sample}_${experiment}_CHRIII_18nt_ordered.tsv"
            awk -F'\t' 'BEGIN {OFS="\t"} {coord=289025+NR-1; print $1, $4, coord}' "${subdir}/${sample}_${experiment}_CHRV_18nt.tsv" > "${subdir}/${sample}_${experiment}_CHRV_18nt_ordered.tsv"

            # For TSG, TLG and TLR, remove columnes 2, 3, 5, 6, and add coordinates to the last column (nonRPGC for quantifications)
            if [[ "$sample" == "TSG" || "$sample" == "TLG" || "$sample" == "TLR" ]]; then
              awk -F'\t' 'BEGIN {OFS="\t"} {coord=199953+NR-1; print $1, $4, coord}' "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC.tsv" > "${subdir}/${sample}_${experiment}_CHRIII_18nt_nonRPGC_ordered.tsv"
              awk -F'\t' 'BEGIN {OFS="\t"} {coord=289025+NR-1; print $1, $4, coord}' "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC.tsv" > "${subdir}/${sample}_${experiment}_CHRV_18nt_nonRPGC_ordered.tsv"
            fi
                    
            # Clean intermediate files
            rm "${subdir}/${sample}_${experiment}_75nt.fastq" "${subdir}/${sample}_${experiment}_75nt.bam" "${subdir}/${sample}_${experiment}_75nt.bai" "${subdir}/${sample}_${experiment}_75nt.sam"
            rm "${subdir}/${sample}_${experiment}_18nt.fastq" "${subdir}/${sample}_${experiment}_18nt.bam" "${subdir}/${sample}_${experiment}_18nt.bai" "${subdir}/${sample}_${experiment}_18nt.sam"

          else
          echo "Warning: Decompressed files missing for sample $sample in $subdir!" >> "$log_file"
          echo "" >> "$log_file"
          fi
        else
        echo "Warning: One or both compressed files for sample $sample are missing in $subdir!" >> "$log_file"
        echo "" >> "$log_file"
        fi
      done

      # === AFTER E1, E2 and E3 are processed ===
      for chr in CHRIII CHRV; do
        # Average general CHRIII and CHRV coverage (Only for 75nt reads)
        if [[ -f "${subdir}/${sample}_E1_75nt_${chr}.tsv" && -f "${subdir}/${sample}_E2_75nt_${chr}.tsv" && -f "${subdir}/${sample}_E3_75nt_${chr}.tsv" ]]; then
          LC_NUMERIC=C awk -F'\t' '
            FILENAME == ARGV[1] {
              a[FNR] = $2 + 0
              chr[FNR] = $1
              coord[FNR] = $3
              next
            }
            FILENAME == ARGV[2] {
              b[FNR] = $2 + 0
              next
            }
            FILENAME == ARGV[3] {
              c[FNR] = $2 + 0
              next
            }
            END {
              for (i = 1; i <= FNR; i++) {
                avg = (a[i] + b[i] + c[i]) / 3
                printf "%s\t%.5f\t%s\n", chr[i], avg, coord[i]
              }
            }
          ' "${subdir}/${sample}_E1_75nt_${chr}.tsv" \
            "${subdir}/${sample}_E2_75nt_${chr}.tsv" \
            "${subdir}/${sample}_E3_75nt_${chr}.tsv" \
          > "${subdir}/${sample}_75nt_${chr}_avg.tsv"

          # Add a column with the sample name
          numeric_sample="${sample#T}"
          awk -F'\t' -v sample="$numeric_sample" 'BEGIN{OFS="\t"} {print sample, $0}' "${subdir}/${sample}_75nt_${chr}_avg.tsv" > "${subdir}/${sample}_75nt_${chr}_avg_ordered.tsv"
          
          # Reorder columns to coordinate, time and coverage
          awk -F'\t' 'BEGIN{OFS="\t"} {print $4, $1, $3}' "${subdir}/${sample}_75nt_${chr}_avg_ordered.tsv" > "${subdir}/${sample}_75nt_${chr}_avg_ordered.tsv.tmp" && mv "${subdir}/${sample}_75nt_${chr}_avg_ordered.tsv.tmp" "${subdir}/${sample}_75nt_${chr}_avg_ordered.tsv"
        else
          echo "Warning: One or more ChrIII/V 75nt files for sample $sample are missing in $subdir!. Average ChrIII/V can not be calculated!" >> "$log_file"
          echo "" >> "$log_file"
        fi

        # Bin into 1000bp
        if [[ -f "${subdir}/${sample}_75nt_${chr}_avg_ordered.tsv" ]]; then
          input="${subdir}/${sample}_75nt_${chr}_avg_ordered.tsv"
          output="${subdir}/${sample}_75nt_${chr}_binned.tsv"
          bin_size=100

            gawk -v bin="$bin_size" '
            {
                # force floating point by adding 0.0
                cov_sum += ($3 + 0.0)
                last_coord = $1
                time = $2
                count++

                if (count == bin) {
                    avg_cov = cov_sum / bin
                    printf "%d\t%s\t%.5f\n", last_coord, time, avg_cov
                    cov_sum = 0
                    count = 0
                }
            }
            ' "$input" > "$output"
        else
          echo "Warning: ${subdir}/${sample}_75nt_${chr}_avg_ordered.tsv not found! Chr Binning cannot be created" >> "$log_file"
          echo "" >> "$log_file"
        fi

        # Average MATa coverage (75nt reads)
        if [[ -f "${subdir}/${sample}_E1_75nt_${chr}_MATa.tsv" && -f "${subdir}/${sample}_E2_75nt_${chr}_MATa.tsv" && -f "${subdir}/${sample}_E3_75nt_${chr}_MATa.tsv" ]]; then
          LC_NUMERIC=C awk -F'\t' '
            FILENAME == ARGV[1] {
              a[FNR] = $2 + 0
              chr[FNR] = $1
              coord[FNR] = $3
              next
            }
            FILENAME == ARGV[2] {
              b[FNR] = $2 + 0
              next
            }
            FILENAME == ARGV[3] {
              c[FNR] = $2 + 0
              next
            }
            END {
              for (i = 1; i <= FNR; i++) {
                avg = (a[i] + b[i] + c[i]) / 3
                printf "%s\t%.5f\t%s\n", chr[i], avg, coord[i]
              }
            }
          ' "${subdir}/${sample}_E1_75nt_${chr}_MATa.tsv" \
            "${subdir}/${sample}_E2_75nt_${chr}_MATa.tsv" \
            "${subdir}/${sample}_E3_75nt_${chr}_MATa.tsv" \
          > "${subdir}/${sample}_75nt_${chr}_MATa_avg.tsv"
        else
          echo "Warning: One or more ChrIII/V MATa 75nt files for sample $sample are missing in $subdir!. Averaged MATa can not be calculated!" >> "$log_file"
          echo "" >> "$log_file"
        fi

        # Add a column with the sample name (75nt reads)
        if [[ -f "${subdir}/${sample}_75nt_${chr}_MATa_avg.tsv" ]]; then
          awk -F'\t' -v sample="$numeric_sample" 'BEGIN{OFS="\t"} {print sample, $0}' "${subdir}/${sample}_75nt_${chr}_MATa_avg.tsv" > "${subdir}/${sample}_75nt_${chr}_MATa_avg_ordered.tsv"
        fi

        # Reorder columns to coordinate, time and coverage (75nt reads)
        if [[ -f "${subdir}/${sample}_75nt_${chr}_MATa_avg_ordered.tsv" ]]; then
          awk -F'\t' 'BEGIN{OFS="\t"} {print $4, $1, $3}' "${subdir}/${sample}_75nt_${chr}_MATa_avg_ordered.tsv" > "${subdir}/${sample}_75nt_${chr}_MATa_avg_ordered.tsv.tmp" && mv "${subdir}/${sample}_75nt_${chr}_MATa_avg_ordered.tsv.tmp" "${subdir}/${sample}_75nt_${chr}_MATa_avg_ordered.tsv"
        fi

      # Average MATa coverage (18nt reads)
      if [[ -f "${subdir}/${sample}_E1_${chr}_18nt_ordered.tsv" && -f "${subdir}/${sample}_E2_${chr}_18nt_ordered.tsv" && -f "${subdir}/${sample}_E3_${chr}_18nt_ordered.tsv" ]]; then
        LC_NUMERIC=C awk -F'\t' '
            FILENAME == ARGV[1] {
              a[FNR] = $2 + 0
              chr[FNR] = $1
              coord[FNR] = $3
              next
            }
            FILENAME == ARGV[2] {
              b[FNR] = $2 + 0
              next
            }
            FILENAME == ARGV[3] {
              c[FNR] = $2 + 0
              next
            }
            END {
              for (i = 1; i <= FNR; i++) {
                avg = (a[i] + b[i] + c[i]) / 3
                printf "%s\t%.5f\t%s\n", chr[i], avg, coord[i]
              }
            }
        ' "${subdir}/${sample}_E1_${chr}_18nt_ordered.tsv" \
          "${subdir}/${sample}_E2_${chr}_18nt_ordered.tsv" \
          "${subdir}/${sample}_E3_${chr}_18nt_ordered.tsv" \
        > "${subdir}/${sample}_${chr}_18nt_ordered_avg.tsv"
      else
        echo "Warning: One or more MATa $chr 18nt files for sample $sample are missing in $subdir!. Averaged MATa ${chr} 18nt can not be calculated!" >> "$log_file"
        echo "" >> "$log_file"
      fi
      
      # Add a column with the sample name (18nt reads)
      if [[ -f "${subdir}/${sample}_${chr}_18nt_ordered_avg.tsv" ]]; then
        awk -F'\t' -v sample="$numeric_sample" 'BEGIN{OFS="\t"} {print sample, $0}' "${subdir}/${sample}_${chr}_18nt_ordered_avg.tsv" > "${subdir}/${sample}_${chr}_18nt_ordered_avg_ordered.tsv"
      fi

      # Reorder columns to coordinate, timepoint, coverage and chromosome (18nt reads)
      if [[ -f "${subdir}/${sample}_${chr}_18nt_ordered_avg_ordered.tsv" ]]; then
        awk -F'\t' 'BEGIN{OFS="\t"} {print $4, $1, $3}' "${subdir}/${sample}_${chr}_18nt_ordered_avg_ordered.tsv" > "${subdir}/${chr}_MATa_${sample}_18nt_Coverage_nonHO.tsv"
        awk -v start=-800 '{printf "%d\t%s\t%s\n", start+(NR-1), $2, $3}' "${subdir}/${chr}_MATa_${sample}_18nt_Coverage_nonHO.tsv" > "${subdir}/${chr}_MATa_${sample}_18nt_Coverage_nonCHR.tsv"
        awk -v chr="$chr" 'BEGIN {OFS="\t"} {print $0, chr}' "${subdir}/${chr}_MATa_${sample}_18nt_Coverage_nonCHR.tsv" > "${subdir}/${chr}_MATa_${sample}_18nt_Coverage.tsv"
      fi
      done
    done
done

# Concatenate all average ordered TSVs (75nt)
for subdir in "${MYWD}"*/; do
  # Concatenate all binned CHRIII/CHRV TSVs
    for chr in CHRIII CHRV; do
        output_file="${subdir}/75nt_${chr}_Coverage.tsv"
        true > "$output_file"

        for sample in T0 TSG TLG TLR; do
            input_file="${subdir}/${sample}_75nt_${chr}_binned.tsv"
            if [[ -f "$input_file" ]]; then
                cat "$input_file" >> "$output_file"
            else
                echo "Warning: ${input_file} not found! Catenation of binned CHRIII/V failed" >> "$log_file"
                echo "" >> "$log_file"
            fi
        done
    done

    # Concatenate all MATs TSVs (75nt)
    for chr in CHRIII CHRV; do
        output_file="${subdir}/75nt_${chr}_MATa_Coverage.tsv"
        true > "$output_file"

        for sample in T0 TSG TLG TLR; do
            input_file="${subdir}/${sample}_75nt_${chr}_MATa_avg_ordered.tsv"
            if [[ -f "$input_file" ]]; then
                cat "$input_file" >> "$output_file"
            else
                echo "Warning: ${input_file} not found! Catenation of MATs failed" >> "$log_file"
                echo "" >> "$log_file"
            fi
        done
    done
done

# === R CODE GRAPHS FOR 75nt COVERAGE PROFILE AND FOR 18nt POLYMORPHISMS COVERAGE ===

# Generate 75nt plots for CHRIII/V and MATs
for subdir in "${MYWD}"*/; do
  for chr in CHRIII CHRV; do
    for suffix in "Coverage.tsv" "MATa_Coverage.tsv"; do
      file="${subdir}/75nt_${chr}_${suffix}"
      if [[ -f "$file" ]]; then
        echo "Generating graph for $file" 
        FILE="$file" CHR="$chr" SUFFIX="$suffix" SUBDIR="$subdir" Rscript - <<'EOF'
          library(ggplot2)
          library(extrafont)
          library(dplyr)

          file_path <- Sys.getenv("FILE")
          chr_name <- Sys.getenv("CHR")
          suffix <- Sys.getenv("SUFFIX")
          subdir <- Sys.getenv("SUBDIR")

          title_text <- paste("Normalized 75nt", chr_name, suffix)
          output_name <- paste0(subdir, "/plot_", chr_name, "_75nt_", gsub("\\.tsv$", "", suffix), ".svg")

          data <- read.table(file_path, header = FALSE)
          colnames(data) <- c("Position", "Timepoint", "Coverage")

          data <- data %>%
            mutate(
              Timepoint = factor(Timepoint, levels = rev(c("0", "SG", "LG", "LR"))),
              Coverage = as.numeric(Coverage)
            )

          t0_values <- data %>%
            filter(Timepoint == "0") %>%
            select(Position, T0_Coverage = Coverage)

          data_normalized <- data %>%
            left_join(t0_values, by = "Position") %>%
            mutate(
              Normalized_Coverage = ifelse(T0_Coverage == 0, NA, Coverage / T0_Coverage)
            )

          p1 <- ggplot(
            data_normalized,
            aes(x = Position, y = Timepoint, fill = Normalized_Coverage)
          ) +
            geom_raster() +
            scale_fill_gradientn(
              colors = rev(c("#AF2418", "#E1AC40", "#EFD24D", "#5D8B27", "#4EACE9", "#4573A1", "#4C1F8E")),
              values = scales::rescale(c(0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2)),
              na.value = "gray90",
              name = "Normalized Coverage",
              limits = c(0, 2),
              oob = scales::squish
            ) +
            scale_x_continuous(labels = scales::comma) +
            labs(
              title = title_text,
              x = "Genomic Position",
              y = "Timepoint"
            ) +
            theme_minimal() +
            theme(
              legend.position = "right",
              plot.title = element_text(hjust = 0.5),
              panel.grid = element_line(color ="Black", linewidth =0,1),
              panel.background = element_blank(),
              plot.background = element_rect(fill = "transparent", color = NA),
            )

          ggsave(output_name, plot = p1, width = 10, height = 6, dpi = 300, device = "svg")
EOF
      fi
    done
  done
done

# Generate 18nt plots for T0 and TLG with both chromosomes
for subdir in "${MYWD}"*/; do
  for timepoint in T0 TSG TLG TLR; do
    file_chrIII="${subdir}/CHRIII_MATa_${timepoint}_18nt_Coverage.tsv"
    file_chrV="${subdir}/CHRV_MATa_${timepoint}_18nt_Coverage.tsv"

    if [[ -f "$file_chrIII" && -f "$file_chrV" ]]; then
      echo "Generating spaghetti plot for $timepoint in $subdir"

      Rscript - <<EOF
        # Load necessary libraries
        library(ggplot2)
        library(extrafont)
        library(dplyr)

        # Assign file paths from the bash variables
        file_chrIII <- "$file_chrIII"
        file_chrV <- "$file_chrV"
        timepoint <- "$timepoint"  # Pass the timepoint variable to R

        # Read the dataset for chrIII and chrV
        data_chrIII <- read.table(file_chrIII, header=FALSE, col.names=c("Coordinate", "Timepoint", "Coverage", "Chromosome"))
        data_chrV <- read.table(file_chrV, header=FALSE, col.names=c("Coordinate", "Timepoint", "Coverage", "Chromosome"))

        # Combine the two datasets into one
        all_data <- rbind(data_chrIII, data_chrV)

        # Check if the necessary columns exist
        if (!all(c("Coordinate", "Timepoint", "Coverage", "Chromosome") %in% colnames(all_data))) {
          stop("Error: Required columns are missing in the combined data")
        }

        # Plot the data using ggplot
        p2 <- ggplot(all_data, aes(x=Coordinate, y=Coverage, color=Chromosome)) +
          geom_line(linewidth=0.8) +
          labs(
            title=paste("Coverage of ChrIII and ChrV - Timepoint", timepoint),
            x="Coordinate (relative to MAT locus)",
            y="Coverage"
          ) +
          theme_minimal() +
          theme(
            plot.title = element_text(hjust=0.5),  # Center the title
            legend.position="right",  # Position the legend
            panel.grid = element_line(color ="Black", linewidth =0,1),
            panel.background = element_blank(),
            plot.background = element_rect(fill = "transparent", color = NA),
          ) +
          scale_color_manual(values=c("CHRIII"="#2F2C7E", "CHRV"="#A30000")) +  # Color for each chromosome
          coord_cartesian(ylim=c(0, 3))  # Optional: Set y-axis limits
          scale_x_continuous(breaks=seq(-800, 800, by=200))  # Set x-axis breaks to be at intervals of 200

        # Define the output file path
        output_name <- file.path("$subdir", paste0("plot_", timepoint, "_18nt_MATa_Coverage.svg"))

        # Save the plot
        ggsave(output_name, plot=p2, width=10, height=6, dpi=300, device="svg")
EOF
    else
      echo "Missing files for $timepoint in $subdir"
    fi
  done
done

### === DATA ORGANIZATION ===

#Crate folder for the Alignment output files
for subdir in "${MYWD}"*/; do
    mkdir -p "${subdir}/Alignment_data"
    mv "${subdir}"/*.bedgraph "${subdir}/Alignment_data/"
done

# Create a folder for the Coverage TSV files
for subdir in "${MYWD}"*/; do
    mkdir -p "${subdir}/Coverage_data"
    mv "${subdir}"/*_Coverage.tsv "${subdir}/Coverage_data/"
done

for subdir in "${MYWD}"*/; do
    mkdir -p "${subdir}/MATs_quant_data"
    for chr in CHRIII CHRV; do
        mv "${subdir}"/*_"${chr}"_18nt_nonRPGC_ordered.tsv "${subdir}/MATs_quant_data/"
    done
done

# Create a folder for the graphs
for subdir in "$MYWD"*/; do
  mkdir -p "${subdir}/Graphs_Coverage"
  mv "${subdir}/plot_"*".svg" "${subdir}/Graphs_Coverage/"
done

# Create a folder for FASTQP files
for subdir in "$MYWD"*/; do
  mkdir -p "${subdir}/FASTQP"
  mv "${subdir}"/*.fastq.html "${subdir}/FASTQP/"
  mv "${subdir}"/*.fastq.json "${subdir}/FASTQP/"
done

# Remove index files
find "$MYREF" -name "*.ebwt" -exec rm {} +
find "$MYREF" -name "*.fai" -exec rm {} +
find "$MYREF" -name "*.txt" -exec rm {} +

# Delete all TSV files in subdir, excluding those in Alignment_data
for subdir in "${MYWD}"*; do
    find "${subdir}" -maxdepth 1 -type f -name "*.tsv" ! -name "*_75nt.tsv" -exec rm {} \;
done

### === MATs quantification for TSG, TLG and TLR ===
# This section calculates the difference in coverage for polymorphism between CHRIII and CHRV

# Coordinates (you can add more coordinates separated by space)
coordinates_CHRIII=(200119 200167 200212 200272 200326 200386 200449 200509 200542 200575 200635 200689 200753 200817 200882 200947 201012 201077 201148 201207 201272 201337 201402)
coordinates_CHRV=(289191 289239 289284 289344 289398 289458 289521 289581 289614 289647 289707 289761 289825 289889 289954 290019 290084 290149 290220 290279 290344 290409 290474)

offset=19 

for subdir in "$MYWD"*/MATs_quant_data/; do
  for sample in TSG TLG TLR; do
    for exp in E1 E2 E3; do
      input_file_CHRIII="${subdir}/${sample}_${exp}_CHRIII_18nt_nonRPGC_ordered.tsv"
      input_file_CHRV="${subdir}/${sample}_${exp}_CHRV_18nt_nonRPGC_ordered.tsv"

      if [[ -f "$input_file_CHRIII" && -f "$input_file_CHRV" ]]; then
        echo "Processing files in $subdir for $sample _ $exp..."

        # Loop through CHRIII coordinates
        for coordinate_CHRIII in "${coordinates_CHRIII[@]}"; do
          line_number_CHRIII=$(awk -v coord="$coordinate_CHRIII" '$3 == coord {print NR}' "$input_file_CHRIII")

          if [[ -n "$line_number_CHRIII" ]]; then
            top_line_CHRIII=$((line_number_CHRIII - offset))
            bottom_line_CHRIII=$((line_number_CHRIII + offset))
            [[ "$top_line_CHRIII" -lt 1 ]] && top_line_CHRIII=1

            top_line_content=$(sed -n "${top_line_CHRIII}p" "$input_file_CHRIII")
            mid_line_content=$(sed -n "${line_number_CHRIII}p" "$input_file_CHRIII")
            bottom_line_content=$(sed -n "${bottom_line_CHRIII}p" "$input_file_CHRIII")

            top_coverage=$(echo "$top_line_content" | awk '{print $2}')
            bottom_coverage=$(echo "$bottom_line_content" | awk '{print $2}')
            baseline_coverage=$(awk -v top="$top_coverage" -v bottom="$bottom_coverage" 'BEGIN {print top + (bottom - top)/2}')

            # Extract fields from mid_line_content
            mid_chr=$(echo "$mid_line_content" | awk '{print $1}')
            mid_coverage=$(echo "$mid_line_content" | awk '{print $2}')
            mid_coordinate=$(echo "$mid_line_content" | awk '{print $3}')

            # Calculate coverage difference (mid - baseline)
            coverage_diff=$(awk -v mid="$mid_coverage" -v base="$baseline_coverage" 'BEGIN {print mid - base}')

            # Build new line with: original chr, diff coverage, and coordinate (tab-separated)
            diff_line=$(echo -e "$mid_chr\t$coverage_diff\t$mid_coordinate")

            echo "CHRIII Coord: $coordinate_CHRIII — Coverage Diff: $coverage_diff"

            output_file_CHRIII="${subdir}/${sample}_${exp}_CHRIII_diff_${coordinate_CHRIII}.tsv"
            {
              echo "$diff_line"
            } > "$output_file_CHRIII"

          else
          echo "Coordinate $coordinate_CHRIII not found in $input_file_CHRIII for $sample $exp."
          fi
        done
    
        # Loop through CHRV coordinates
        for coordinate_CHRV in "${coordinates_CHRV[@]}"; do
          line_number_CHRV=$(awk -v coord="$coordinate_CHRV" '$3 == coord {print NR}' "$input_file_CHRV")

          if [[ -n "$line_number_CHRV" ]]; then
            top_line_CHRV=$((line_number_CHRV - offset))
            bottom_line_CHRV=$((line_number_CHRV + offset))
            [[ "$top_line_CHRV" -lt 1 ]] && top_line_CHRV=1

            top_line_content=$(sed -n "${top_line_CHRV}p" "$input_file_CHRV")
            mid_line_content=$(sed -n "${line_number_CHRV}p" "$input_file_CHRV")
            bottom_line_content=$(sed -n "${bottom_line_CHRV}p" "$input_file_CHRV")

            top_coverage=$(echo "$top_line_content" | awk '{print $2}')
            bottom_coverage=$(echo "$bottom_line_content" | awk '{print $2}')
            baseline_coverage=$(awk -v top="$top_coverage" -v bottom="$bottom_coverage" 'BEGIN {print top + (bottom - top)/2}')

            # Extract fields from mid_line_content
            mid_chr=$(echo "$mid_line_content" | awk '{print $1}')
            mid_coverage=$(echo "$mid_line_content" | awk '{print $2}')
            mid_coordinate=$(echo "$mid_line_content" | awk '{print $3}')

            # Calculate coverage difference (mid - baseline)
            coverage_diff=$(awk -v mid="$mid_coverage" -v base="$baseline_coverage" 'BEGIN {print mid - base}')

            # Build new line with: original chr, diff coverage, and coordinate (tab-separated)
            diff_line=$(echo -e "$mid_chr\t$coverage_diff\t$mid_coordinate")

            echo "CHRV Coord: $coordinate_CHRV — Coverage Diff: $coverage_diff"

            output_file_CHRV="${subdir}/${sample}_${exp}_CHRV_diff_${coordinate_CHRV}.tsv"
            {
              echo "$diff_line"
            } > "$output_file_CHRV"

          else
          echo "Coordinate $coordinate_CHRV not found in $input_file_CHRV for $sample $exp."
          fi
        done
      else
      echo "Files not found for $sample $exp in $subdir"
      fi
    done
  done
done

# Combine all the diff files into one for each experiment and chromosome
for subdir in "$MYWD"*/MATs_quant_data/; do
  for sample in TSG TLG TLR; do
    for exp in E1 E2 E3; do
      for chr in CHRIII CHRV; do
        cat "${subdir}/${sample}_${exp}_${chr}_diff_"*.tsv > "${subdir}/${sample}_${exp}_${chr}_diff_allPoly.tsv" 
      done
    done
  done
done

# Average E1, E2 and E3 files into one for each chromosome
for subdir in "$MYWD"*/MATs_quant_data/; do
  for sample in TSG TLG TLR; do
    for chr in CHRIII CHRV; do
      file1="${subdir}/${sample}_E1_${chr}_diff_allPoly.tsv"
      file2="${subdir}/${sample}_E2_${chr}_diff_allPoly.tsv"
      file3="${subdir}/${sample}_E3_${chr}_diff_allPoly.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" ]]; then
        paste "$file1" "$file2" "$file3" | awk '{
          chr=$1
          coord=$3
          cov1=$2
          cov2=$5
          cov3=$8
          avg_cov = (cov1 + cov2 + cov3) / 3
          std_dev = sqrt(((cov1 - avg_cov)^2 + (cov2 - avg_cov)^2 + (cov3 - avg_cov)^2) / 3)
          printf "%s\t%.2f\t%.2f\t%s\n", chr, avg_cov, std_dev, coord
        }' > "${subdir}/${sample}_${chr}_averaged_diff_allPoly.tsv"
      else
        echo "Files not found for $sample $chr in $subdir"
      fi
    done
  done
done

# Clean up intermediate files
for subdir in "$MYWD"/*/MATs_quant_data/; do
  for sample in TSG TLG TLR; do
    for exp in E1 E2 E3; do
      for chr in CHRIII CHRV; do
        rm "${subdir}/${sample}_${exp}_${chr}_diff_"*.tsv
        rm "${subdir}/${sample}_${exp}_${chr}_18nt_nonRPGC_ordered.tsv"
      done
    done
  done
done

# Substitute absolute coordinates for relative to HO coordinates
    # Relative coordinates
    rel_coords=(-634 -586 -541 -481 -427 -367 -304 -244 -211 -178 -118 -64 0 64 129 194 259 324 395 454 519 584 649)

for subdir in "$MYWD"*/MATs_quant_data/; do
  for sample in TSG TLG TLR; do
    for chr in CHRIII CHRV; do
      input_file="${subdir}/${sample}_${chr}_averaged_diff_allPoly.tsv"
      output_file="${subdir}/${sample}_${chr}_averaged_diff_allPoly_newCoor.tsv"

      # Loop through the file and the array together
      awk -v coords="${rel_coords[*]}" '
        BEGIN {
          split(coords, rel_arr, " ")
        }
        {
          print $1, $2, $3, rel_arr[NR]
        }
      ' OFS="\t" "$input_file" > "$output_file"
      rm "$input_file"
    done
  done
done

# Catenate CHRIII and CHRV files from all subdirectories
for subdir in "$MYWD"*/MATs_quant_data/; do
  for sample in TSG TLG TLR; do
    if [[ -f "${subdir}/${sample}_CHRIII_averaged_diff_allPoly_newCoor.tsv" && -f "${subdir}/${sample}_CHRV_averaged_diff_allPoly_newCoor.tsv" ]]; then
      # Ensure the output file is saved in the correct MATs_quant_data folder
      cat "${subdir}/${sample}_CHRIII_averaged_diff_allPoly_newCoor.tsv" "${subdir}/${sample}_CHRV_averaged_diff_allPoly_newCoor.tsv" > "${subdir}/${sample}_Final_Dataset.tsv"
      sed 's/,/./g' "${subdir}/${sample}_Final_Dataset.tsv" > "${subdir}/${sample}_Cleaned_Final_Dataset.tsv"
      rm "${subdir}/${sample}_CHRIII_averaged_diff_allPoly_newCoor.tsv" "${subdir}/${sample}_CHRV_averaged_diff_allPoly_newCoor.tsv" "${subdir}/${sample}_Final_Dataset.tsv"
    else
      echo "Warning: Missing files in $subdir for $sample"
    fi
  done
done

#### R CODE ####

for subdir in "$MYWD"*/MATs_quant_data/; do
  for sample in TSG TLG TLR; do
Rscript - <<EOF
  library(ggplot2)
  library(extrafont)
  library(dplyr)

  # Load your data
  data <- read.table(header=FALSE, sep="\t", file="${subdir}/${sample}_Cleaned_Final_Dataset.tsv")

  # Name the columns
  colnames(data) <- c("Chromosome", "Coverage", "StdDev", "Coordinate")

  # Ensure Coordinate is numeric
  data\$Coordinate <- as.numeric(as.character(data\$Coordinate))

  # Plot
  p3 <- ggplot(data, aes(x=Coordinate, y=Coverage, color=Chromosome, fill=Chromosome)) +
    geom_ribbon(aes(ymin=Coverage - StdDev, ymax=Coverage + StdDev),
                alpha=0.2, color=NA) +
    geom_line(size=1.2) +
    scale_x_continuous(breaks=unique(data\$Coordinate)) +  # Only show x-ticks for coordinates in column 4
    scale_y_continuous(limits = c(-125, 125)) +
    scale_color_manual(values = c("CHRIII" = "#2F2C7E", "CHRV" = "#A30000")) +
    scale_fill_manual(values = c("CHRIII" = "#2F2C7E", "CHRV" = "#A30000")) +
    labs(
        title=paste("Quant_Coverage of ChrIII and ChrV polymorphisms - ${sample}"),
        x="Relative Coordinate (bp)",
        y="Average Coverage") +
    theme(
      axis.text.x = element_text(angle=90, vjust=0.5, hjust=1),
      panel.grid.minor.x = element_blank(),  # Remove vertical minor grid lines
      panel.grid.major.y = element_line(color = "gray", size = 0.5),  # Keep horizontal grid lines
      panel.grid = element_line(color ="Black", linewidth =0,1),
      panel.background = element_blank(),
      plot.background = element_rect(fill = "transparent", color = NA),
    )

  # Save plot
  ggsave(filename="${subdir}/plot_${sample}_18nt_MATa_Coverage_Quant.svg", plot=p3, width=10, height=6, dpi=300, device="svg")

EOF
  done
done

# Move the plots to the Graphs_Coverage folder
for subdir in "$MYWD"*/; do
  for sample in TSG TLG TLR; do
    mv "${subdir}/MATs_quant_data/plot_${sample}_18nt_MATa_Coverage_Quant.svg" "${subdir}/Graphs_Coverage/"
  done
done

# Calulate total elapsed time
elapsed_time_total_cov=$((( SECONDS - start_time_total_cov )/60))
echo "Coverage and Polymorphisms Analysis completed in ${elapsed_time_total_cov} minutes" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line            


###########################################
####### GENOMIC CATEGORIES ANALYSIS #######
###########################################

current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Genomic Categories Analysis - initiated at: \"$current_time\"" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line 

# Start timer for the R category analysis
start_time_total_cat=$SECONDS

# Loop through each directory inside MYWD
for subdir in "$MYWD"*/; do
  echo "Processing R analysis: $subdir"
  strain=$(basename "$subdir") # Extract the strain name
  subdir_escaped="${subdir%/}" # Remove trailing slash
    for time in T0 TSG TLG TLR; do
        for category in ORF LTR TEG Ty tRNA rRNA ncRNA snRNA snoRNA ARS Cen Tel Int; do
            echo "Processing category: $category"

            shopt -s nullglob
            category_files=("$CATEGORY_PATH"/*.PMV."$category".tsv)
            shopt -u nullglob

            if [ ${#category_files[@]} -eq 0 ]; then
            echo "No files found for category $category, skipping."
            continue
            fi

            for category_file in "${category_files[@]}"; do
              if [ "$time" == "T0" ]; then
                echo "Skippint T0 vs T0 comparison"
                continue
              fi
            echo "Running Rscript on $category for $time in $strain"
        
      Rscript - <<EOF

# Load packages
library(tidyverse)

# Variables from Bash
cepa <- "${strain}"
category <- "${category}"
category_file <- "${category_file}"
subdir <- "${subdir_escaped}"
time <- "${time}"

# File paths
plot_path <- file.path(subdir, paste0(cepa, "_", category, "_T0vs", time,"_plot.svg"))
tsv_path <- file.path(subdir, paste0(category, "_fingerprint_", cepa, "_T0vs", time,".tsv"))
#all_data_path <- file.path(subdir, paste0(category, "_all_data_", cepa, "_T0vs", time, ".tsv")) only to check raw data

# Chromosome positions
chr_positions <- list(
  CHRI = 1:230218, CHRII = 1:813184, CHRIII = 1:316513,
  CHRIV = 1:1531933, CHRV = 1:578179, CHRVI = 1:270161,
  CHRVII = 1:1090940, CHRVIII = 1:562643, CHRIX = 1:439888,
  CHRX = 1:745751, CHRXI = 1:666816, CHRXII = 1:1078177,
  CHRXIII = 1:924431, CHRXIV = 1:784333, CHRXV = 1:1091291,
  CHRXVI = 1:948066
)

# Read category regions
df_categorias <- read_tsv(category_file, col_names = FALSE,
  col_types = cols(X1 = col_character(), X2 = col_character(),
                   X3 = col_double(), X4 = col_double(), X5 = col_character())) %>%
  rename(Tipo = X1, Categoria = X2, Pos_inicio = X3, Pos_fin = X4, Cromosoma = X5) %>%
  mutate(Categoria = as.factor(Categoria))

# Function to process each experiment
process_experiment <- function(exp_num, time) {
  data_file <- file.path(subdir, paste0(time, "_", "E", exp_num, "_75nt.tsv"))
  df <- read_tsv(data_file, col_names = FALSE, col_types = cols_only(X1 = col_character(), X4 = col_double()))

  df_full <- tibble(
    Cepa = cepa,
    Experimento = exp_num,
    Tiempo = time,
    Cromosoma = df\$X1,
    Valor_real = df\$X4
  )

  map_dfr(names(chr_positions), function(chr) {
    chr_df <- df_full %>% filter(Cromosoma == chr) %>%
      mutate(Posicion = chr_positions[[chr]])

    cat_df <- df_categorias %>% filter(Cromosoma == chr)

    map_dfr(unique(cat_df\$Categoria), function(cat) {
      regions <- cat_df %>% filter(Categoria == cat)
      map_dfr(1:nrow(regions), function(i) {
        chr_df %>%
          filter(Posicion >= regions\$Pos_inicio[i], Posicion <= regions\$Pos_fin[i]) %>%
          mutate(Nombre = cat, categoria = regions\$Tipo[i])
      })
    })
  })
}

# Process all experiments
experiments <- expand.grid(exp = 1:3, time = c("T0", time))
all_data <- pmap_dfr(experiments, ~process_experiment(..1, ..2))

# Export all_data(Only to check raw data)
# write_tsv(all_data, all_data_path)
# message("Raw data saved to: ", all_data_path)

# Compute ratios
ratio_data <- all_data %>%
  group_by(Cepa, Cromosoma, categoria, Nombre, Experimento, Tiempo) %>%
  summarise(Valor_real = sum(Valor_real), .groups = "drop") %>%
  group_by(Cepa, Cromosoma, categoria, Nombre, Experimento) %>%
  mutate(ratio = Valor_real / Valor_real[Tiempo == "T0"]) %>%
  filter(Tiempo == time) %>%
  group_by(Cepa, Cromosoma, categoria, Nombre) %>%
  summarise(ratio_medio = mean(ratio), desv_est = sd(ratio), .groups = "drop")

# Plot
p <- ggplot(ratio_data) + 
    geom_col(aes(y = ratio_medio, x = Nombre), fill = "#2F2C7E", width = 0.7, 
           color = "black", linewidth = 0.1) +
    geom_errorbar(aes(x = Nombre, ymin = ratio_medio - desv_est, 
                    ymax = ratio_medio + desv_est), 
                width = 0.3, color = "grey8", alpha = 1, size = 0.3) +
    theme_classic() +
    labs(title = paste0("Ratio T0vs", time), subtitle = paste0("Cepa ", cepa), 
       y = "Ratio", x = "Feature")

    ggsave(
        filename = plot_path,
        plot = p,
        width = 8,
        height = 6,
        dpi = 300,
        device = "svg"
        )
    write_tsv(ratio_data, file = tsv_path)

EOF
            done
        done
    done
done

### ORDERING CATEGORIES DATASET ###

# Loop through each directory inside MYWD
for subdir in "${MYWD}"*/; do
  echo "Processing directory: $subdir"
  for time in "T0vsTSG" "T0vsTLG" "T0vsTLR"; do

    Rscript - <<EOF

library(tidyverse)

# Variables from Bash
category_path <- "${CATEGORY_PATH}"
subdir <- "${subdir}"
time <- "${time}"
subdir <- sub("/\$", "", subdir)  # Remove trailing slash

# Define all categories
categories <- c("ORF", "LTR", "TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Cen", "Tel", "Int")
combined <- list()

# Read the order file
orden_path <- file.path(category_path, "Nombre_ordenado_MATanoalpha_INTERGENICA.tsv")
orden <- read_tsv(orden_path, show_col_types = FALSE)

# Loop through all categories
for (category in categories) {
  file_path <- file.path(subdir, paste0(category, "_fingerprint_", basename(subdir), "_", time, ".tsv"))

  if (file.exists(file_path)) {
    message("Reading: ", file_path)
    df <- read_tsv(file_path, show_col_types = FALSE)
    df_analisis <- data.frame(Analisis = rep(time, nrow(df)))
    completo <- bind_cols(df, df_analisis)
    completo_ordenado <- merge(completo, orden, by = "Nombre")
    combined[[category]] <- completo_ordenado
  }
}

# Combine and write final output
if (length(combined) > 0) {
  all_combined <- bind_rows(combined)

  # Sort by the first letter and number in 'Nombre_ordenado'
  df_sorted <- all_combined %>%
    mutate(
      Initial = substr(Nombre_ordenado, 1, 1),
      Number = as.numeric(gsub("_.*", "", substr(Nombre_ordenado, 2, nchar(Nombre_ordenado))))
    ) %>%
    arrange(Initial, Number)

  # Save the sorted file
  sorted_output <- file.path(subdir, paste0("Genomic_sorted_", basename(subdir), "_", gsub(" ", "", time), ".tsv"))
  write_tsv(df_sorted, sorted_output)
  message("Sorted file written to: ", sorted_output)
} else {
  warning("No data found for time: ", time)
}
EOF

  done
done

# Move tsv category files into a category data folder
for subdir in "${MYWD}"*/; do
  mkdir -p "${subdir}/Category_Data_TSV_and_Plots"
  mv "${subdir}"/*"fingerprint"* "${subdir}/Category_Data_TSV_and_Plots/"
  mv "${subdir}"/*"all_data"* "${subdir}/Category_Data_TSV_and_Plots/"
  mv "${subdir}"/*".svg" "${subdir}/Category_Data_TSV_and_Plots/"
done

### PLOTTING CATEGORIES DATA ###

for subdir in "$MYWD"*/; do
  for time in "T0vsTSG.tsv" "T0vsTLG.tsv" "T0vsTLR.tsv"; do
  echo "Processing time point: $time"

# Run R inline to process and plot

Rscript - <<EOF

# Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
library(extrafont)
library(plotrix)

# Bash variables injected as strings
mydir <- "${MYWD}"
time <- "${time}"
subdir <- "${subdir}"

# Normalize subdir path and extract strain (folder name)
strain <- basename(normalizePath(subdir))

# Set working directory
setwd(subdir)

# REORDER THE DATASET BY CATEGORIES
# Define the order of categories
categoria_order <- c("ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene", 
                     "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene", 
                     "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere")

# Define the file pattern to search for
file_gen <- paste0("Genomic_sorted_", strain, "_", time)

# Check if the file exists
if (!file.exists(file_gen)) {
  stop("File not found: ", file_gen)
}

# Read the file
df_gen <- read_tsv(file_gen, show_col_types = FALSE)

# Factor and sort by category
df_gen <- df_gen %>%
  mutate(categoria = factor(categoria, levels = categoria_order, ordered = TRUE)) %>%
  arrange(categoria)

# Remove ".tsv" from time for cleaner output name
time_clean <- str_remove(time, "\\\\.tsv$")
out_name <- paste0("Category_sorted_", strain, "_", time_clean, ".tsv")

# Write Output
write_tsv(df_gen, out_name)
message("Written: ", out_name)

# PLOT VIOLIN PLOTS WITH THE DISTRIBUTION OF THE DATA FOR EACH GENOMIC CATEGORY

# Match tsvs with the timepoint
file_cat <- paste0("Category_sorted_", strain, "_", time)
# Check if the file exists
if (!file.exists(file_cat)) {
  stop("File not found: ", file_cat)
}

# Read the file
df_cat <- read_tsv(file_cat, show_col_types = FALSE)

# Convert categoria to factor
df_cat <- df_cat %>%
  mutate(categoria = factor(categoria, levels = categoria_order, ordered = TRUE))

# Define the transformation function # for better visualization
transform_y <- function(y) {
  ifelse(y <= 2, 
         y * (0.75 / 2),                     # scale 0-2 to 0-0.75
         0.75 + ((y - 2) * (0.25 / (10 - 2))) # scale 2-10 to 0.75-1
  )
}

# Transformed ratio_medio column
df_cat\$ratio_medio_trans <- transform_y(df_cat\$ratio_medio)

# Create output folder
out_dir <- file.path(subdir, "Plots_Analysis")
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

# Define the color palette with your specific color codes
categoria_colors <- c(
  "ORF" = "#4F71BE", 
  "intergenic" = "#FF051D", 
  "long_terminal_repeat" = "#DE8344", 
  "transposable_element_gene" = "#A5A5A5", 
  "LTR_retrotransposon" = "#F5C242", 
  "tRNA_gene" = "#6A99D0", 
  "rRNA_gene" = "#7EAB55", 
  "ncRNA_gene" = "#2D4374", 
  "snRNA_gene" = "#934D20", 
  "snoRNA_gene" = "#636363", 
  "ARS" = "#937424", 
  "centromere" = "#355D8D", 
  "telomere" = "#4B6733"
)

p1 <- ggplot(df_cat, aes(x = categoria, y = ratio_medio_trans, fill = categoria)) +
  geom_jitter(aes(color = categoria), width = 0.1, size = 0.1, alpha = 0.2) +
  geom_violin(trim = FALSE, size = 0.1, width = 0.8, alpha = 0.8, scale = "width") +
  geom_boxplot(width = 0.1, alpha = 1, size = 0.1, outlier.shape = NA) +
  theme_minimal() +
  labs(title = paste("Strain:", strain, "-", time),
       x = "Category", y = "Coverage", fill = "Category") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = categoria_colors) +
  scale_color_manual(values = categoria_colors, guide = "none") + 
  scale_x_discrete(labels = c(
  "ORF" = "ORF",
  "intergenic" = "Intergenic",
  "long_terminal_repeat" = "LTR",
  "transposable_element_gene" = "TEG",
  "LTR_retrotransposon" = "Ty",
  "tRNA_gene" = "tRNA",
  "rRNA_gene" = "rRNA",
  "ncRNA_gene" = "ncRNA",
  "snRNA_gene" = "snRNA",
  "snoRNA_gene" = "snoRNA",
  "ARS" = "ARS",
  "centromere" = "Centromere",
  "telomere" = "Telomere"
  )) +
  coord_cartesian(ylim = c(0, 1.02), expand = FALSE) +
  scale_y_continuous(
    name = "Coverage",
    breaks = c(0, 0.1875, 0.375, 0.5625, 0.75, 0.8125, 0.875, 0.9375, 1),
    labels = c("0", "0.5", "1", "1.5", "2", "4", "6", "8", "10")
  )

  # Save the plot
  formats <- c("svg", "png")
  for (fmt in formats) {
    ggsave(
      filename = file.path(out_dir, paste0("Violin_", strain, "_", time_clean, ".", fmt)),
      plot = p1,
      device = fmt,
      width = 8,
      height = 5,
      dpi = 300
    )
  }

# PLOTTING GENOMIC COVERAGE

# Prepare the template dataframe: Generate column1, total number of rows in the dataframe
total_rows <- nrow(df_cat)

# First segment: 0.5 increments
first_part <- seq(1, 6597.5, by = 0.5)

# Number of remaining positions
remaining <- total_rows - length(first_part)

# Second segment: 1 increments starting from 6599
second_part <- seq(6598.5, by = 1, length.out = remaining)

# Combine both parts
position_vector <- c(first_part, second_part)

# Create the final dataframe
Cov_df <- data.frame(
  Position = position_vector,
  Coverage = df_cat\$ratio_medio,
  Coverage_eje = df_cat\$ratio_medio - 1,
  SD = df_cat\$desv_est,
  Series = df_cat\$categoria
  )

# Output filename
cov_out_name <- paste0("Coverage_Template_Data_", strain, "_", time_clean, ".tsv")

# Write the new TSV
write_tsv(Cov_df, file = cov_out_name)
message("Written: ", cov_out_name)

# Plot genomic coverage
p2 <- ggplot(Cov_df, aes(x = Position, y = Coverage_eje)) +
  geom_col(size = 0.1, linewidth = 0.1, color = "darkblue") +
  theme_classic(base_family = "Arial") +
  theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                  panel.background = element_blank(), 
                                  plot.background = element_rect(fill = "transparent", colour = NA)) +
  theme(legend.position="none") +
  labs(title = paste("Strain:", strain, "-", time),
       x = "Position", y = "Coverage (ratio_medio)") +
  coord_cartesian(xlim = c(1,7921.5), ylim = c(-1, 1), expand=FALSE) +
  theme(aspect.ratio = 0.08) + 
  scale_x_continuous(breaks = c(1, 3285.5, 6598.5, 6981.5, 7072.5, 7122.5, 7397.5,
                                7422.5, 7439.5, 7445.5, 7522.5, 7874.5, 7890.5)) +
  scale_y_continuous(breaks = seq(-1, 1, 0.5),
                    labels = c("0", "0.5", "1", "1.5", "2")) +
  geom_vline(xintercept=c(1, 59.5, 287.5, 378, 796, 957.5, 1027, 1318.5, 1479,
                          1599.5, 1798.5, 1972.5, 2261.5, 2514, 2731.5, 3030),
            linetype="dashed", color = "black", linewidth=0.1) +
  geom_vline(xintercept=c(3285.5, 3342, 3567.5, 3669, 4081, 4247, 4319.5, 4623, 4781.5,
                          4899.5, 5101.5, 5284.5, 5564.5, 5824.5, 6040.5, 6343.5),
            linetype="dashed", color = "black", linewidth=0.1) +
  geom_vline(xintercept=c(3285.5, 6598.5, 6981.5, 7072.5, 7122.5, 7397.5,
                          7422.5, 7439.5, 7445.5, 7522.5, 7874.5, 7890.5),
            linetype="dashed", color = "black", linewidth=0.15) +
  theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 10),
        axis.title.y = element_text(vjust = 1, size = 10)) +
  theme(axis.text.x = element_text(vjust = 0, size = 0),
        axis.text.y = element_text(vjust = 0, size = 5))
  
  # Save the plot
  formats <- c("svg", "png")
  for (fmt in formats) {
    ggsave(
      filename = file.path(out_dir, paste0("Genomic_Coverage_", strain, "_", time_clean, ".", fmt)),
      plot = p2,
      device = fmt,
      width = 8,
      height = 5,
      dpi = 300
    )
  }

# QUANTIFICATION OF COVERAGE >1.2 AND <0.8

Cov_summary <- Cov_df %>%
  group_by(Series) %>%
  summarise(
    total_non_na = sum(!is.na(Coverage)),
    perc_above_1.2 = (sum(Coverage > 1.2, na.rm = TRUE) / total_non_na) * 100,
    perc_below_0.8 = (sum(Coverage < 0.8, na.rm = TRUE) / total_non_na) * 100,
    sd_above_1.2 = mean(SD[Coverage > 1.2], na.rm = TRUE),
    sd_below_0.8 = mean(SD[Coverage < 0.8], na.rm = TRUE)
  )

# Pivot to long format for plotting
Cov_summary_long <- Cov_summary %>%
  select(Series, perc_above_1.2, perc_below_0.8, sd_above_1.2, sd_below_0.8) %>%
  pivot_longer(cols = starts_with("perc_"), names_to = "Category", values_to = "Percentage") %>%
  mutate(
    Category = recode(Category,
                      "perc_above_1.2" = "> 1.2",
                      "perc_below_0.8" = "< 0.8"),
    Percentage = ifelse(Category == "< 0.8", -Percentage, Percentage)
  )

# Add SDs in same long format
Cov_sd_long <- Cov_summary %>%
  select(Series, sd_above_1.2, sd_below_0.8) %>%
  pivot_longer(cols = starts_with("sd_"), names_to = "Category", values_to = "SD") %>%
  mutate(
    Category = recode(Category,
                      "sd_above_1.2" = "> 1.2",
                      "sd_below_0.8" = "< 0.8")
  )

# Merge percentages and SDs
Cov_summary <- left_join(Cov_summary_long, Cov_sd_long, by = c("Series", "Category"))

# Plot the results
# Define the order for the y-axis categories
  category_order <- c(
    "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
    "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
    "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
  )
# Relevel Series factor in the summary dataframe
  Cov_summary\$Series <- factor(Cov_summary\$Series, levels = rev(category_order))

p3 <- ggplot(Cov_summary, aes(x = Percentage, y = Series, fill = Category)) +
  geom_col(width = 0.6) +
  geom_errorbarh(aes(xmin = Percentage - SD, xmax = Percentage + SD, color = Category),
                 height = 0.3, linewidth = 0.25) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.5) +
  scale_color_manual(values = c("> 1.2" = "#A30000", "< 0.8" = "#2F2C7E")) +
  scale_fill_manual(values = c("> 1.2" = "#A30000", "< 0.8" = "#2F2C7E")) +
  scale_x_continuous(labels = abs,
                     name = "Percentage",
                     limits = c(-75, 75)) +
  scale_y_discrete(labels = c(
    "ORF" = "ORF",
    "intergenic" = "Intergenic",
    "long_terminal_repeat" = "LTR",
    "transposable_element_gene" = "TEG",
    "LTR_retrotransposon" = "Ty",
    "tRNA_gene" = "tRNA",
    "rRNA_gene" = "rRNA",
    "ncRNA_gene" = "ncRNA",
    "snRNA_gene" = "snRNA",
    "snoRNA_gene" = "snoRNA",
    "ARS" = "ARS",
    "centromere" = "Centromere",
    "telomere" = "Telomere"
  )) +
  labs(title = paste("Strain:", strain, "-", time),
       x = "Percentage",
       y = "Category") +
  theme_minimal() +
  theme(
    panel.grid.major.y = element_blank(),
    axis.title.y = element_text(margin = margin(r = 10)),
    axis.title.x = element_text(margin = margin(t = 10))
  )

  # Save the plot
  formats <- c("svg", "png")
  for (fmt in formats) {
    ggsave(
      filename = file.path(out_dir, paste0("Percentages <0.8 and >1.2_", strain, "_", time_clean, ".", fmt)),
      plot = p3,
      device = fmt,
      width = 8,
      height = 5,
      dpi = 300
    )
  }

# QUANTIFICATION OF COVERAGE >1.2 AND <0.8 BY CHROMOSOME

# Reorder the dataset by chromosome
  # Define the order of chromosomes
  chromosome_order <- c("CHRI", "CHRII", "CHRIII", "CHRIV", "CHRV", "CHRVI", 
                       "CHRVII", "CHRVIII", "CHRIX", "CHRX", "CHRXI", 
                       "CHRXII", "CHRXIII", "CHRXIV", "CHRXV", "CHRXVI")

# Sort Coverage file by chromosme
df_gen_chr <- df_gen %>%
  mutate(Cromosoma = factor(Cromosoma, levels = chromosome_order, ordered = TRUE)) %>%
  arrange(Cromosoma)

# Otuput file
chr_name <- paste0("Chromosome_sorted_", strain, "_", time_clean, ".tsv")

# Write Output
write_tsv(df_gen_chr, chr_name)
message("Written: ", chr_name)

# Filtering the data (cov >1.2 and <0.8), determine their percentage against the total values per chromosome
Chr_summary <- df_gen_chr %>%
  group_by(Cromosoma) %>%
  summarise(
    total_non_na = sum(!is.na(ratio_medio)),
    above_1.2 = sum(ratio_medio > 1.2, na.rm = TRUE),
    below_0.8 = sum(ratio_medio < 0.8, na.rm = TRUE),
    perc_above = (above_1.2 / total_non_na) * 100,
    perc_below = (below_0.8 / total_non_na) * 100,
    sd_above = mean(desv_est[ratio_medio > 1.2], na.rm = TRUE),
    sd_below = mean(desv_est[ratio_medio < 0.8], na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = c(perc_above, perc_below),
    names_to = "Category",
    values_to = "Percentage"
  ) %>%
  mutate(
    SD = ifelse(Category == "perc_above", sd_above, sd_below),
    Category = ifelse(Category == "perc_above", "> 1.2", "< 0.8"),
  ) %>%
  select(Cromosoma, Category, Percentage, SD)

# Apply negation to the <0.8 values only for p4
  Chr_summary_p4 <- Chr_summary %>%
    mutate(Percentage = ifelse(Category == "< 0.8", -Percentage, Percentage))

# Plot the results
# Relevel Chromosome factor in the summary dataframe
Chr_summary_p4\$Cromosoma <- factor(Chr_summary\$Cromosoma, levels = (chromosome_order))

p4 <- ggplot(Chr_summary_p4, aes(x = Cromosoma, y = Percentage, fill = Category)) +
  geom_col(width = 0.6) +
  geom_errorbar(aes(ymin = Percentage - SD, ymax = Percentage + SD, color = Category),
                width = 0.2, linewidth = 0.3) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.5) +
  scale_fill_manual(values = c("> 1.2" = "#A30000", "< 0.8" = "#2F2C7E")) +
  scale_color_manual(values = c("> 1.2" = "#A30000", "< 0.8" = "#2F2C7E")) +
  scale_y_continuous(labels = abs,
                     name = "Percentage",
                     limits = c(-5, 15),
                     breaks = seq(-5, 15, 2.5)) +
  scale_x_discrete(
    name = "Chromosome",
    labels = c("I", "II", "III", "IV", "V", "VI", 
               "VII", "VIII", "IX", "X", "XI", 
               "XII", "XIII", "XIV", "XV", "XVI")
  ) +
  labs(title = paste("Strain:", strain, "-", time)) +
  theme_minimal() +
  theme(
    axis.title.y = element_text(margin = margin(r = 10)),
    axis.title.x = element_text(margin = margin(t = 10)),
    legend.position = "right"
  )

  # Save the plot
  formats <- c("svg", "png")
  for (fmt in formats) {
    ggsave(
      filename = file.path(out_dir, paste0("Chr_Percentages <0.8 and >1.2_", strain, "_", time_clean, ".", fmt)),
      plot = p4,
      device = fmt,
      width = 8,
      height = 5,
      dpi = 300
    )
  }

# Plot the results in a circular format
# Relevel Chromosome factor in the summary dataframe
Chr_summary\$Cromosoma <- factor(Chr_summary\$Cromosoma, levels = chromosome_order)

p5 <- ggplot(Chr_summary, aes(x = Cromosoma, y = Percentage, fill = Category)) +
  geom_bar(stat = "identity", position = position_dodge(1), width = 1, alpha = 1) +
  coord_polar(start = -pi / 16) +
  scale_y_continuous(limits = c(-1.66, 10), breaks = c(0, 3.3, 6.6, 10), expand = c(0, 0)) +
  scale_x_discrete(
    name = "Chromosome",
    labels = c("I", "II", "III", "IV", "V", "VI", 
               "VII", "VIII", "IX", "X", "XI", 
               "XII", "XIII", "XIV", "XV", "XVI")
  ) +
  geom_vline(xintercept = seq(0.5, length(unique(Chr_summary\$Cromosoma)) + 1.5, by = 1), color = "gray", linewidth = 0.1) +
  geom_errorbar(aes(ymin = Percentage - SD, ymax = Percentage + SD, color = Category),
                width = 0.2, linewidth = 0.3,
                position = position_dodge (1)
                ) +
  scale_color_manual(values = c("> 1.2" = "#BE1823", "< 0.8" = "#2F2C7E")) +  
  scale_fill_manual(values = c("> 1.2" = "#BE1823", "< 0.8" = "#2F2C7E")) +  
  theme_minimal() +
  theme(
    panel.grid.major.y = element_line(linewidth = 0.2),
    panel.grid.minor.y = element_line(linewidth = 0.2),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_line(linewidth = 0.2),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 12)
  ) +
    labs(title = paste("Strain:", strain, "-", time),
      x = "Percentage",
      y = "Crhomosome"
      )

  # Save the plot
  formats <- c("svg", "png")
  for (fmt in formats) {
    ggsave(
      filename = file.path(out_dir, paste0("Chr_Percentages_Circular_<0.8_and_>1.2_", strain, "_", time_clean, ".", fmt)),
      plot = p5,
      device = fmt,
      width = 8,
      height = 5,
      dpi = 300
    )
  }

EOF

  done
done

# R plots for gal vs raf coverage
# Start timer for R processing

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      #echo "$root_dir"
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Plotting gal vs raf coverage" >> "$log_file"
        start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        #echo "ROOT_DIR: $ROOT_DIR"
        #echo "STRAIN: $STRAIN"
        Rscript - <<'EOF'
          # load libraries

          library(ggplot2)
          library(svglite)
          library(purrr)
          library(stringr)
          library(readr)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          options(dplyr.summarise.inform = FALSE)
          library(ggrepel)

          # Read environment variables
          root_dir <- Sys.getenv("ROOT_DIR")
          strain <- Sys.getenv("STRAIN")
          strain <- sub("/$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)

          print(paste("ROOT_DIR:", root_dir))

          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }


        

          # Define a function to process tsv files
          process_coverage_files <- function(file_path) {
            # Extract filename and directory parts
            file_base <- basename(file_path)
            strain_name <- basename(dirname(file_path))  # directory name above the file
            
            # Read file
            temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE) 
            # Skip if empty
            if (nrow(temp_file) == 0) {
              return(NULL)
            }
            
            # Prepare coverage dataframe
            coverage_file <- temp_file %>%  select(Nombre, categoria, ratio_medio, desv_est, Analisis) %>% 
              mutate(
                strain = strain_name
              )
            coverage_file_renamed <- coverage_file %>%  
              rename_with(~ paste0("ratio_medio_", unique(coverage_file$Analisis)), .cols = "ratio_medio") %>%
              rename_with(~ paste0("desv_est_", unique(coverage_file$Analisis)), .cols = "desv_est") %>%  select(!c(Analisis))
            
            return(coverage_file_renamed)
          }


          log_step("Finding coverage files...")
          # Get all coverage.tsv files recursively in root folder
          TLG_coverage_files <- list.files(
            path = root_dir,
            pattern = "Genomic_sorted_.*_T0vsTLG\\.tsv$",
            recursive = TRUE,
            full.names = TRUE
          )

          # Get all coverage.tsv files recursively in root folder
          TLR_coverage_files <- list.files(
            path = root_dir,
            pattern = "Genomic_sorted_.*_T0vsTLR\\.tsv$",
            recursive = TRUE,
            full.names = TRUE
          )

          # Get all coverage.tsv files recursively in root folder
          TSG_coverage_files <- list.files(
            path = root_dir,
            pattern = "Genomic_sorted_.*_T0vsTSG\\.tsv$",
            recursive = TRUE,
            full.names = TRUE
          )

          log_step("Processing coverage files...")
          TLG_processed_df <- purrr::map_dfr(TLG_coverage_files, process_coverage_files)
          TLR_processed_df <- purrr::map_dfr(TLR_coverage_files, process_coverage_files)
          TSG_processed_df <- purrr::map_dfr(TSG_coverage_files, process_coverage_files)

          complete_df <- left_join(TLG_processed_df, TLR_processed_df) %>% 
            left_join(., TSG_processed_df)

          # complete_df 
          # write_tsv(complete_df, file.path(root_dir, paste0(strain_name, "_complete_df.tsv")))

          complete_df_ratio <- complete_df %>% select(strain, Nombre, categoria, 
                                            ratio_medio_T0vsTLG, ratio_medio_T0vsTLR, ratio_medio_T0vsTSG) %>% 
            filter(if_all(starts_with("ratio_medio"), ~ !is.na(.) & is.finite(.))) %>%
            mutate(UP_DOWN_TLG = ifelse(ratio_medio_T0vsTLG > 1.2 & (ratio_medio_T0vsTLR > 0.8 & ratio_medio_T0vsTLR <1.2), "UP", 
                                        ifelse(ratio_medio_T0vsTLG < 0.8 & (ratio_medio_T0vsTLR > 0.8 & ratio_medio_T0vsTLR <1.2), "DOWN", "NO_CHANGE"))) %>% 
            mutate(UP_DOWN_TSG = ifelse(ratio_medio_T0vsTSG > 1.2 & (ratio_medio_T0vsTLR > 0.8 & ratio_medio_T0vsTLR <1.2), "UP", 
                                        ifelse(ratio_medio_T0vsTSG < 0.8 & (ratio_medio_T0vsTLR > 0.8 & ratio_medio_T0vsTLR <1.2), "DOWN", "NO_CHANGE")))

          # write_tsv(complete_df_ratio, file.path(root_dir, paste0(strain_name, "_complete_df_ratio.tsv")))

          n_features <- nrow(complete_df_ratio)

          UP_DOWN_summary <- complete_df_ratio %>% group_by(strain) %>% 
            summarise(UP_TLG = sum(UP_DOWN_TLG == "UP"),
                      DOWN_TLG = sum(UP_DOWN_TLG == "DOWN"),
                      UP_TSG = sum(UP_DOWN_TSG == "UP"),
                      DOWN_TSG = sum(UP_DOWN_TSG == "DOWN")) %>% 
            mutate(UP_TLG_perc = UP_TLG/n_features*100,
                  DOWN_TLG_perc = DOWN_TLG/n_features*100,
                  UP_TSG_perc = UP_TSG/n_features*100,
                  DOWN_TSG_perc = DOWN_TSG/n_features*100) %>% 
            select(strain, ends_with("_perc"))

          

          write_tsv(UP_DOWN_summary, file.path(root_dir, paste0(strain_name, "_UP_DOWN_summary.tsv")))

          # 
          categoria_colors <- c(
            "ORF" = "#4F71BE", 
            "intergenic" = "#FF051D", 
            "long_terminal_repeat" = "#DE8344", 
            "transposable_element_gene" = "#A5A5A5", 
            "LTR_retrotransposon" = "#F5C242", 
            "tRNA_gene" = "#6A99D0", 
            "rRNA_gene" = "#7EAB55", 
            "ncRNA_gene" = "#2D4374", 
            "snRNA_gene" = "#934D20", 
            "snoRNA_gene" = "#636363", 
            "ARS" = "#937424", 
            "centromere" = "#355D8D", 
            "telomere" = "#4B6733"
          )
          log_step("Plotting...")
          plot_TLG<- ggplot(complete_df_ratio, aes(x = ratio_medio_T0vsTLG, y = ratio_medio_T0vsTLR)) +
            geom_point(aes(colour = categoria, alpha = UP_DOWN_TLG),size = 2, shape = 16) + #0.5
            scale_colour_manual(values=categoria_colors) +
            scale_alpha_manual(values = c("NO_CHANGE" = 0.8, "UP" = 0.8, "DOWN" = 0.8)) +
            theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            # geom_text_repel(data = subset(complete_df_ratio, UP_DOWN_TLG == "UP" & ratio_medio_T0vsTLG > 2),
            #               aes(label = Nombre, color = categoria),
            #               size = 3, show.legend = FALSE, max.overlaps = Inf) +
            # geom_text_repel(data = subset(complete_df_ratio, UP_DOWN_TLG == "DOWN" & ratio_medio_T0vsTLG < 0.5),
            #                 aes(label = Nombre, color = categoria),
            #                 size = 3, show.legend = FALSE, max.overlaps = Inf) +
            theme(legend.position="none") + 
            coord_cartesian(xlim = c(0,5.3), ylim = c(0, 5.3), expand=FALSE) +
            theme(aspect.ratio = 0.8) +
            geom_vline(xintercept=c(0.75, 1.25),
                      linetype="dashed", color = "black", linewidth=0.3) +
            geom_hline(yintercept=c(0.75, 1.25),
                      linetype="dashed", color = "black", linewidth=0.3) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 20), #25
                  axis.title.y = element_text(vjust = 1, size = 20)) + #25
            theme(axis.text.x = element_text(vjust = 0, size = 15), #20
                  axis.text.y = element_text(vjust = 0, size = 15)) +
            labs(
                title = paste0("Gal vs Raf coverage - ", strain_name, " - ", "TLG"),
                x = "Gal_coverage",
                y = "Raf_coverage"
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("Gal_vs_raf_coverage_", strain_name, "_","TLG", ".svg")),
              plot = plot_TLG,
              #width = 8,
              #height = 3.6,
              device = svglite,
              bg = "transparent"
            )

            plot_TSG <- ggplot(complete_df_ratio, aes(x = ratio_medio_T0vsTSG, y = ratio_medio_T0vsTLR)) +
            geom_point(aes(colour = categoria, alpha = UP_DOWN_TSG),size = 2, shape = 16) + #0.5
            scale_colour_manual(values=categoria_colors) +
            scale_alpha_manual(values = c("NO_CHANGE" = 0.8, "UP" = 0.8, "DOWN" = 0.8)) +
            theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            # geom_text_repel(data = subset(complete_df_ratio, UP_DOWN_TSG == "UP" & ratio_medio_T0vsTSG > 2),
            #               aes(label = Nombre, color = categoria),
            #               size = 3, show.legend = FALSE, max.overlaps = Inf) +
            # geom_text_repel(data = subset(complete_df_ratio, UP_DOWN_TSG == "DOWN" & ratio_medio_T0vsTSG < 0.5),
            #                 aes(label = Nombre, color = categoria),
            #                 size = 3, show.legend = FALSE, max.overlaps = Inf) +
            theme(legend.position="none") + 
            coord_cartesian(xlim = c(0,5.3), ylim = c(0, 5.3), expand=FALSE) +
            theme(aspect.ratio = 0.8) +
            geom_vline(xintercept=c(0.75, 1.25),
                      linetype="dashed", color = "black", linewidth=0.3) +
            geom_hline(yintercept=c(0.75, 1.25),
                      linetype="dashed", color = "black", linewidth=0.3) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 20), #25
                  axis.title.y = element_text(vjust = 1, size = 20)) + #25
            theme(axis.text.x = element_text(vjust = 0, size = 15), #20
                  axis.text.y = element_text(vjust = 0, size = 15)) +
            labs(
                title = paste0("Gal vs Raf coverage - ", strain_name, " - ", "TSG"),
                x = "Gal_coverage",
                y = "Raf_coverage"
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("Gal_vs_raf_coverage_", strain_name, "_TSG", ".svg")),
              plot = plot_TSG,
              #width = 8,
              #height = 3.6,
              device = svglite,
              bg = "transparent"
            )


          
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total gal vs raf plotting completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 

done


# Move tsv category files into a category data folder
for subdir in "${MYWD}"*/; do
  mkdir -p "${subdir}/Sorted_datasets"
  mv "${subdir}"/*"sorted"* "${subdir}/Sorted_datasets"
  mv "${subdir}"/*"Template"* "${subdir}/Sorted_datasets"
  mv "${subdir}"/*"UP_DOWN"* "${subdir}/Sorted_datasets"
  mv "${subdir}"/*".svg" "${subdir}/Plots_Analysis/"
done

# Calulate total elapsed time
elapsed_time_total_cat=$((( SECONDS - start_time_total_cat )/60))
echo "Genomic Categories Analysis completed in ${elapsed_time_total_cat} minutes" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line


###########################################
########### MUTAGENIC RATE AT HO ########## #Updated on 30/09/2025
###########################################

current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Mutagenic Rate at HO Analysis - initiated at: \"$current_time\"" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line 

#Add a line to separate bowtie and bwa alignments in the stat file
echo "=========  BWA Alignment ==========" >> "$stats"
echo "=========  Mutagenic rate at HO - BWA Alignment ==========" >> "$log_file"

# Set locale
export LC_ALL=C
export LANG=C

# Start timer for the entire script processing
start_time_total_mut=$SECONDS

# Index RG
bwa index "${MYREF}/RG_PMV_v9_CHRIII.fasta"

# Loop through each directory inside MYWD for alignments
for subdir in "$MYWD"*/; do
  echo "Processing directory: $subdir"
    for sample in T0 TLG TLR; do
      for exp in E1 E2 E3; do
        file1_gz="${subdir}/${sample}_${exp}_R1.fastq.gz"
        file2_gz="${subdir}/${sample}_${exp}_R2.fastq.gz"
       
        # Check if both compressed files exist
        if [[ -f "$file1_gz" && -f "$file2_gz" ]]; then
          echo "Processing files: $file1_gz, $file2_gz"

          # Decompress the current pair
          gunzip -k "$file1_gz" "$file2_gz"
          file1_path="${subdir}/${sample}_${exp}_R1.fastq"
          file2_path="${subdir}/${sample}_${exp}_R2.fastq"

          # Concatenate the two fastq files
          cat "$file1_path" "$file2_path" > "${subdir}/${sample}_${exp}.fastq"
          
          #Filtering and alinging reads
          if [[ -f "${subdir}/${sample}_${exp}.fastq" ]]; then
          
            # Detecting number of available CPUs
            N_CPU=$(nproc)
            
            # Filter reads Q30
            fastp \
            -i "${subdir}/${sample}_${exp}.fastq" \
            -o "${subdir}/${sample}_${exp}_Q30.fastq" \
            -q 30 -u 0 -e 30 \
            --thread "$N_CPU" \
            --html "${subdir}/${sample}_${exp}_Q30.fastq.html" \
            --json "${subdir}/${sample}_${exp}_Q30.fastq.json"
                
            # BWA mapping
            bwa mem -t "$N_CPU" "${MYREF}/RG_PMV_v9_CHRIII.fasta" "${subdir}/${sample}_${exp}_Q30.fastq" > "${subdir}/${sample}_${exp}_Q30.sam"

            # Filtering CHRIII reads
            sed -n -e '1,2p' "${subdir}/${sample}_${exp}_Q30.sam" > "${subdir}/${sample}_${exp}_cabecera.sam"
            awk '$3 == "CHRIII"' "${subdir}/${sample}_${exp}_Q30.sam" > "${subdir}/${sample}_${exp}_Q30_CHRIII.sam"
            cat "${subdir}/${sample}_${exp}_cabecera.sam" "${subdir}/${sample}_${exp}_Q30_CHRIII.sam" > "${subdir}/${sample}_${exp}_Q30_CHRIII_header.sam"
          
            # Convert SAM to sorted BAM
            samtools sort -@ "$N_CPU" -o "${subdir}/${sample}_${exp}_processed.bam" "${subdir}/${sample}_${exp}_Q30_CHRIII_header.sam"
            samtools index "${subdir}/${sample}_${exp}_processed.bam" "${subdir}/${sample}_${exp}_processed.bai"

            # Extact reads mapping to the HO site
            samtools view "${subdir}/${sample}_${exp}_processed.bam" "CHRIII:200753-200753" -h -O SAM > "${subdir}/${sample}_${exp}_HOs.sam"
            samtools sort -@ "$N_CPU" -o "${subdir}/${sample}_${exp}_HOs.bam" "${subdir}/${sample}_${exp}_HOs.sam"
            samtools index "${subdir}/${sample}_${exp}_HOs.bam" "${subdir}/${sample}_${exp}_HOs.bai"
            echo "" >> "$stats"
            echo "### $(basename "$subdir")/${sample}/${exp} 150nt ###" >> "$stats"
            echo "BWA Alignment: Reads mappint the HO site" >> "$stats"
            samtools flagstat "${subdir}/${sample}_${exp}_HOs.bam" | head -n 1 >> "$stats"

            # Remove intermediate files
            rm "${subdir}"/*.fastq "${subdir}"/*.sam
            
          else
          echo "Warning: Decompressed files missing for sample $sample in $subdir!" >> "$log_file"
          echo "" >> "$log_file"
          fi
        else
        echo "Warning: One or both compressed files for sample $sample are missing in $subdir!" >> "$log_file"
        echo "" >> "$log_file"
        fi
      done
    done
done

# Remove intermediate files
find "$MYWD" -type f \( -name "*.sam" -o -name "*.fastq" \) -exec rm {} + # intermediate alignmet files

### DATA ANALYSIS ###

# Start timer for data analysis and plotting

### Invoque python script to extract reads with A or G at postion 200689 ###

for subdir in "$MYWD"*/; do
  for sample in T0 TLG TLR; do
    for exp in E1 E2 E3; do
      bam_file="${subdir}/${sample}_${exp}_HOs.bam"
      output_bam_G="${subdir}/${sample}_${exp}_200689_G.bam"
      output_bam_A="${subdir}/${sample}_${exp}_200689_A.bam"
      if [[ -f "$bam_file" ]]; then
        echo "Processing BAM file: $bam_file"
      else
        echo "Warning: BAM file $bam_file does not exist!"
      fi
  
python3 <<EOF
import pysam
import sys

def extract_reads(bam_file, nucleotide, output_bam, ref_name, position):
    try:
        # Open input BAM
        bam = pysam.AlignmentFile(bam_file, "rb")
        
        # Open output BAM (using input as template)
        out_bam = pysam.AlignmentFile(output_bam, "wb", template=bam)
        
        # Fetch reads overlapping the position (1-based in pysam)
        for read in bam.fetch(ref_name, position-1, position):
            # Skip if no sequence (e.g., unmapped reads)
            if not read.query_sequence:
                continue
            
            # Get aligned pairs (query-to-reference positions)
            aligned_pairs = read.get_aligned_pairs(matches_only=True)
            
            # Check each aligned base
            for query_pos, ref_pos in aligned_pairs:
                # If this is the target position (0-based)
                if ref_pos == position - 1:
                    # Check if the base matches the desired nucleotide
                    if read.query_sequence[query_pos] == nucleotide:
                        out_bam.write(read)
                        break  # Stop checking this read once matched
        
        # Close files
        bam.close()
        out_bam.close()
    
    except Exception as e:
        print(f"ERROR: Failed to process {bam_file} for {nucleotide}: {e}", file=sys.stderr)
        sys.exit(1)

# ===== Parameters =====
bam_file = "${bam_file}"          # Input BAM file
ref_name = "CHRIII"               # Reference chromosome
position = 200689                 # 1-based genomic position
nucleotideA = "A"                 # Nucleotide to extract (A)
output_bam_A = "${output_bam_A}"  # Output BAM for A reads
nucleotideG = "G"                 # Nucleotide to extract (G)
output_bam_G = "${output_bam_G}"  # Output BAM for G reads

# ===== Run Extraction =====
extract_reads(bam_file, nucleotideA, output_bam_A, ref_name, position)
extract_reads(bam_file, nucleotideG, output_bam_G, ref_name, position)
EOF

    #Generate bai index for the new bam files
    samtools index "${output_bam_A}" "${output_bam_A}.bai"
    samtools index "${output_bam_G}" "${output_bam_G}.bai"

    # Add stats to the log file
    echo "Read count for A at 200689: $(samtools view -c "${output_bam_A}")" 
    #samtools view -c "${output_bam_A}" > "${subdir}/${sample}_${exp}_200689A_row_count.tsv"
    echo "Read count for G at 200689: $(samtools view -c "${output_bam_G}")" 
    samtools view -c "${output_bam_G}" > "${subdir}/${sample}_${exp}_200689G_row_count.tsv"
    done
  done
done

### Invoque python script to extract reads with T or C at postion 200753 from reads with A at position 200689 ###

for subdir in "$MYWD"*/; do
  for sample in T0 TLG TLR; do
    for exp in E1 E2 E3; do
      bam_file="${subdir}/${sample}_${exp}_200689_A.bam"
      output_bam_T="${subdir}/${sample}_${exp}_200689_A_200753_T.bam"
      output_bam_C="${subdir}/${sample}_${exp}_200689_A_200753_C.bam"
      if [[ -f "$bam_file" ]]; then
        echo "Processing BAM file: $bam_file"
      else
        echo "Warning: BAM file $bam_file does not exist!"
      fi
  
python3 <<EOF
import pysam
import sys

def extract_reads(bam_file, nucleotide, output_bam, ref_name, position):
    try:
        # Open input BAM
        bam = pysam.AlignmentFile(bam_file, "rb")
        
        # Open output BAM (using input as template)
        out_bam = pysam.AlignmentFile(output_bam, "wb", template=bam)
        
        # Fetch reads overlapping the position (1-based in pysam)
        for read in bam.fetch(ref_name, position-1, position):
            # Skip if no sequence (e.g., unmapped reads)
            if not read.query_sequence:
                continue
            
            # Get aligned pairs (query-to-reference positions)
            aligned_pairs = read.get_aligned_pairs(matches_only=True)
            
            # Check each aligned base
            for query_pos, ref_pos in aligned_pairs:
                # If this is the target position (0-based)
                if ref_pos == position - 1:
                    # Check if the base matches the desired nucleotide
                    if read.query_sequence[query_pos] == nucleotide:
                        out_bam.write(read)
                        break  # Stop checking this read once matched
        
        # Close files
        bam.close()
        out_bam.close()
    
    except Exception as e:
        print(f"ERROR: Failed to process {bam_file} for {nucleotide}: {e}", file=sys.stderr)
        sys.exit(1)

# ===== Parameters =====
bam_file = "${bam_file}"          # Input BAM file
ref_name = "CHRIII"               # Reference chromosome
position = 200753                 # 1-based genomic position
nucleotideT = "T"                 # Nucleotide to extract (T)
output_bam_T = "${output_bam_T}"  # Output BAM for T reads
nucleotideC = "C"                 # Nucleotide to extract (T)
output_bam_C = "${output_bam_C}"  # Output BAM for C reads

# ===== Run Extraction =====
extract_reads(bam_file, nucleotideT, output_bam_T, ref_name, position)
extract_reads(bam_file, nucleotideC, output_bam_C, ref_name, position)
EOF

    #Generate bai index for the new bam files
    samtools index "${output_bam_T}" "${output_bam_T}.bai"
    samtools index "${output_bam_C}" "${output_bam_C}.bai"
    # Add stats to the log file
    echo "Read count for T at 200753 and A at 200689: $(samtools view -c "${output_bam_T}")" 
    samtools view -c "${output_bam_T}" > "${subdir}/${sample}_${exp}_200689AT_row_count.tsv"
    echo "Read count for C at 200753 and A at 200689: $(samtools view -c "${output_bam_C}")"
    samtools view -c "${output_bam_C}" > "${subdir}/${sample}_${exp}_200689AC_row_count.tsv"



    # Merge the two bam files
    samtools merge -f "${subdir}/${sample}_${exp}_200689_A_CT.bam" "${output_bam_C}" "${output_bam_T}"
    samtools view -c "${subdir}/${sample}_${exp}_200689_A_CT.bam" > "${subdir}/${sample}_${exp}_200689ACT_row_count.tsv"
    samtools index "${subdir}/${sample}_${exp}_200689_A_CT.bam" "${subdir}/${sample}_${exp}_200689_A_CT.bai"
    samtools merge -f "${subdir}/${sample}_${exp}_200689_A_CT_G.bam" "${subdir}/${sample}_${exp}_200689_A_CT.bam" "${subdir}/${sample}_${exp}_200689_G.bam"
    samtools view -c "${subdir}/${sample}_${exp}_200689_A_CT_G.bam" > "${subdir}/${sample}_${exp}_200689ACTG_row_count.tsv"
    samtools index "${subdir}/${sample}_${exp}_200689_A_CT_G.bam" "${subdir}/${sample}_${exp}_200689_A_CT_G.bai"
    
    ### Assesing IGVtools for Del and Ins ###
    
    # Extract base scores usign bcftools
    ref_fasta="${MYREF}/RG_PMV_v9_CHRIII.fasta"

    # Define the path to igvtools
    bam_file_igv_A_CT="${subdir}/${sample}_${exp}_200689_A_CT.bam"
    bam_file_igv_A_CT_G="${subdir}/${sample}_${exp}_200689_A_CT_G.bam"
    bam_file_igv_A_200753_T="${subdir}/${sample}_${exp}_200689_A_200753_T.bam"
    bam_file_igv_A_200753_C="${subdir}/${sample}_${exp}_200689_A_200753_C.bam"
    bam_file_igv_G="${subdir}/${sample}_${exp}_200689_G.bam"
    ref_fasta="${MYREF}/RG_PMV_v9_CHRIII.fasta"

    # Create a loop to assess 200689  ACTG, ATG, A_T, A_C or G polymorphisms
      ### Assesisng IGVtools - Del and Ins ###
      for poly in A_CT A_CT_G A_200753_T A_200753_C G ; do
        wig_output="${subdir}/${sample}_${exp}_200689_${poly}.wig"
        var_name="bam_file_igv_${poly}"
        bam_file="${!var_name}" # indirect expansion
      
        # Run igvtools to generate the WIG file
        igvtools count -w 1 --bases --query CHRIII:200743-200762 "$bam_file" "$wig_output" "$ref_fasta"


        ### Assesing nucleotide variants by BCFtools ###

        tsv_output_BCF="${subdir}/${sample}_${exp}_${poly}_BCF.tsv"
        bam_file="${subdir}/${sample}_${exp}_200689_${poly}.bam"      
        vcf_file="${subdir}/${sample}_${exp}_${poly}_variants.vcf.gz"

        # Variant calling
        bcftools mpileup -Ou -f "$ref_fasta" -r CHRIII:200742-200762 "$bam_file" | \
        bcftools call -mA --ploidy 1 -Oz -o "$vcf_file"
        bcftools index "$vcf_file"

        # Fill in missing INFO tags like AF, AN, AC
        vcf_with_af="${vcf_file%.vcf.gz}_with_AF.vcf.gz"
        bcftools +fill-tags "$vcf_file" -Oz -o "$vcf_with_af" -- -t AF,AN,AC
        bcftools index "$vcf_with_af"

        # Extract the region and required fields
        filtered_vcf="${vcf_with_af%.vcf.gz}.filtered.vcf"
        bcftools view -r CHRIII:200743-200762 "$vcf_with_af" > "$filtered_vcf"
        bcftools query -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP\t%INFO/DP4\n' "$vcf_file" | \
        awk 'BEGIN { OFS="\t" }
        {
            split($6, dp4, ",");
            ref_count = dp4[1] + dp4[2];
            alt_count = dp4[3] + dp4[4];
            total = ref_count + alt_count;
            af = (total == 0) ? 0 : int((alt_count / total) * 100);
            print $1, $2, $3, $4, $5, af
        }' > "$tsv_output_BCF"

        find "$MYWD" -type f \( -name "*.vcf" -o -name "*.vcf.gz" -o -name "*.csi" \) -exec rm {} + # BCF intermediate files
         done
    done
  done
done


### Calculate repair pathway frequency
# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      wd_dir="${MYWD}"
      
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Plotting repair_pathway for ${strain}" >> "$log_file"
        
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        export WD_DIR="$wd_dir"
        
        Rscript - <<'EOF'
        # Script to calculate repair pathaway %
        # load libraries

        library(ggplot2)
        library(extrafont)
        library(svglite)
        library(purrr)
        library(stringr)
        library(readr)
        library(tidyverse, warn.conflicts = FALSE)
        library(tidyr, warn.conflicts = FALSE)
        library(dplyr, warn.conflicts = FALSE)
        options(dplyr.summarise.inform = FALSE)

        # Read environment variables
        root_dir <- Sys.getenv("ROOT_DIR")
        wd_dir <- Sys.getenv("WD_DIR")
        strain <- Sys.getenv("STRAIN")
        strain <- sub("/$", "", strain)  # Remove trailing slash
        strain_name <- basename(strain)

        

        print(paste("ROOT_DIR:", root_dir))

        log_step <- function(message) {
        timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
        message(sprintf("[%s] %s", timestamp, message))
        }

        # Define a function to process tsv files
        process_nucleotide_row_count_files <- function(file_path) {
        # Extract filename and directory parts
        file_base <- basename(file_path)
        strain_name <- basename(dirname(file_path))  # directory name above the file
        
        # 
        parts <- str_split(file_base, "_", simplify = TRUE)
        
        # Validate and extract parts safely
        if (ncol(parts) >= 3) {
            sample_name <- parts[1]
            experiment_name <- parts[2]
            nucleotide_name <- parts[3]
        } else {
            warning(paste("Filename does not match expected format:", file_base))
            return(NULL)
        }
        
        # Read file
        temp_file <- read_tsv(file_path, col_names = FALSE, show_col_types = FALSE)
        
        # Skip if empty
        if (nrow(temp_file) == 0) {
            return(NULL)
        }
        
        # Prepare nucleotide_count df
        nucleotide_count_file <- temp_file %>%
            rename("nucleotide_count" = !!names(.[1])) %>%
            mutate(
            strain = strain_name,
            sample = sample_name,
            experiment = experiment_name,
            nucleotide = nucleotide_name
            )
        
        return(nucleotide_count_file)
        }



        log_step("Finding nucleotide row count files...")
        # Get all nucleotide row count files recursively in root folder
        nucleotide_row_count_files <- list.files(
        path = root_dir,
        pattern = "row_count\\.tsv$",
        recursive = TRUE,
        full.names = TRUE
        )





        log_step("Processing nucleotide row count files...")
        nucleotide_processed_df <- purrr::map_dfr(nucleotide_row_count_files, process_nucleotide_row_count_files)
        nucleotide_processed_df <- nucleotide_processed_df %>% 
        mutate(repair_pathway = ifelse(nucleotide == "200689AC", "NHEJ", 
                                        ifelse(nucleotide == "200689ACT", "shHR+NHEJ", 
                                                ifelse(nucleotide == "200689ACTG", "all", 
                                                    ifelse(nucleotide == "200689AT", "shHR", 
                                                            ifelse(nucleotide == "200689G", "lHR", "-"))))))

        nucleotide_processed_df_all <- nucleotide_processed_df %>% filter(repair_pathway == "all") %>% 
        mutate(nucleotide_count_all = nucleotide_count) %>% 
        select(strain, sample, experiment, nucleotide_count_all)


        nucleotide_processed_df_ratio <- left_join(nucleotide_processed_df, nucleotide_processed_df_all) %>% 
        mutate(nucleotide_count_ratio = nucleotide_count / nucleotide_count_all) %>% 
        filter(repair_pathway %in% c("NHEJ", "shHR", "lHR")) 

       


        nucleotide_processed_df_ratio_T0 <- nucleotide_processed_df_ratio %>% 
        filter(sample == "T0" & repair_pathway == "lHR") %>% 
        mutate(nucleotide_count_ratio_T0 = nucleotide_count_ratio) %>% 
        select(strain, experiment, nucleotide_count_ratio_T0)


        nucleotide_processed_df_ratio_lHR <- nucleotide_processed_df_ratio %>% 
        filter(sample == "TLG" & repair_pathway == "lHR") %>% 
        left_join(., nucleotide_processed_df_ratio_T0) %>% 
        mutate(nucleotide_count_ratio_repair_V = 2*(nucleotide_count_ratio - nucleotide_count_ratio_T0)) %>% 
        select(strain, sample, experiment, nucleotide, repair_pathway, nucleotide_count_ratio_repair_V) %>% 
        rename("nucleotide_count_ratio" = !!names(.[6]))

        nucleotide_processed_df_ratio_NHEJ <- nucleotide_processed_df_ratio %>% 
        filter(sample == "TLG" & repair_pathway == "NHEJ") %>% 
        select(strain, sample, experiment, nucleotide, repair_pathway, nucleotide_count_ratio) 

        nucleotide_processed_df_ratio_shHR <- nucleotide_processed_df_ratio %>% 
        filter(sample == "TLG" & repair_pathway == "shHR") %>% 
        select(strain, sample, experiment, nucleotide, repair_pathway, nucleotide_count_ratio) 

        nucleotide_processed_df_ratio_repair <- bind_rows(nucleotide_processed_df_ratio_lHR, nucleotide_processed_df_ratio_shHR) %>% 
        bind_rows(., nucleotide_processed_df_ratio_NHEJ)




        write_tsv(nucleotide_processed_df_ratio, file.path(root_dir, paste0(strain_name, "_repair_pathway_df.tsv")))
        write_tsv(nucleotide_processed_df_ratio_repair, file.path(root_dir, paste0(strain_name, "_repair_pathway_only_repair_df.tsv")))


        nucleotide_processed_df_ratio_summary <- nucleotide_processed_df_ratio %>% 
        group_by(strain, sample, nucleotide, repair_pathway) %>% 
        summarise(mean_ratio = mean(nucleotide_count_ratio, na.rm = TRUE), 
                    sd_ratio = sd(nucleotide_count_ratio, na.rm = TRUE))


        nucleotide_processed_df_ratio_repair_summary <- nucleotide_processed_df_ratio_repair %>% 
        group_by(strain, sample, nucleotide, repair_pathway) %>% 
        summarise(mean_ratio = mean(nucleotide_count_ratio, na.rm = TRUE), 
                    sd_ratio = sd(nucleotide_count_ratio, na.rm = TRUE))

        
        nucleotide_processed_df_ratio_repair_fraction_summary <- nucleotide_processed_df_ratio_repair %>% 
        group_by(strain, sample, experiment) %>% 
        summarise(sum_ratio = sum(nucleotide_count_ratio, na.rm = TRUE)) %>%  
        summarise(mean_ratio = mean(sum_ratio, na.rm = TRUE), 
                    sd_ratio = sd(sum_ratio, na.rm = TRUE))





        write_tsv(nucleotide_processed_df_ratio_summary, file.path(root_dir, paste0(strain_name, "_repair_pathway_summary.tsv")))
        write_tsv(nucleotide_processed_df_ratio_repair_summary, file.path(root_dir, paste0(strain_name, "_repair_pathway_only_repair_summary.tsv")))
        write_tsv(nucleotide_processed_df_ratio_repair_fraction_summary, file.path(root_dir, paste0(strain_name, "_repair_pathway_only_repair_fraction_summary.tsv")))

        log_step("Preparing plot data...")
        samples_order <- c("T0", "TLG", "TLR")
        repair_pathway_order <- c("NHEJ", "shHR", "lHR")

        nucleotide_processed_df_ratio_summary_graphs <- nucleotide_processed_df_ratio_summary %>% 
        mutate(sample = factor(sample, levels = samples_order),
                repair_pathway = factor(repair_pathway, levels = repair_pathway_order)) 


        nucleotide_processed_df_ratio_repair_summary_graphs <- nucleotide_processed_df_ratio_repair_summary %>% 
        mutate(repair_pathway = factor(repair_pathway, levels = repair_pathway_order)) 

        log_step("Plotting...")
        # Generate plots

        bar_plot <- ggplot(nucleotide_processed_df_ratio_summary_graphs, aes(x = sample, y = mean_ratio, fill = repair_pathway)) +
        geom_col(position = "dodge2") +
        geom_errorbar(aes(ymin = mean_ratio - sd_ratio, ymax = mean_ratio + sd_ratio), 
                        linewidth = 0.8, width = 0.2, colour = "gray10", position = position_dodge(width = 0.9)) +
        scale_fill_manual(values=c("gold","dodgerblue", "purple3")) +
        theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                        panel.background = element_blank(), 
                                                        plot.background = element_rect(fill = "transparent", colour = NA)) +
        theme(legend.position="right") +  
        coord_cartesian(expand=FALSE) +
        coord_cartesian(ylim = c(0, 1), expand=FALSE) +
        theme(aspect.ratio = 0.75) + 
        scale_x_discrete(name = expression("Sample")) +
        scale_y_continuous(name = expression("Fraction"),
                            #limits = c(0, 1),
                            breaks = seq(0,1,0.2)) +
        theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                axis.title.y = element_text(vjust = 1, size = 25)) + 
        theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 20, angle = 0), 
                axis.text.y = element_text(vjust = 0, size = 20)) +
        labs(
            title = paste0("Repair_pathway - ", strain_name)
        )

        ggsave(
        filename = paste0(strain,"/", "Repair_pathway_plot_", strain_name, ".svg"),
        plot = bar_plot,
        #width = 8,
        #height = 3.6,
        device = svglite,
        bg = "transparent"
        )


        log_step("Plotting...")
        bar_plot <- ggplot(nucleotide_processed_df_ratio_repair_summary_graphs, aes(x = sample, y = mean_ratio, fill = repair_pathway)) +
        geom_col(position = "dodge2") +
        geom_errorbar(aes(ymin = mean_ratio - sd_ratio, ymax = mean_ratio + sd_ratio), 
                        linewidth = 0.8, width = 0.2, colour = "gray10", position = position_dodge(width = 0.9)) +
        scale_fill_manual(values=c("gold","dodgerblue", "purple3")) +
        theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                        panel.background = element_blank(), 
                                                        plot.background = element_rect(fill = "transparent", colour = NA)) +
        theme(legend.position="right") +  
        coord_cartesian(expand=FALSE) +
        coord_cartesian(ylim = c(0, 1), expand=FALSE) +
        theme(aspect.ratio = 0.75) + 
        scale_x_discrete(name = expression("Sample")) +
        scale_y_continuous(name = expression("Fraction"),
                            #limits = c(0, 1),
                            breaks = seq(0,1,0.2)) +
        theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                axis.title.y = element_text(vjust = 1, size = 25)) + 
        theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 20, angle = 0), 
                axis.text.y = element_text(vjust = 0, size = 20)) +
        labs(
            title = paste0("Repair_pathway - repair - ", strain_name)
        )

        ggsave(
        filename = paste0(strain,"/", "Repair_pathway_only_repair_plot_", strain_name, ".svg"),
        plot = bar_plot,
        #width = 8,
        #height = 3.6,
        device = svglite,
        bg = "transparent"
        )



        # Calculate % of each nucleotide
        # Define a function to process wig files
        process_wig_files <- function(file_path) {
        # Extract filename and directory parts
        file_base <- basename(file_path)
        strain_name <- basename(dirname(file_path))  
        
        # Remove extension
        file_no_ext <- str_remove(file_base, "\\.wig$")
        
        # Extract sample and experiment
        
        parts <- str_split(file_no_ext, "_", simplify = TRUE)
        
        if (ncol(parts) < 2) {
            warning(paste("Filename does not match expected format:", file_base))
            return(NULL)
        }
        
        sample_name <- parts[1]
        experiment_name <- parts[2]  
        
        # Extract everything after experiment (E1_, E2_, E3_)
        nucleotide_name <- str_remove(file_no_ext, paste0("^", sample_name, "_", experiment_name, "_"))
        
        # ---- Read the file ----
        all_lines <- readLines(file_path)
        data_lines <- all_lines[!grepl("^(track|#|variableStep)", all_lines)]
        
        if (length(data_lines) == 0) {
            return(NULL)
        }
        
        wig_df <- read_tsv(
            I(data_lines),
            col_names = c("Pos", "A", "C", "G", "T", "N", "DEL", "INS"),
            show_col_types = FALSE
        )
        
        if (nrow(wig_df) == 0) {
            return(NULL)
        }
        
        # ---- Add metadata ----
        wig_df <- wig_df %>%
            mutate(
            strain = strain_name,
            sample = sample_name,
            experiment = experiment_name,
            nucleotide = nucleotide_name
            )
        
        return(wig_df)
        }



        log_step("Finding wig files...")
        # Get all wig files recursively in root folder
        wig_files <- list.files(
        path = root_dir,
        pattern = "\\.wig$",
        recursive = TRUE,
        full.names = TRUE
        )


        wig_processed_df <- purrr::map_dfr(wig_files, process_wig_files)

        wig_processed_df <- wig_processed_df %>% 
        mutate(repair_pathway = ifelse(nucleotide == "200689_A_200753_C", "NHEJ", 
                                        ifelse(nucleotide == "200689_A_CT", "shHR+NHEJ", 
                                                ifelse(nucleotide == "200689_A_CT_G", "all", 
                                                    ifelse(nucleotide == "200689_A_200753_T", "shHR", 
                                                            ifelse(nucleotide == "200689_G", "lHR", "-"))))))


        wig_processed_df_percent <- wig_processed_df %>% 
        pivot_longer(cols = c(A, C, T, G, N, DEL, INS),
                    names_to = "mutation",
                    values_to = "mutation_count") %>% 
        group_by(Pos, strain, sample, experiment, nucleotide, repair_pathway) %>%
        mutate(
            total_count = sum(mutation_count),
            perc_mutation = (mutation_count / total_count) * 100
        ) %>%
        ungroup() 

        write_tsv(wig_processed_df_percent, file.path(root_dir, paste0( "/",strain_name,  "_mutation_wig_percentage_df.tsv")))


        wig_processed_df_percent_summary <- wig_processed_df_percent %>% 
        group_by(Pos, strain, sample, nucleotide, repair_pathway, mutation) %>% 
        summarise(mean_percentage = mean(perc_mutation, na.rm = TRUE), 
                    sd_percentage = sd(perc_mutation, na.rm = TRUE)) %>% 
        ungroup() %>% 
        filter(mutation != "N")

        write_tsv(wig_processed_df_percent_summary, file.path(root_dir, paste0("/",strain_name, "_mutation_wig_percentage_summary.tsv")))


        # Calculate % of AF
        # Define a function to process BCF files
        process_bcf_files <- function(file_path) {
        # Extract filename and directory parts
        file_base <- basename(file_path)
        strain_name <- basename(dirname(file_path))  
        
        # Remove extension
        file_no_ext <- str_remove(file_base, "_BCF\\.tsv$")
        
        # Extract sample and experiment
        
        parts <- str_split(file_no_ext, "_", simplify = TRUE)
        
        if (ncol(parts) < 2) {
            warning(paste("Filename does not match expected format:", file_base))
            return(NULL)
        }
        
        sample_name <- parts[1]
        experiment_name <- parts[2]  
        
        # Extract everything after experiment (E1_, E2_, E3_)
        nucleotide_name <- str_remove(file_no_ext, paste0("^", sample_name, "_", experiment_name, "_"))
        
        # ---- Read the file ----
        all_lines <- readLines(file_path)
        data_lines <- all_lines[!grepl("^(track|#|variableStep)", all_lines)]
        
        if (length(data_lines) == 0) {
            return(NULL)
        }
        
        bcf_df <- read_tsv(
            I(data_lines),
            col_select = c(X2, X6),
            col_names = FALSE,
            show_col_types = FALSE
        )
        
        if (nrow(bcf_df) == 0) {
            return(NULL)
        }
        
        # ---- Add metadata ----
        bcf_df <- bcf_df %>%
            mutate(
            strain = strain_name,
            sample = sample_name,
            experiment = experiment_name,
            nucleotide = nucleotide_name
            ) %>% 
            rename("Pos" = !!names(.[1]), "AF_perc" = !!names(.[2]))
        
        return(bcf_df)
        }



        log_step("Finding bcf files...")
        # Get all BCFv files recursively in root folder
        bcf_files <- list.files(
        path = root_dir,
        pattern = "\\BCF.tsv",
        recursive = TRUE,
        full.names = TRUE
        )


        bcf_processed_df <- purrr::map_dfr(bcf_files, process_bcf_files) 
        

        bcf_processed_df <- bcf_processed_df %>% 
        mutate(repair_pathway = ifelse(nucleotide == "A_200753_C", "NHEJ", 
                                        ifelse(nucleotide == "A_CT", "shHR+NHEJ", 
                                                ifelse(nucleotide == "A_CT_G", "all", 
                                                    ifelse(nucleotide == "A_200753_T", "shHR", 
                                                            ifelse(nucleotide == "G", "lHR", "-")))))) %>% 
        mutate(mutation = "AF")


        bcf_processed_df_percent_summary <- bcf_processed_df %>% 
        group_by(Pos, strain, sample, nucleotide, mutation, repair_pathway) %>%
        summarise(mean_percentage = mean(AF_perc, na.rm = TRUE), 
                    sd_percentage = sd(AF_perc, na.rm = TRUE)) %>% 
        ungroup() 

        write_tsv(bcf_processed_df, file.path(root_dir, paste0(strain_name, "_mutation_bcf_percentage_df.tsv")))
        write_tsv(bcf_processed_df_percent_summary, file.path(root_dir, paste0(strain_name, "_mutation_bcf_percentage_summary.tsv")))

        wig_processed_df_percent_summary_plots <- wig_processed_df_percent_summary %>% 
        select(c(Pos,strain, sample, repair_pathway, mutation, mean_percentage, sd_percentage))

        bcf_processed_df_summary_plots <- bcf_processed_df_percent_summary %>% 
        select(c(Pos,strain, sample, repair_pathway, mutation, mean_percentage, sd_percentage))


        wig_bcf_combined_summary <- bind_rows(wig_processed_df_percent_summary_plots, bcf_processed_df_summary_plots) %>% 
        select(Pos,strain, sample, repair_pathway, mutation, mean_percentage, sd_percentage) %>% 
        filter(mutation != "N") 

        write_tsv(wig_bcf_combined_summary, file.path(root_dir, paste0("/",strain_name, "_mutation_wig_bcf_percentage_summary.tsv")))
        


        

        mutation_order <- rev(c("A", "C", "G", "T", "AF", "DEL", "INS"))

        wig_bcf_plot_df <- wig_bcf_combined_summary %>% 
        mutate(rel_pos = Pos - 200753) %>% 
        mutate(mutation = factor(mutation, levels = mutation_order))
        


        
        log_step("Plotting heatmaps...")

        wig_bcf_plot_df %>%
        group_split(repair_pathway, sample) %>%
        purrr::imap(function(df, i) {
            rp <- unique(df$repair_pathway)
            sm <- unique(df$sample)
            
            p <- ggplot(df, aes(x = rel_pos, y = mutation, fill = mean_percentage)) +
            geom_tile(color = "white", linewidth = 0.4) +
            geom_hline(yintercept = seq(0.5, length(unique(df$mutation)) + 0.5, by = 1),
                        color = "black", linewidth = 0.2) +
            geom_vline(xintercept = seq(-11.5, 9.5, by = 1),
                        color = "black", linewidth = 0.2) +
            scale_x_continuous(breaks = seq(-11, 9, by = 1), expand = c(0, 0)) +
            scale_fill_gradientn(
                colors = rev(c("#AF2418", "#E1AC40", "#EFD24D",
                                        "#5D8B27", "#4EACE9", "#4573A1", "white")),
                                        values = scales::rescale(c(0, 25, 50, 75, 100)),
                na.value = "gray90",
                name = "Normalized Coverage",
                limits = c(0, 100),
                oob = scales::squish
            ) +
            theme_minimal(base_size = 14) +
            labs(
                title = paste0(rp, " - ", sm, " - ", strain_name),
                x = "Genomic position",
                y = "Base/Indel"
            )
            #ggtitle(paste("Repair pathway:", rp, "| Sample:", sm)) +
            
            
            ggsave(
            filename = paste0(strain,"/", "Repair_heatmap_plot_",rp, "_", sm, "_", strain_name, ".svg"),
            plot = p,
            width = 8,
            height = 3,
            device = svglite,
            bg = "transparent"
            )
            
        })

        log_step("Plotting DNA logos...")

        library(ggseqlogo)

        wig_bcf_plot_df_logo <- wig_bcf_plot_df %>% 
        select(strain, sample, repair_pathway, mutation, mean_percentage, rel_pos) %>% 
        filter(mutation %in% c("A", "C", "T", "G")) %>%
        filter(sample == "TLG")

        cs1 = make_col_scheme(chars=c('C', 'A', 'G', 'T'), 
                            cols=c('#355C95', '#459450', '#ECB74B', '#C53940'))



        wig_bcf_plot_df_logo%>%
        group_split(repair_pathway, sample) %>%
        purrr::imap(function(df, i) {
            
            rp <- unique(df$repair_pathway)
            sm <- unique(df$sample)
            
            
            matrix <- df %>%
            mutate(freq = mean_percentage / 100) %>%        
            select(rel_pos, mutation, freq) %>%
            pivot_wider(names_from = rel_pos, values_from = freq) %>%
            column_to_rownames("mutation") %>%
            as.matrix()
            
            # ensure nucleotide order is standard A,C,G,T if needed
            matrix <- matrix[c("A", "C", "G", "T"), , drop = FALSE]
            
            # make the ggseqlogo plot
            p <- ggseqlogo(matrix, method = "custom", seq_type='dna',
                        stack_width = 0.9, font = "helvetica_regular", col_scheme=cs1) +
            theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank()) +
            ggtitle(paste0(rp, " - ", sm, " - ", strain_name)) +
            theme(aspect.ratio = 0.3) + 
            theme(
                plot.title = element_text(hjust = 0.5),
                panel.grid = element_blank()
            ) +
            xlab("Genomic position") +
            ylab("Freq") +
            scale_x_continuous(
                breaks = seq_along(colnames(matrix)),
                labels = colnames(matrix)
            )
            ggsave(
            filename = paste0(strain,"/", "Repair_logo_plot_",rp, "_", sm, "_", strain_name, ".svg"),
            plot = p,
            width = 8,
            height = 3,
            device = svglite,
            bg = "transparent"
            )
            
            
        })

        #### Mutagenic rate

        wig_processed_df_percent_mut_rate <- wig_processed_df_percent %>% 
        select(Pos, strain, sample, experiment, repair_pathway, mutation, perc_mutation) %>% 
        filter(mutation %in% c("DEL", "INS")) %>% 
        filter(Pos != 200753) %>% 
        group_by(strain, sample, experiment, repair_pathway, mutation) %>% 
        summarise(mean_mut_rate = mean(perc_mutation))


        bcf_processed_df_mut_rate <- bcf_processed_df %>% 
        select(Pos, strain, sample, experiment, repair_pathway, mutation, AF_perc) %>% 
        mutate(perc_mutation = AF_perc) %>% 
        select(Pos, strain, sample, experiment, repair_pathway, mutation, perc_mutation) %>% 
        filter(mutation == "AF") %>% 
        filter(Pos != 200753) %>% 
        group_by(strain, sample, experiment, repair_pathway, mutation) %>% 
        summarise(mean_mut_rate = mean(perc_mutation))



        wig_bcf_combined_summary_mut_rate <- bind_rows(wig_processed_df_percent_mut_rate, 
                                                    bcf_processed_df_mut_rate) %>% 
        filter(sample == "TLG") %>% 
        group_by(strain, sample, repair_pathway, mutation) %>% 
        summarise(mean_mut_rate_global = mean(mean_mut_rate),
                    sd_mut_rate_global = sd(mean_mut_rate))

        write_tsv( wig_bcf_combined_summary_mut_rate, file.path(root_dir, paste0("/",strain_name, "_mutation_wig_bcf_mut_rate_summary.tsv")))


        mutation_order_plot <- c("AF", "DEL", "INS")

        wig_bcf_combined_summary_mut_rate <- wig_bcf_combined_summary_mut_rate %>% 
        mutate(mutation = factor(mutation, levels = mutation_order_plot))



        wig_bcf_combined_summary_mut_rate %>% 
        group_split(repair_pathway, sample) %>%
        purrr::imap(function(df, i) {
            rp <- unique(df$repair_pathway)
            sm <- unique(df$sample)
            
            p <- ggplot(df, aes(x = strain, y = mean_mut_rate_global, fill = mutation)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = mean_mut_rate_global - sd_mut_rate_global, ymax = mean_mut_rate_global + sd_mut_rate_global), 
                            linewidth = 0.8, width = 0.2, colour = "gray10", position = position_dodge(width = 0.9)) +
            scale_fill_manual(values=c("gold", "dodgerblue", "purple3")) +
            theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(expand=FALSE) +
            coord_cartesian(ylim = c(0, 10), expand=FALSE) +
            theme(aspect.ratio = 0.7) + 
            scale_x_discrete(name = expression("Strain")) +
            scale_y_continuous(name = expression("Percentage"),
                                #limits = c(0, 1),
                                breaks = seq(0,10,2)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                    axis.title.y = element_text(vjust = 1, size = 25)) + 
            theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 15, angle = 0), 
                    axis.text.y = element_text(vjust = 0, size = 20)) +
            labs(
                title = paste0(rp, " - ", sm, " - ", strain_name)
            )
            
            ggsave(
            filename = paste0(strain,"/", "Mutagenic_rate_plot_",rp, "_", sm, "_", strain_name, ".svg"),
            plot = p,
            #width = 8,
            #height = 3,
            device = svglite,
            bg = "transparent"
            )

        })

        
EOF
done




# Process all files in the MYWD directory
  echo "Processing directory: ${MYWD}" >> "$log_file"
      root_dir="${MYWD}"
      wd_dir="${MYWD}"
      
        echo "Plotting repair_pathway comparison" >> "$log_file"
        start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export WD_DIR="$wd_dir"
        
        Rscript - <<'EOF'

        library(ggplot2)
        library(extrafont)
        library(svglite)
        library(purrr)
        library(stringr)
        library(readr)
        library(tidyverse, warn.conflicts = FALSE)
        library(tidyr, warn.conflicts = FALSE)
        library(dplyr, warn.conflicts = FALSE)
        options(dplyr.summarise.inform = FALSE)

        # Read environment variables
        root_dir <- Sys.getenv("ROOT_DIR")
        wd_dir <- Sys.getenv("WD_DIR")
        

        print(paste("ROOT_DIR:", root_dir))

        log_step <- function(message) {
        timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
        message(sprintf("[%s] %s", timestamp, message))
        }

        ## Find all. repair_pathway_only_repair_summary.tsv files
        # Define a function to process tsv files
        process_repair_pathway_only_repair_summary_files <- function(file_path) {
        
        # Read file
        temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
        
        # Skip if empty
        if (nrow(temp_file) == 0) {
            return(NULL)
        }
        
        # Prepare concordant dataframe
        repair_pathway_only_repair_summary_file <- temp_file 
        
        return(repair_pathway_only_repair_summary_file)
        }


        log_step("Finding repair_pathway_only_repair_summary files...")
        # Get all repair_pathway_only_repair_summary.tsv files recursively in root folder
        repair_pathway_only_repair_summary_files <- list.files(
        path = root_dir,
        pattern = "repair_pathway_only_repair_summary\\.tsv$",
        recursive = TRUE,
        full.names = TRUE
        )


        repair_pathway_only_repair_summary_all_processed_df <- purrr::map_dfr(repair_pathway_only_repair_summary_files, 
                                                                            process_repair_pathway_only_repair_summary_files) 

        samples_order <- c("T0", "TLG", "TLR")
        repair_pathway_order <- c("NHEJ", "shHR", "lHR")



        repair_pathway_only_repair_summary_all_processed_df_plots <- repair_pathway_only_repair_summary_all_processed_df %>% 
        mutate(repair_pathway = factor(repair_pathway, levels= repair_pathway_order))


        bar_plot <- ggplot(repair_pathway_only_repair_summary_all_processed_df_plots, aes(x = strain, y = mean_ratio, fill = repair_pathway)) +
        geom_col(position = "dodge2") +
        geom_errorbar(aes(ymin = mean_ratio - sd_ratio, ymax = mean_ratio + sd_ratio), 
                        linewidth = 0.8, width = 0.2, colour = "gray10", position = position_dodge(width = 0.9)) +
        scale_fill_manual(values=c("gold","dodgerblue", "purple3")) +
        theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                        panel.background = element_blank(), 
                                                        plot.background = element_rect(fill = "transparent", colour = NA)) +
        theme(legend.position="right") +  
        coord_cartesian(expand=FALSE) +
        coord_cartesian(ylim = c(0, 1), expand=FALSE) +
        theme(aspect.ratio = 0.7) + 
        scale_x_discrete(name = expression("Strain")) +
        scale_y_continuous(name = expression("Fraction"),
                            #limits = c(0, 1),
                            breaks = seq(0,1,0.2)) +
        theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                axis.title.y = element_text(vjust = 1, size = 25)) + 
        theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 15, angle = 0), 
                axis.text.y = element_text(vjust = 0, size = 20)) +
        labs(
            title = paste0("Repair_pathway - comparison")
        )

        ggsave(
        filename = paste0(root_dir, "/", "Repair_pathway_plot_comparison", ".svg"),
        plot = bar_plot,
        #width = 8,
        #height = 3.6,
        device = svglite,
        bg = "transparent"
        )

        log_step("Finding repair_pathway_summary files...")
        # Get all repair_pathway_only_repair_summary.tsv files recursively in root folder
        repair_pathway_summary_files <- list.files(
        path = root_dir,
        pattern = "repair_pathway_summary\\.tsv$",
        recursive = TRUE,
        full.names = TRUE
        )


        repair_pathway_summary_all_processed_df <- purrr::map_dfr(repair_pathway_summary_files, 
                                                                            process_repair_pathway_only_repair_summary_files) 




        repair_pathway_summary_all_processed_df_plots <- repair_pathway_summary_all_processed_df %>% 
        mutate(repair_pathway = factor(repair_pathway, levels= repair_pathway_order),
                sample = factor(sample, levels = samples_order))

        orden_plot <- tibble(position = c(1, 6, 11, 17, 22, 27, 33, 38, 43,
                                        2, 7, 12, 18, 23, 28, 34, 39, 44,
                                        3, 8, 13, 19, 24, 29, 35, 40, 45,
                                        4, 9, 14, 20, 25, 30, 36, 41, 46,
                                        5, 10, 15, 21, 26, 31, 37, 42, 47))

        repair_pathway_summary_all_processed_df_plots <- bind_cols(repair_pathway_summary_all_processed_df_plots, orden_plot)


        bar_plot <- ggplot(repair_pathway_summary_all_processed_df_plots, aes(x = position, y = mean_ratio, fill = repair_pathway)) +
        geom_col(position = "dodge2") +
        geom_errorbar(aes(ymin = mean_ratio - sd_ratio, ymax = mean_ratio + sd_ratio),
                        linewidth = 0.8, width = 0.4, colour = "gray10", position = position_dodge(width = 0.9)) +
        scale_fill_manual(values=c("gold","dodgerblue", "purple3")) +
        theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                        panel.background = element_blank(), 
                                                        plot.background = element_rect(fill = "transparent", colour = NA)) +
        theme(legend.position="right") +  
        coord_cartesian(expand=FALSE) +
        coord_cartesian(ylim = c(0, 1), expand=FALSE) +
        theme(aspect.ratio = 1) + 
        scale_x_discrete(name = expression("Sample")) +
        scale_y_continuous(name = expression("Fraction"),
                            #limits = c(0, 1),
                            breaks = seq(0,1,0.2)) +
        theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                axis.title.y = element_text(vjust = 1, size = 25)) + 
        theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 15, angle = 0), 
                axis.text.y = element_text(vjust = 0, size = 20)) +
        labs(
            title = paste0("Repair_pathway - comparison")
        )

        ggsave(
        filename = paste0(root_dir, "/", "Repair_pathway_all_timepoints_plot_comparison", ".svg"),
        plot = bar_plot,
        #width = 8,
        #height = 3.6,
        device = svglite,
        bg = "transparent"
        )


        ## Find all mutation_wig_bcf_mut_rate_summary.tsv files
        # Define a function to process tsv files
        process_mutation_wig_bcf_mut_rate_summary_files <- function(file_path) {
        
        # Read file
        temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
        
        # Skip if empty
        if (nrow(temp_file) == 0) {
            return(NULL)
        }
        
        # Prepare concordant dataframe
        mutation_wig_bcf_mut_rate_summary_file <- temp_file 
        
        return(mutation_wig_bcf_mut_rate_summary_file)
        }


        log_step("Finding mutation_wig_bcf_mut_rate_summary files...")
        # Get all mutation_wig_bcf_mut_rate_summary.tsv files recursively in root folder
        mutation_wig_bcf_mut_rate_summary_files <- list.files(
        path = root_dir,
        pattern = "mutation_wig_bcf_mut_rate_summary\\.tsv$",
        recursive = TRUE,
        full.names = TRUE
        )


        mutation_wig_bcf_mut_rate_summary_all_processed_df <- purrr::map_dfr(mutation_wig_bcf_mut_rate_summary_files, 
                                                                            process_mutation_wig_bcf_mut_rate_summary_files) %>% 
        filter(repair_pathway == "all")




        bar_plot <- ggplot(mutation_wig_bcf_mut_rate_summary_all_processed_df, aes(x = strain, y = mean_mut_rate_global, fill = mutation)) +
        geom_col(position = "dodge2") +
        geom_errorbar(aes(ymin = mean_mut_rate_global - sd_mut_rate_global, ymax = mean_mut_rate_global + sd_mut_rate_global), 
                        linewidth = 0.8, width = 0.2, colour = "gray10", position = position_dodge(width = 0.9)) +
        scale_fill_manual(values=c("gold", "dodgerblue", "purple3")) +
        theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                        panel.background = element_blank(), 
                                                        plot.background = element_rect(fill = "transparent", colour = NA)) +
        theme(legend.position="right") +  
        coord_cartesian(expand=FALSE) +
        coord_cartesian(ylim = c(0, 4), expand=FALSE) +
        theme(aspect.ratio = 0.7) + 
        scale_x_discrete(name = expression("Strain")) +
        scale_y_continuous(name = expression("Pecentage"),
                            #limits = c(0, 1),
                            breaks = seq(0,6,2)) +
        theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                axis.title.y = element_text(vjust = 1, size = 25)) + 
        theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 15, angle = 0), 
                axis.text.y = element_text(vjust = 0, size = 20)) +
        labs(
            title = paste0("Mutagenic rate - comparison")
        )

        ggsave(
        filename = paste0(root_dir, "/", "Mutagenic_rate_plot_comparison", ".svg"),
        plot = bar_plot,
        #width = 8,
        #height = 3.6,
        device = svglite,
        bg = "transparent"
        )

EOF


# Calculate total elapsed time
elapsed_time_total_mut=$((( SECONDS - start_time_total_mut )/60))
echo "Mutagenic Rate at HO Analysis completed in ${elapsed_time_total_mut} minutes" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line



# === ORGANIZING DATA ===

# Remove intermediate files
find "$MYWD" -type f \( -name "*_BFC.tsv" \) -exec rm {} + # BCF.tsv intermediate files

# Move data into subfolders
for subdir in "$MYWD"*/; do
  mkdir -p "${subdir}/HO_mut_rate/FASTQP" "${subdir}/HO_mut_rate/SVG" "${subdir}/HO_mut_rate/TSV"
  mv "${subdir}"/*.fastq.html "${subdir}/HO_mut_rate/FASTQP/" 2> /dev/null
  mv "${subdir}"/*.fastq.json "${subdir}/HO_mut_rate/FASTQP/" 2> /dev/null
  mv "${subdir}"/*.svg "${subdir}/HO_mut_rate/SVG/" 2> /dev/null
  mv "${subdir}"/*.tsv "${subdir}/HO_mut_rate/TSV/" 2> /dev/null
done

# Remove unecesary files
find "$MYREF" \( -name "*.amb" -o -name "*.ann" -o -name "*.bwt" -o -name "*.pac" -o -name "*.sa" -o -name "*.fai" \) -exec rm {} + # index files
find "$MYWD" -type f \( -name "*.bai" -o -name "*.bam" \) -exec rm {} + # intermediate alignmet files
find "$MYWD" -type f \( -name "*.vcf" -o -name "*.vcf.gz" -o -name "*.csi" \) -exec rm {} + # BCF intermediate files
find "$MYWD" -type f \( -name "*.wig" \) -exec rm {} + # WIG intermediate files



# Calculate total elapsed time
elapsed_time_total_mut=$((( SECONDS - start_time_total_mut )/60))
echo "HO Mutagenic Rate Analysis completed in ${elapsed_time_total_mut} minutes" >> "$log_file"
echo "" >> "$log_file"

# Calculate total script elapsed time
elapsed_time_total_script_1=$((( SECONDS - start_time_total_script )/60))
echo "=================================" >> "$log_file"
echo "CONCORDANT ANALYSIS - COMPLETED IN ${elapsed_time_total_script_1} MINUTES" >> "$log_file"
echo "" >> "$log_file"


# Bash script for the analysis of DNA repair mutants at short/long timepoints with 3 Experiments (E1, E2 and E3).
# This script combines an analysis of MATa-MATa' discordant reads pairs (using 18bp and 75 bp long reads) 
# and genome-wide inter-chromosomal discordant read pairs (using 75bp long reads).

# 75bp reads analysis:
# 150>75_rAB_Q30both_SR_-v0_-m1_PE_bowtie2 and inter-chromosomal_discordant_pairs processing 
# Both R1 and R2 align discordantly (inter-chromosomal discordant read pairs) and in -m 1 and -v 0 mode (in SR alignment with bowtie)
# Name reads as T0_E1_R1.fastq.gz, T0_E1_R2.fastq.gz, T0_E2_R1.fastq.gz, T0_E2_R2.fasatq.gz, etc, etc. and put them in the same directory.
# Uses RG_PMV_v9.fasta as reference genome.
# Set "experiment" as E1, E2 and E3; and "sample" as T0, TSG (TimeShortGal), TLG (TimeLongGal) and TLR (TimeLongRaf).
# This script processes paired-end fastq files, trims them to 75nt and adds _rA or _rB to read name after trimming,
# filters read pairs by read quality (minimum Q30 quality in each nt in both read of the same pair) 
# and aligns them as single-read to a reference genome using bowtie to select reads aligning in -m1 -v0 for both R1 and R2.
# Then aligns filtered read pairs to a reference genome using bowtie2.
# Processes .sam output to keep only inter-chromosomal discordant read pairs
# and filters valid reads using BLAST
# Reads are filtered for quality using fastp, Q30 quality per nucleotide and for all nt in the read.
# Uses cutadapt for trimming, bowtie and bowtie2 for alignment, and samtools and deeptools for post-processing.
# After R processing of SAM file to identify read-genomic_feature, read pairs are validated using BLAST
# for query sequence alignment against mate genomic feature database (and previous and post genomic features).
# Assumes that the input files are gzipped fastq files and that the reference genome is indexed with bowtie and bowtie2.

# 18bp reads analysis:
# 150>18_Q30both_SR_-v0_-m1_PE_bowtie2 and inter-chromosomal_discordant_pairs processing 
# Inter-chromosomal discordant read pairs are extracted from the same 150bp long read (pairs every 60bp to do polymorphism analysis)
# Both R1 and R2 align discordantly (inter-chromosomal discordant read pairs) and in -m 1 and -v 0 mode (in SR alignment with bowtie)
# Uses cutadapt for trimming, bowtie and bowtie2 for alignment, and samtools and deeptools for post-processing.
# Generates a log_file with the processing timings and a stat file with the alignment information.
# Only MATa-MATa' inter-chromosomal discordant analysis, only TLG sample
# CHRIII/CHRV_MATs (75nt) are not binned.


# Generates plots using R-ggplot and saves it as a svg file.





#################################

# shellcheck source=/opt/anaconda3/etc/profile.d/conda.sh
#source /home/ibfg/miniconda3/etc/profile.d/conda.sh

# Set conda environment
#conda activate env_genomics #changed from env_disc 


# Allocating directories
#MYREF=/home/ibfg/GWSL/RG
#MYWD=/home/ibfg/GWSL/WD/
#CATEGORY_PATH=/home/ibfg/GWSL/Categories 
#MYBLAST=/home/ibfg/GWSL/BLAST/features_extraction
#MYREPORT=/home/ibfg/GWSL/Report_files


# Create a log and stat file
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "DISCORDANT ANALYSIS - initiated at: \"$current_time\"" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line

# Start timer for the entire script processing
#start_time_total_script=$SECONDS
start_time_total_script_2=$SECONDS

########### MODULE CORE - START ###########
# ############## Alignment and processing of 75bp reads ############

# Start timer for the alignment and processing section
start_time_total_alignment=$SECONDS

# Index RG for bowtie alignment
bowtie-build "${MYREF}/RG_PMV_v9.fasta" "${MYREF}/S_cerevisiae_indexed"

# Index RG for bowtie2 alignment
bowtie2-build "${MYREF}/RG_PMV_v9.fasta" "${MYREF}/S_cerevisiae_indexed"

# Loop through each directory inside MYWD

echo "================================" >> "$log_file"
echo "### 75bp analysis ###" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
echo "### Alignments and SAM processing ###" >> "$log_file"
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Initiated at ${current_time}" >> "$log_file" 
echo "" >> "$log_file"  # Adds a blank line

for strain in "$MYWD"*/; do
  echo "Processing directory: $strain" >> "$log_file"

  # Loop through sample prefixes (T0, TSG, TLG, TLR.)
    for sample in T0 TSG TLG TLR; do
      for experiment in E1 E2 E3; do
        file1_gz="${strain}/${sample}_${experiment}_R1.fastq.gz"
        file2_gz="${strain}/${sample}_${experiment}_R2.fastq.gz"
       
        # Check if both compressed files exist
        if [[ -f "$file1_gz" && -f "$file2_gz" ]]; then
          echo "Processing files: $file1_gz, $file2_gz" >> "$log_file"
          echo "" >> "$log_file"  # Adds a blank line

          # Keep the current pair compressed for 18bp alignment
          gunzip -k "$file1_gz" "$file2_gz" # keep compressed
          

          if [[ -f "${strain}/${sample}_${experiment}_R1.fastq" && -f "${strain}/${sample}_${experiment}_R2.fastq" ]]; then
            # Determine the number of cores available
            N_CPU=$(nproc)

            # Start timers for total processing of a strain/sample/experiment
            start_time_total=$SECONDS
        
            # Trim reads using cutadapt
            echo "### $(basename "$strain")/${sample} ${experiment} ###" >> "$log_file"
            echo "" >> "$log_file"  # Adds a blank line
            start_time=$SECONDS
            # trim R1 reads
            cutadapt -j "$N_CPU" --cut -75 -o "${strain}/${sample}_${experiment}_R1_1.fastq" "${strain}/${sample}_${experiment}_R1.fastq"
            cutadapt -j "$N_CPU" --cut 75 -o "${strain}/${sample}_${experiment}_R1_2.fastq" "${strain}/${sample}_${experiment}_R1.fastq"
            # trim R2 reads
            cutadapt -j "$N_CPU" --cut -75 -o "${strain}/${sample}_${experiment}_R2_1.fastq" "${strain}/${sample}_${experiment}_R2.fastq"
            cutadapt -j "$N_CPU" --cut 75 -o "${strain}/${sample}_${experiment}_R2_2.fastq" "${strain}/${sample}_${experiment}_R2.fastq"

            # Remove intermediate 75nt fastq files
            rm "${strain}/${sample}_${experiment}_R1.fastq" "${strain}/${sample}_${experiment}_R2.fastq"

            # Rename them as _rA or _rB # Needs sed -E to rename reads matching V35 or E25
            sed -E '/^@(V35|E25)[a-zA-Z0-9].*\/1/s/\/1/rA\/1/' "${strain}/${sample}_${experiment}_R1_1.fastq" > "${strain}/${sample}_${experiment}_R1_1_A.fastq"
            sed -E '/^@(V35|E25)[a-zA-Z0-9].*\/2/s/\/2/rA\/2/' "${strain}/${sample}_${experiment}_R2_1.fastq" > "${strain}/${sample}_${experiment}_R2_1_A.fastq"
            sed -E '/^@(V35|E25)[a-zA-Z0-9].*\/1/s/\/1/rB\/1/' "${strain}/${sample}_${experiment}_R1_2.fastq" > "${strain}/${sample}_${experiment}_R1_2_B.fastq"
            sed -E '/^@(V35|E25)[a-zA-Z0-9].*\/2/s/\/2/rB\/2/' "${strain}/${sample}_${experiment}_R2_2.fastq" > "${strain}/${sample}_${experiment}_R2_2_B.fastq"

            # Cat _rA and _rB R1 files; and _rA and _rB R2 files
            cat "${strain}/${sample}_${experiment}_R1_1_A.fastq" "${strain}/${sample}_${experiment}_R1_2_B.fastq" > "${strain}/${sample}_${experiment}_r_R1.fastq"
            cat "${strain}/${sample}_${experiment}_R2_1_A.fastq" "${strain}/${sample}_${experiment}_R2_2_B.fastq" > "${strain}/${sample}_${experiment}_r_R2.fastq"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_R1_1.fastq" "${strain}/${sample}_${experiment}_R1_2.fastq" "${strain}/${sample}_${experiment}_R2_1.fastq" "${strain}/${sample}_${experiment}_R2_2.fastq"
            rm "${strain}/${sample}_${experiment}_R1_1_A.fastq" "${strain}/${sample}_${experiment}_R2_1_A.fastq" "${strain}/${sample}_${experiment}_R1_2_B.fastq" "${strain}/${sample}_${experiment}_R2_2_B.fastq"
                    
            # Filter 75nt reads Q30
            fastp \
              -i "${strain}/${sample}_${experiment}_r_R1.fastq" \
              -o "${strain}/${sample}_${experiment}_r_R1_filtered.fastq" \
              -I "${strain}/${sample}_${experiment}_r_R2.fastq" \
              -O "${strain}/${sample}_${experiment}_r_R2_filtered.fastq" \
              -q 30 -u 0 -e 30 \
              --thread "$N_CPU" \
              --html "${strain}/${sample}_${experiment}_75nt.fastq.html" \
              --json "${strain}/${sample}_${experiment}_75nt.fastq.json"
            
            # Remove intermediate 75nt fastq files
            rm "${strain}/${sample}_${experiment}_r_R1.fastq" "${strain}/${sample}_${experiment}_r_R2.fastq"
            
            elapsed_time=$(( SECONDS - start_time ))
            echo "Cutting and Filtering Reads completed in ${elapsed_time} seconds" >> "$log_file"
          
            # Bowtie mapping (SR -m1 -v0) for R1 filtered reads
            start_time=$SECONDS
            echo "### $(basename "$strain")/${sample} 75nt R1 ###" >> "$stats"
            echo "${experiment}" >> "$stats"
            bowtie -p "$N_CPU" -m 1 -v 0 -S "${MYREF}/S_cerevisiae_indexed" "${strain}/${sample}_${experiment}_r_R1_filtered.fastq" > "${strain}/${sample}_${experiment}_r_R1_filtered.sam" 2>> "$stats"
            echo "" >> "$stats"  # Adds a blank line
            elapsed_time=$(( SECONDS - start_time ))
            echo "Bowtie SR alignment 75nt for R1 reads completed in ${elapsed_time} seconds" >> "$log_file"

            # Bowtie mapping (SR -m1 -v0) for R2 filtered reads
            start_time=$SECONDS
            echo "### $(basename "$strain")/${sample} 75nt R2 ###" >> "$stats"
            echo "${experiment}" >> "$stats"
            bowtie -p "$N_CPU" -m 1 -v 0 -S "${MYREF}/S_cerevisiae_indexed" "${strain}/${sample}_${experiment}_r_R2_filtered.fastq" > "${strain}/${sample}_${experiment}_r_R2_filtered.sam" 2>> "$stats"
            echo "" >> "$stats"  # Adds a blank line
            elapsed_time=$(( SECONDS - start_time ))
            echo "Bowtie SR alignment 75nt for R2 reads completed in ${elapsed_time} seconds" >> "$log_file"
                    
            # Select reads aligning for both R1 and R2
            samtools view -F 4 "${strain}/${sample}_${experiment}_r_R1_filtered.sam" > "${strain}/${sample}_${experiment}_r_R1_mapped.sam"
            samtools view -F 4 "${strain}/${sample}_${experiment}_r_R2_filtered.sam" > "${strain}/${sample}_${experiment}_r_R2_mapped.sam"

            # Extract read names, sort and find common reads
            cut -f1 "${strain}/${sample}_${experiment}_r_R1_mapped.sam" | sed 's/\/1//' > "${strain}/${sample}_${experiment}_r_R1_mapped.txt"
            cut -f1 "${strain}/${sample}_${experiment}_r_R2_mapped.sam" | sed 's/\/2//' > "${strain}/${sample}_${experiment}_r_R2_mapped.txt"
            sort "${strain}/${sample}_${experiment}_r_R1_mapped.txt" -o "${strain}/${sample}_${experiment}_r_R1_mapped_sorted.txt"
            sort "${strain}/${sample}_${experiment}_r_R2_mapped.txt" -o "${strain}/${sample}_${experiment}_r_R2_mapped_sorted.txt"

            comm -12 "${strain}/${sample}_${experiment}_r_R1_mapped_sorted.txt" "${strain}/${sample}_${experiment}_r_R2_mapped_sorted.txt" > "${strain}/${sample}_${experiment}_r_R12_mapped.txt"
            
            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_r_R1_filtered.sam" "${strain}/${sample}_${experiment}_r_R2_filtered.sam"
            rm  "${strain}/${sample}_${experiment}_r_R1_mapped.sam" "${strain}/${sample}_${experiment}_r_R2_mapped.sam"
            rm "${strain}/${sample}_${experiment}_r_R1_mapped.txt" "${strain}/${sample}_${experiment}_r_R2_mapped.txt"
            rm "${strain}/${sample}_${experiment}_r_R1_mapped_sorted.txt" "${strain}/${sample}_${experiment}_r_R2_mapped_sorted.txt"
            

            # Bowtie2 mapping (in a forced -m1 -v0 mode)
            start_time=$SECONDS
            echo "### $(basename "$strain")/${sample} 75nt paired-end Bowtie2 alignment ###" >> "$stats"
            echo "${experiment}" >> "$stats"
            bowtie2 \
              -p "$N_CPU" \
              --no-1mm-upfront \
              --score-min C,0,0 \
              -N 0 \
              --end-to-end \
              --fr \
              -x "${MYREF}/S_cerevisiae_indexed" \
              -1 "${strain}/${sample}_${experiment}_r_R1_filtered.fastq" \
              -2 "${strain}/${sample}_${experiment}_r_R2_filtered.fastq" \
              -S "${strain}/${sample}_${experiment}.sam" 2>> "$stats" 

            echo "" >> "$stats"  # Adds a blank line
            elapsed_time=$(( SECONDS - start_time ))
            echo "Bowtie2 alignment 75nt for paired-end reads completed in ${elapsed_time} seconds" >> "$log_file"
            echo "" >> "$log_file"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_r_R1_filtered.fastq"
            rm "${strain}/${sample}_${experiment}_r_R2_filtered.fastq"

            #########
            # Bowtie2 SAM processing (concordant read-pairs for % recombination)
            start_time=$SECONDS
            echo "### $(basename "$strain")/${sample} Bowtie2 SAM processing - concordant read pairs ###" >> "$log_file"
            echo "${experiment}" >> "$log_file"

            # Remove header for processing
            sed -n -e '1,19p' "${strain}/${sample}_${experiment}.sam" > "${strain}/${sample}_${experiment}_header.sam"
            tail -n +20 "${strain}/${sample}_${experiment}.sam" > "${strain}/${sample}_${experiment}_alignment.sam"

            # Processing (set pairs in the same row, extract only those aligning both R1 and R2 completely)
            # Consider for further processing only reads pair aligning uniquely
            awk -vOFS='\t' '{$11="AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"; print}' "${strain}/${sample}_${experiment}_alignment.sam" | \
            cut -f1-19 | \
            sed '$!N;s/\n/ /' | \
            awk '($3 != $7 && $7 == "=")' | \
            awk '($7 != "*")' | \
            awk '$6 == "75M"' | \
            awk '$25 == "75M"' | \
            awk '$13 == "XN:i:0"' | \
            awk '$32 == "XN:i:0"' | \
            sed 's/ /\t/g' | \
            awk '($19 != "YT:Z:UP")' | \
            awk '($38 != "YT:Z:UP")' > "${strain}/${sample}_${experiment}_alignment_processed.sam"

            # Remove intermediate files
            #rm "${strain}/${sample}_${experiment}_alignment.sam"

            # Place read pairs in SAM standard output format
            cut -f1-19 "${strain}/${sample}_${experiment}_alignment_processed.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R1.sam"
            cut -f20-38 "${strain}/${sample}_${experiment}_alignment_processed.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R2.sam"
            cat "${strain}/${sample}_${experiment}_alignment_processed_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R2.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R12.sam"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_alignment_processed_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R2.sam"

            # Add header back
            cat "${strain}/${sample}_${experiment}_header.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R12_header.sam"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_alignment_processed_R12.sam"

            # Extract R1 reads that aligned in -m1 -v0 in SR bowtie mapping
            samtools view -N "${strain}/${sample}_${experiment}_r_R12_mapped.txt" -o "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header.sam"

            # Extract R2 reads that aligned in -m1 -v0 in SR bowtie mapping
            samtools view -N "${strain}/${sample}_${experiment}_r_R12_mapped.txt" -o "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R2.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header.sam"

            # Cat mapping reads
            cat "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R2.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R12.sam"
            
            # Add header back
            cat "${strain}/${sample}_${experiment}_header.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R12.sam" > "${strain}/${sample}_${experiment}_concordant_pairs.sam"
            
            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R12.sam"
            rm "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R2.sam"

            # Concordant read pairs - unique reads
            awk '!seen[$0]++' "${strain}/${sample}_${experiment}_concordant_pairs.sam" > "${strain}/${sample}_${experiment}_concordant_pairs_unique.sam"

            # Get row count
            tail -n +20 "${strain}/${sample}_${experiment}_concordant_pairs_unique.sam" | wc -l | awk '{print $1}' > "${strain}/${sample}_${experiment}_concordant_pairs_unique_row_count.tsv"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_concordant_pairs.sam"
            rm "${strain}/${sample}_${experiment}_alignment_processed_R12_header.sam"
            rm "${strain}/${sample}_${experiment}_alignment_processed.sam"
            rm "${strain}/${sample}_${experiment}_concordant_pairs_unique.sam"
            #rm "${strain}/${sample}_${experiment}_r_R12_mapped.txt"

            echo "" >> "$log_file"  # Adds a blank line
            elapsed_time=$(( SECONDS - start_time ))
            echo "Concordant read pairs processing completed in ${elapsed_time} seconds" >> "$log_file"
            echo "" >> "$log_file"  # Adds a blank line 
            

            ########

            # Bowtie2 SAM processing (inter-chromosomal discordant read-pairs)
            start_time=$SECONDS
            echo "### $(basename "$strain")/${sample} Bowtie2 SAM processing - inter-chromosomal discordant read pairs ###" >> "$log_file"
            echo "${experiment}" >> "$log_file"

            # Remove header for processing
            #sed -n -e '1,19p' "${strain}/${sample}_${experiment}.sam" > "${strain}/${sample}_${experiment}_header.sam"
            #tail -n +20 "${strain}/${sample}_${experiment}.sam" > "${strain}/${sample}_${experiment}_alignment.sam"

            # Processing (set pairs in the same row, extract only those aligning both R1 and R2 completely)
            # Consider for further processing only reads pair aligning uniquely
            awk -vOFS='\t' '{$11="AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"; print}' "${strain}/${sample}_${experiment}_alignment.sam" | \
            cut -f1-19 | \
            sed '$!N;s/\n/ /' | \
            awk '($3 != $7 && $7 != "=")' | \
            awk '($7 != "*")' | \
            awk '$6 == "75M"' | \
            awk '$25 == "75M"' | \
            awk '$13 == "XN:i:0"' | \
            awk '$32 == "XN:i:0"' | \
            sed 's/ /\t/g' | \
            awk '($19 != "YT:Z:UP")' | \
            awk '($38 != "YT:Z:UP")' > "${strain}/${sample}_${experiment}_alignment_processed.sam"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_alignment.sam"

            # Place read pairs in SAM standard output format
            cut -f1-19 "${strain}/${sample}_${experiment}_alignment_processed.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R1.sam"
            cut -f20-38 "${strain}/${sample}_${experiment}_alignment_processed.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R2.sam"
            cat "${strain}/${sample}_${experiment}_alignment_processed_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R2.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R12.sam"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_alignment_processed_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R2.sam"

            # Add header back
            cat "${strain}/${sample}_${experiment}_header.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R12_header.sam"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_alignment_processed_R12.sam"

            # Extract R1 reads that aligned in -m1 -v0 in SR bowtie mapping
            samtools view -N "${strain}/${sample}_${experiment}_r_R12_mapped.txt" -o "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header.sam"

            # Extract R2 reads that aligned in -m1 -v0 in SR bowtie mapping
            samtools view -N "${strain}/${sample}_${experiment}_r_R12_mapped.txt" -o "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R2.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header.sam"

            # Cat mapping reads
            cat "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R2.sam" > "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R12.sam"
            
            # Add header back
            cat "${strain}/${sample}_${experiment}_header.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R12.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs.sam"
            
            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_header.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R12.sam"
            rm "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_alignment_processed_R12_header_R2.sam"

            # Inter-chromosomal discordant read pairs - unique reads
            awk '!seen[$0]++' "${strain}/${sample}_${experiment}_inter_discordant_pairs.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique.sam"

            # Remove intermediate files
            rm "${strain}/${sample}_${experiment}_inter_discordant_pairs.sam"
            rm "${strain}/${sample}_${experiment}_alignment_processed_R12_header.sam"
            rm "${strain}/${sample}_${experiment}_alignment_processed.sam"
            rm "${strain}/${sample}_${experiment}_r_R12_mapped.txt"
            rm "${strain}/${sample}_${experiment}.sam"
            rm "${strain}/${sample}_${experiment}_header.sam"

            # Prepare tsv file for R processing
            tail -n +20 "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique.sam" | \
            # Extract relevant columns (1, 3, 4, 7, 8, 10) and convert to tsv format
            # Note: $1 is read name, $3 is reference sequence name, $4 is position, $7 is mate reference sequence name, $8 is mate position, $10 is sequence
            awk 'BEGIN{OFS="\t"} {print $1, $3, $4, $7, $8, $10}' > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique.tsv"
            
            echo "" >> "$log_file"  # Adds a blank line
            elapsed_time=$(( SECONDS - start_time ))
            echo "Inter-chromosomal discordant read pairs processing completed in ${elapsed_time} seconds" >> "$log_file"
            echo "" >> "$log_file"  # Adds a blank line 

            # Calculate total elapsed time
            elapsed_time_total=$((( SECONDS - start_time_total )/60))
            echo "Total processing completed in ${elapsed_time_total} minutes" >> "$log_file"
            echo "" >> "$log_file"  # Adds a blank line 

          else
          echo "Warning: Decompressed files missing for sample $sample in $strain!" >> "$log_file"
          echo "" >> "$log_file"
          fi
        else
        echo "Warning: One or both compressed files for sample $sample are missing in $strain!" >> "$log_file"
        echo "" >> "$log_file"
        fi
      done
    done
done

# Calculate alignment and processing total elapsed time
elapsed_time_total_alignment=$((( SECONDS - start_time_total_alignment )/60))
echo "================================" >> "$log_file"
echo "" >> "$log_file"
echo "ALIGNMENT AND SAM PROCESSING COMPLETED IN ${elapsed_time_total_alignment} MINUTES" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line


########### MODULE CORE - END ###########


##### MODULE MATs - START #####
############## MATa-MATa' analysis of 75bp reads ############

# MATa-MATa' analysis

echo "================================" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
echo "### MATa-MATa' analysis, 75bp analysis ###" >> "$log_file"
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Initiated at ${current_time}" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line 
start_time_total_MATs=$SECONDS

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in T0 TSG TLG TLR; do
    for experiment in E1 E2 E3; do
      file_alignment="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique.sam"
      if [[ -f "$file_alignment"  ]]; then
        echo "$(basename "$strain") ${sample} ${experiment}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing MATs for $file_alignment" >> "$log_file" 
        start_time_MATs=$SECONDS
        
        # Determine the number of cores available
        N_CPU=$(nproc)
        
        # Extract inter-chromosomal discordant read pairs for MATa-MATa' analysis
        # Remove header for processing
        sed -n -e '1,19p' "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_header.sam"

        # Extract reads and cat them to a new file
        awk ' ($3=="CHRIII" && $7=="CHRV" && $8>289178 && $8<290483) ' "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R1.sam"
        awk ' ($3=="CHRV" && $7=="CHRIII" && $4>289178 && $4<290483) ' "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R2.sam"
        cat "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_header.sam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R1.sam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R2.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.sam"
        #cat "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_header.sam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R1.sam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R2.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.tsv"
        #rm  "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_header.sam"
        #rm "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R1.sam"
        #rm "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R2.sam"

        # convert SAM to sorted BAM (75nt)
        start_time=$SECONDS
        samtools sort -@ "$N_CPU" -o "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.sam"
        samtools index "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bai"
        elapsed_time=$(( SECONDS - start_time ))
        echo "Bam and Bai 75nt MAT reads completed in ${elapsed_time} seconds" >> "$log_file"

        # Generate BedGraphs coverage files (75nt)
        start_time=$SECONDS
        bamCoverage -b "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bam" -o "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bedgraph" -of bedgraph -p "$N_CPU"  -bs 1 --smoothLength 1
        elapsed_time=$(( SECONDS - start_time ))
        echo "Bedgraphs 75nt reads completed in ${elapsed_time} seconds" >> "$log_file"

        # Sorting Bedgraphs files (75nt)
        samtools faidx "${MYREF}/RG_PMV_v9.fasta" # Create index file
        cut -f1,2 "${MYREF}/RG_PMV_v9.fasta.fai" > "${MYREF}/chrom_order.txt"
        bedtools sort -i "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bedgraph" -g "${MYREF}/chrom_order.txt" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_sorted.bedgraph"
             
        
        # Generate TSV files (75nt)
        start_time=$SECONDS
        #bedtools coverage -a "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bedgraph" -b "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bam" -d > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.tsv"
        bedtools coverage -a "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_sorted.bedgraph" -b "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bam" -sorted -g "${MYREF}/chrom_order.txt" -d > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_sorted.tsv"
            
        # Keep only coverage for chromosomes CHRIII and CHRV
        awk '$1=="CHRIII" || $1=="CHRV"' "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_sorted.tsv" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_filtered.tsv"

        # Remove intermediate files   
        rm "${strain}/${sample}_${experiment}_"*.bai
        rm "${strain}/${sample}_${experiment}_"*.bam
        rm "${strain}/${sample}_${experiment}_"*.bedgraph
        rm "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_sorted.tsv"
        rm "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R1.sam"
        rm "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_R2.sam"
        rm "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_header.sam"

      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time_MATs )))
        echo "Total MATs SAM processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample/$experiment: $file_alignment" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done

      

# R plots for inter-chromosomal discordant read pairs
# After processing all samples, all discordant pairs are associated to their genomic features
# and only discordant pairs not present at T0 are kept for further BLAST validation.
# Start timer for R processing

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      #echo "$root_dir"
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Plotting MATa-MATa' coverage" >> "$log_file"
        start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        #echo "ROOT_DIR: $ROOT_DIR"
        #echo "STRAIN: $STRAIN"
        Rscript - <<'EOF'
          # load libraries
          
          library(ggplot2)
          library(extrafont)
          library(svglite)
          library(ggdensity)
          library(purrr)
          library(stringr)
          library(readr)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          options(dplyr.summarise.inform = FALSE)

          # Read environment variables
          root_dir <- Sys.getenv("ROOT_DIR")
          strain <- Sys.getenv("STRAIN")
          strain <- sub("/$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)

          print(paste("ROOT_DIR:", root_dir))

          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          # Define a function to process tsv files
          process_MATs_coverage_files <- function(file_path) {
            # Extract filename and directory parts
            file_base <- basename(file_path)
            strain_name <- basename(dirname(file_path))  # directory name above the file

            # Expect filename like T4_E07_MAT_filtered.tsv
            parts <- str_split(file_base, "_", simplify = TRUE)

            # Validate and extract parts safely
            if (ncol(parts) >= 3) {
              sample_name <- parts[1]
              experiment_name <- parts[2]
            } else {
              warning(paste("Filename does not match expected format:", file_base))
              return(NULL)
            }

            # Read file
            temp_file <- read_tsv(file_path, col_names = FALSE, show_col_types = FALSE)

            # Skip if empty
            if (nrow(temp_file) == 0) {
              return(NULL)
            }

            # Prepare coverage dataframe
            coverage_file <- temp_file %>%
              rename("chromosome" = !!names(.[1]), "coverage" = !!names(.[4])) %>%
              select(chromosome, coverage) %>%
              mutate(
                strain = strain_name,
                sample = sample_name,
                experiment = experiment_name
              )

            return(coverage_file)
          }
        

          log_step("Finding MATa-MATa' coverage files...")
          # Get all coverage.tsv files recursively in root folder
          MAT_coverage_files <- list.files(
            path = root_dir,
            pattern = "MAT_filtered\\.tsv$",
            recursive = TRUE,
            full.names = TRUE
          )
          MAT_coverage_files
          log_step("Processing MATa-MATa' coverage files...")
          MATs_processed_df <- purrr::map_dfr(MAT_coverage_files, process_MATs_coverage_files)
          

          log_step("Processing chromosome III...")
          III_df <- MATs_processed_df %>% filter(chromosome == "CHRIII") %>%
            group_by(strain, sample, experiment) %>% 
            mutate(position = row_number(), position_HO_centered = position - 200753) %>%
            ungroup() %>% 
            group_by(strain, sample, chromosome, position, position_HO_centered) %>%
            summarise(mean_coverage = mean(coverage, na.rm = TRUE), sd_coverage = sd(coverage, na.rm = TRUE))

          log_step("Processing chromosome V...")
          V_df <- MATs_processed_df %>% filter(chromosome == "CHRV") %>%
            group_by(strain, sample, experiment) %>% 
            mutate(position = row_number(), position_HO_centered = position - 289825) %>%
            ungroup() %>% 
            group_by(strain, sample, chromosome, position, position_HO_centered) %>%
            summarise(mean_coverage = mean(coverage, na.rm = TRUE), sd_coverage = sd(coverage, na.rm = TRUE))

          MAT_df <- bind_rows(III_df, V_df)
          log_step(paste("Number of samples found:", length(MAT_df)))
          

          # Set polymorphisms positions
          polymorphisms <- tibble(position_HO_centered = c(-634,-586,-541,-481,-427,-367,-304,-244,-211,-178,-118,-64,
                                                 0,64,129,194,259,324,395,454,519,584,649),
                        mean_coverage = rep(c(0)),
                        chromosome = rep(c("polymorphism")))

          log_step("Splitting by sample...")
          # Split by sample
          split_MAT_df <- split(MAT_df, 
                                MAT_df$sample)

          # Set output directory
          #svg_output_dir <- file.path(root_dir, "MAT_plots")
          #dir.create(svg_output_dir, showWarnings = FALSE, recursive = TRUE)
          write_tsv(MAT_df, file.path(root_dir, paste0(strain_name, "_MAT_coverage_df.tsv")))

          
          log_step("Plotting...")
          # Generate plots
          MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
            data_subset <- split_MAT_df[[sample]]
            
            p <- ggplot(data_subset, aes(x = position_HO_centered, y = mean_coverage, color = chromosome)) +
              geom_point(data = polymorphisms, aes(x = position_HO_centered, y = mean_coverage),
                        color = "chartreuse3", shape = 108, size = 5) +
              geom_line(linewidth = 1) + #1.2
              scale_color_manual(values = c("CHRIII" = "#2F2C7E", "CHRV" = "#A30000")) + #2F2C7E, A30000
              theme_classic(base_family = "Arial") +
              theme(
                panel.grid = element_line(color = "black", linewidth = 0.1),
                panel.background = element_blank(),
                plot.background = element_rect(fill = "transparent", colour = NA),
                legend.position = "none",
                aspect.ratio = 0.45,
                plot.title = element_text(hjust = 0.5),
                axis.title.x = element_text(hjust = 1)
              ) +
              theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 20),
              axis.title.y = element_text(vjust = 2, size = 20)) +
              theme(axis.text.x = element_text(vjust = 0, size = 15),
              axis.text.y = element_text(vjust = 0, size = 15)) +
              coord_cartesian(xlim = c(-1200, 1200), ylim = c(0, 30), expand = FALSE) +
              scale_x_continuous(limits = c(-1100, 1100), breaks = seq(-1100, 1100, 200)) +
              scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5)) +
              geom_vline(xintercept = 0, linetype = "dashed", color = "grey3", linewidth = 0.5) +
              labs(
                title = paste0("Average coverage of MATa-MATa' discordant reads - ", strain_name, " - ", sample),
                x = "Relative Coordinate (bp)",
                y = "Average Coverage"
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("Average_MATa_MATa_coverage_", strain_name, "_", sample, ".svg")),
              plot = p,
              #width = 8,
              #height = 3.6,
              device = svglite,
              bg = "transparent"
            )
            
            return(p)
            
          })

          # Generate plots for chromosome III (only coverage shape)
          MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
            data_subset <- split_MAT_df[[sample]]
            data_subset <- data_subset %>% filter(chromosome == "CHRIII")
            
            p <- ggplot(data_subset, aes(x = position_HO_centered, y = mean_coverage, color = chromosome)) +
              geom_line(linewidth = 1) +
              scale_color_manual(values = c("CHRIII" = "#2F2C7E")) +
              theme_classic(base_family = "Arial") +
              theme(
                panel.grid = element_line(color = "black", linewidth = 0.1),
                panel.background = element_blank(),
                plot.background = element_rect(fill = "transparent", colour = NA),
                legend.position = "none",
                aspect.ratio = 0.25,
                plot.title = element_text(hjust = 0.5),
                axis.title.x = element_text(hjust = 1)
              ) +
              theme(axis.line=element_blank(), axis.ticks=element_blank()) +
              theme(axis.text.x = element_text(vjust = 0, size = 0),
              axis.text.y = element_text(vjust = 0, size = 0))+
              coord_cartesian(xlim = c(-1200, 1200), ylim = c(0, 30), expand = FALSE) +
              scale_x_continuous(limits = c(-1100, 1100), breaks = seq(-1100, 1100, 200)) +
              scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5)) +
              labs(
                title = paste0("Average coverage of MATa-MATa' discordant reads chrIII - ", strain_name, " - ", sample),
                x = "",
                y = ""
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("Average_MATa_MATa_coverage_chrIII_", strain_name, "_", sample, ".svg")),
              plot = p,
              width = 8,
              height = 3.6,
              device = svglite,
              bg = "transparent"
            )
            
            return(p)
            
          })

          # Generate plots for chromosome V (only coverage shape)
          MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
            data_subset <- split_MAT_df[[sample]]
            data_subset <- data_subset %>% filter(chromosome == "CHRV")
            
            p <- ggplot(data_subset, aes(x = position_HO_centered, y = mean_coverage, color = chromosome)) +
              geom_line(linewidth = 1) +
              scale_color_manual(values = c("CHRV" = "#B86029")) +
              theme_classic(base_family = "Arial") +
              theme(
                panel.grid = element_line(color = "black", linewidth = 0.1),
                panel.background = element_blank(),
                plot.background = element_rect(fill = "transparent", colour = NA),
                legend.position = "none",
                aspect.ratio = 0.25,
                plot.title = element_text(hjust = 0.5),
                axis.title.x = element_text(hjust = 1)
              ) +
              theme(axis.line=element_blank(), axis.ticks=element_blank()) +
              theme(axis.text.x = element_text(vjust = 0, size = 0),
              axis.text.y = element_text(vjust = 0, size = 0))+
              coord_cartesian(xlim = c(1200, -1200), ylim = c(0, 30), expand = FALSE) +
              scale_x_continuous(limits = c(-1100, 1100), breaks = seq(-1100, 1100, 200)) +
              scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5)) +
              labs(
                title = paste0("Average coverage of MATa-MATa' discordant reads chrV - ", strain_name, " - ", sample),
                x = "",
                y = ""
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("Average_MATa_MATa_coverage_chrV_", strain_name, "_", sample, ".svg")),
              plot = p,
              width = 8,
              height = 3.6,
              device = svglite,
              bg = "transparent"
            )
            
            return(p)
            
          })

          # Define a function to process sam files
          process_MATs_pairs_files <- function(file_path) {
            # Extract filename and directory parts
            file_base <- basename(file_path)
            strain_name <- basename(dirname(file_path))  # directory name above the file
            
            
            parts <- str_split(file_base, "_", simplify = TRUE)
            
            # Validate and extract parts safely
            if (ncol(parts) >= 3) {
              sample_name <- parts[1]
              experiment_name <- parts[2]
            } else {
              warning(paste("Filename does not match expected format:", file_base))
              return(NULL)
            }
            
            # Read file
            temp_file <- read_tsv(file_path, skip = 19, col_names = FALSE, show_col_types = FALSE)
            
            # Skip if empty
            if (nrow(temp_file) == 0) {
              return(NULL)
            }
            
            # Prepare coverage dataframe
            pairs_file <- temp_file %>%
              rename("chromosome_A" = !!names(.[3]), "position_A" = !!names(.[4]),
                    "chromosome_B" = !!names(.[7]), "position_B" = !!names(.[8])) %>%
              select(chromosome_A, position_A, chromosome_B, position_B) %>%
              mutate(
                strain = strain_name,
                sample = sample_name,
                experiment = experiment_name
              )
            
            return(pairs_file)
          }

          log_step("Finding MATa-MATa' pairs files...")
          # Get all pairs files recursively in root folder
          MAT_pairs_files <- list.files(
            path = root_dir,
            pattern = "unique_MAT\\.sam$",
            recursive = TRUE,
            full.names = TRUE
          )
          MAT_pairs_files
          log_step("Processing MATa-MATa' pairs files...")
          MATs_pairs_processed_df <- purrr::map_dfr(MAT_pairs_files, process_MATs_pairs_files)

          MAT_pairs_III <- MATs_pairs_processed_df %>% filter(chromosome_A == "CHRIII" & chromosome_B == "CHRV") %>% 
            rename(X_value_III = position_A, Y_value_V = position_B) %>% 
            select(X_value_III, Y_value_V, strain, sample, experiment)

          MAT_pairs_V <- MATs_pairs_processed_df %>% filter(chromosome_A == "CHRV" & chromosome_B == "CHRIII") %>% 
            rename(X_value_III = position_B, Y_value_V = position_A) %>% 
            select(X_value_III, Y_value_V, strain, sample, experiment)

          MAT_combined <- bind_rows(MAT_pairs_III, MAT_pairs_V)
          write_tsv(MAT_combined, file.path(root_dir, paste0(strain_name, "_MAT_pairs_df.tsv")))

          ### Calculate proportion of GC events to the right or to the left of HO site
          MAT_combined_bar_graph <- MAT_combined %>% mutate(right_left = ifelse(Y_value_V < 289825, "left", "right")) %>% 
            group_by(strain, sample, experiment, right_left) %>% 
            summarise(n_experiment = n()) %>%
            mutate(total_experiment = sum(n_experiment)) %>%                  
            mutate(percentage_experiment = 100 * n_experiment / total_experiment) %>%         # Percent for each right/left
            ungroup() %>% select(!c(n_experiment, total_experiment)) 
          MAT_combined_summary <- MAT_combined_bar_graph %>% 
            group_by(strain, sample, right_left) %>% 
            summarise(average_percentage = mean(percentage_experiment),
                      sd_percentage = sd(percentage_experiment))

          write_tsv(MAT_combined_summary, file.path(root_dir, paste0(strain_name, "_MAT_pairs_summary_df.tsv")))


          split_MAT_df <- split(MAT_combined, 
                                MAT_combined$sample)


          log_step("Plotting...")
          # Generate plots for MATa-MATa' pairs
          MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
            data_subset <- split_MAT_df[[sample]]
            
            p <- ggplot(data_subset, aes(x = X_value_III, y = Y_value_V)) + theme_light(base_family = "Arial") +
              theme(panel.background = element_blank(), plot.background = element_rect(fill = "transparent", colour = NA)) +
              theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) +
              theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank()) +
              scale_x_continuous(breaks = seq(199653,201853, by = 1100), limits = c(199353,202153)) + 
              scale_y_continuous(breaks = seq(288725,290925, by = 1100), limits = c(288425,291225))+ 
              geom_hdr(xlim = c(199353,202153), ylim = c(288425,291225), method = "kde", fill = "brown4") + 
              geom_point (colour = "black", size = 0.5) + 
              theme(aspect.ratio = 1) + 
              geom_hline(yintercept=289825, linetype="dashed", color = "black", linewidth=0.2, alpha = 0.3) + 
              geom_vline(xintercept=200753, linetype="dashed", color = "black", linewidth=0.2, alpha = 0.3) +
              labs(
                title = paste0("MATa-MATa' discordant reads pairs - ", strain_name, " - ",sample),
                x = "Chr.III coordinates",
                y = "Chr.V coordinates"
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("MATa_MATa_pairs_", strain_name, "_", sample, ".svg")),
              plot = p,
              width = 8,
              height = 3.6,
              device = svglite,
              bg = "transparent"
            )
            
            return(p)
            
          })

   
          
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 

done

# Calculate total elapsed time
elapsed_time_total=$((( SECONDS - start_time_total_MATs )/60))
echo "================================" >> "$log_file"
echo "" >> "$log_file"
echo "TOTAL MATa-MATa' PROCESSING COMPLETED IN ${elapsed_time_total} MINUTES" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line    


############## MATa-MATa' analysis of 18bp reads ############

# MATa-MATa' analysis

echo "================================" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
echo "### MATa-MATa' analysis, 18bp analysis ###" >> "$log_file"
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Initiated at ${current_time}" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line 
start_time_total_MATs_18=$SECONDS

# Start timer for the alignment and processing section
start_time_total_alignment=$SECONDS

# Index RG for bowtie alignment
bowtie-build "${MYREF}/RG_PMV_v9.fasta" "${MYREF}/S_cerevisiae_indexed"

# Index RG for bowtie2 alignment
bowtie2-build "${MYREF}/RG_PMV_v9.fasta" "${MYREF}/S_cerevisiae_indexed"

# Loop through each directory inside MYWD

echo "### Alignments and SAM processing ###" >> "$log_file"
echo "Initiated at ${current_time}" >> "$log_file" 
echo "" >> "$log_file"  # Adds a blank line

# Define the pairs
declare -a R1_ids=("R1_1_1_1" "R1_1_1_2" "R1_1_2_1" "R1_1_2_2" "R1_2_1_1" "R2_1_1_1" "R2_1_1_2" "R2_1_2_1" "R2_1_2_2" "R2_2_1_1")
declare -a R2_ids=("R1_1_2_2" "R1_2_1_1" "R1_2_1_2" "R1_2_2_1" "R1_2_2_2" "R2_1_2_2" "R2_2_1_1" "R2_2_1_2" "R2_2_2_1" "R2_2_2_2")


for strain in "$MYWD"*/; do
  echo "Processing directory: $strain" >> "$log_file"

  # Loop through sample prefixes (TLG)
    for sample in TLG; do
      for experiment in E1 E2 E3; do
        file1_gz="${strain}/${sample}_${experiment}_R1.fastq.gz"
        file2_gz="${strain}/${sample}_${experiment}_R2.fastq.gz"
       
        # Check if both compressed files exist
        if [[ -f "$file1_gz" && -f "$file2_gz" ]]; then
          echo "Processing files: $file1_gz, $file2_gz" >> "$log_file"
          echo "" >> "$log_file"  # Adds a blank line

          # Keep the current pair compressed
          gunzip -k "$file1_gz" "$file2_gz"
          #file1_path="${strain}/${sample}_${experiment}_R1.fastq"
          #file2_path="${strain}/${sample}_${experiment}_R2.fastq"

          if [[ -f "${strain}/${sample}_${experiment}_R1.fastq" && -f "${strain}/${sample}_${experiment}_R2.fastq" ]]; then
            # Determine the number of cores available
            N_CPU=$(nproc)

            # Start timers for total processing of a strain/sample/experiment
            start_time_total=$SECONDS
        
            # Trim reads using cutadapt
            echo "### $(basename "$strain")/${sample} ${experiment} ###" >> "$log_file"
            echo "" >> "$log_file"  # Adds a blank line
            start_time=$SECONDS

            ### 75 nt reads #################################################################################################################

            # trim R1 reads
            cutadapt -j "$N_CPU" --cut -75 -o "${strain}/${sample}_${experiment}_R1_1.fastq" "${strain}/${sample}_${experiment}_R1.fastq"
            cutadapt -j "$N_CPU" --cut 75 -o "${strain}/${sample}_${experiment}_R1_2.fastq" "${strain}/${sample}_${experiment}_R1.fastq"
            # trim R2 reads
            cutadapt -j "$N_CPU" --cut -75 -o "${strain}/${sample}_${experiment}_R2_1.fastq" "${strain}/${sample}_${experiment}_R2.fastq"
            cutadapt -j "$N_CPU" --cut 75 -o "${strain}/${sample}_${experiment}_R2_2.fastq" "${strain}/${sample}_${experiment}_R2.fastq"

            # Remove intermediate fastq files
            rm "${strain}/${sample}_${experiment}_R1.fastq" "${strain}/${sample}_${experiment}_R2.fastq"

            ### 37 nt reads #################################################################################################################

            # trim R1 reads
            cutadapt -j "$N_CPU" --cut -38 -o "${strain}/${sample}_${experiment}_R1_1_1.fastq" "${strain}/${sample}_${experiment}_R1_1.fastq"
            cutadapt -j "$N_CPU" --cut 38 -o "${strain}/${sample}_${experiment}_R1_1_2.fastq" "${strain}/${sample}_${experiment}_R1_1.fastq"

            cutadapt -j "$N_CPU" --cut -38 -o "${strain}/${sample}_${experiment}_R1_2_1.fastq" "${strain}/${sample}_${experiment}_R1_2.fastq"
            cutadapt -j "$N_CPU" --cut 38 -o "${strain}/${sample}_${experiment}_R1_2_2.fastq" "${strain}/${sample}_${experiment}_R1_2.fastq"

            # trim R2 reads
            cutadapt -j "$N_CPU" --cut -38 -o "${strain}/${sample}_${experiment}_R2_1_1.fastq" "${strain}/${sample}_${experiment}_R2_1.fastq"
            cutadapt -j "$N_CPU" --cut 38 -o "${strain}/${sample}_${experiment}_R2_1_2.fastq" "${strain}/${sample}_${experiment}_R2_1.fastq"

            cutadapt -j "$N_CPU" --cut -38 -o "${strain}/${sample}_${experiment}_R2_2_1.fastq" "${strain}/${sample}_${experiment}_R2_2.fastq"
            cutadapt -j "$N_CPU" --cut 38 -o "${strain}/${sample}_${experiment}_R2_2_2.fastq" "${strain}/${sample}_${experiment}_R2_2.fastq"
          

            # Remove intermediate fastq files
            rm "${strain}/${sample}_${experiment}_R1_1.fastq" "${strain}/${sample}_${experiment}_R1_2.fastq" 
            rm "${strain}/${sample}_${experiment}_R2_1.fastq" "${strain}/${sample}_${experiment}_R2_2.fastq"


            ### 18 nt reads #################################################################################################################

            # trim R1 reads
            cutadapt -j "$N_CPU" --cut -19 -o "${strain}/${sample}_${experiment}_R1_1_1_1.fastq" "${strain}/${sample}_${experiment}_R1_1_1.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${strain}/${sample}_${experiment}_R1_1_1_2.fastq" "${strain}/${sample}_${experiment}_R1_1_1.fastq"

            cutadapt -j "$N_CPU" --cut -19 -o "${strain}/${sample}_${experiment}_R1_1_2_1.fastq" "${strain}/${sample}_${experiment}_R1_1_2.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${strain}/${sample}_${experiment}_R1_1_2_2.fastq" "${strain}/${sample}_${experiment}_R1_1_2.fastq"

            cutadapt -j "$N_CPU" --cut -19 -o "${strain}/${sample}_${experiment}_R1_2_1_1.fastq" "${strain}/${sample}_${experiment}_R1_2_1.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${strain}/${sample}_${experiment}_R1_2_1_2.fastq" "${strain}/${sample}_${experiment}_R1_2_1.fastq"

            cutadapt -j "$N_CPU" --cut -19 -o "${strain}/${sample}_${experiment}_R1_2_2_1.fastq" "${strain}/${sample}_${experiment}_R1_2_2.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${strain}/${sample}_${experiment}_R1_2_2_2.fastq" "${strain}/${sample}_${experiment}_R1_2_2.fastq"

            # trim R2 reads
            cutadapt -j "$N_CPU" --cut -19 -o "${strain}/${sample}_${experiment}_R2_1_1_1.fastq" "${strain}/${sample}_${experiment}_R2_1_1.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${strain}/${sample}_${experiment}_R2_1_1_2.fastq" "${strain}/${sample}_${experiment}_R2_1_1.fastq"

            cutadapt -j "$N_CPU" --cut -19 -o "${strain}/${sample}_${experiment}_R2_1_2_1.fastq" "${strain}/${sample}_${experiment}_R2_1_2.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${strain}/${sample}_${experiment}_R2_1_2_2.fastq" "${strain}/${sample}_${experiment}_R2_1_2.fastq"

            cutadapt -j "$N_CPU" --cut -19 -o "${strain}/${sample}_${experiment}_R2_2_1_1.fastq" "${strain}/${sample}_${experiment}_R2_2_1.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${strain}/${sample}_${experiment}_R2_2_1_2.fastq" "${strain}/${sample}_${experiment}_R2_2_1.fastq"

            cutadapt -j "$N_CPU" --cut -19 -o "${strain}/${sample}_${experiment}_R2_2_2_1.fastq" "${strain}/${sample}_${experiment}_R2_2_2.fastq"
            cutadapt -j "$N_CPU" --cut 19 -o "${strain}/${sample}_${experiment}_R2_2_2_2.fastq" "${strain}/${sample}_${experiment}_R2_2_2.fastq"

            # Remove intermediate fastq files
            rm "${strain}/${sample}_${experiment}_R1_1_1.fastq" "${strain}/${sample}_${experiment}_R1_1_2.fastq"
            rm "${strain}/${sample}_${experiment}_R1_2_1.fastq" "${strain}/${sample}_${experiment}_R1_2_2.fastq"
            rm "${strain}/${sample}_${experiment}_R2_1_1.fastq" "${strain}/${sample}_${experiment}_R2_1_2.fastq"
            rm "${strain}/${sample}_${experiment}_R2_2_1.fastq" "${strain}/${sample}_${experiment}_R2_2_2.fastq"

            for i in "${!R1_ids[@]}"; do
              R1_file=${R1_ids[$i]}
              R2_file=${R2_ids[$i]}
              echo "Processing files: "${strain}/${sample}_${experiment}_${R1_file}.fastq" "${strain}/${sample}_${experiment}_${R2_file}.fastq"" >> "$log_file"
              echo "" >> "$log_file"

               # Filter 18nt reads Q30
              fastp \
                -i "${strain}/${sample}_${experiment}_${R1_file}.fastq" \
                -o "${strain}/${sample}_${experiment}_${R1_file}_filtered.fastq" \
                -I "${strain}/${sample}_${experiment}_${R2_file}.fastq" \
                -O "${strain}/${sample}_${experiment}_${R2_file}_filtered.fastq" \
                -q 30 -u 0 -e 30 \
                --thread "$N_CPU" \
                --html "${strain}/${sample}_${experiment}_${R1_file}${R2_file}_18nt.fastq.html" \
                --json "${strain}/${sample}_${experiment}_${R1_file}${R2_file}_18nt.fastq.json"
              
              
              elapsed_time=$(( SECONDS - start_time ))
              echo "Cutting and Filtering Reads completed in ${elapsed_time} seconds" >> "$log_file"
              echo ""  >> "$log_file"

                # Bowtie mapping (SR -m1 -v0) for R1 filtered reads
              start_time=$SECONDS
              echo "### $(basename "$strain")/${sample} 18nt R1 ###" >> "$stats"
              echo "${experiment}" >> "$stats"
              echo "${R1_file}" >> "$stats"
              bowtie -p "$N_CPU" -m 1 -v 0 -S "${MYREF}/S_cerevisiae_indexed" "${strain}/${sample}_${experiment}_${R1_file}_filtered.fastq" > "${strain}/${sample}_${experiment}_${R1_file}_filtered.sam" 2>> "$stats"
              echo "" >> "$stats"  # Adds a blank line
              elapsed_time=$(( SECONDS - start_time ))
              echo "Bowtie SR alignment 18nt for R1 reads completed in ${elapsed_time} seconds" >> "$log_file"
              echo "" >> "$log_file"

              # Bowtie mapping (SR -m1 -v0) for R2 filtered reads
              start_time=$SECONDS
              echo "### $(basename "$strain")/${sample} 18nt R2 ###" >> "$stats"
              echo "${experiment}" >> "$stats"
              echo "${R2_file}" >> "$stats"
              bowtie -p "$N_CPU" -m 1 -v 0 -S "${MYREF}/S_cerevisiae_indexed" "${strain}/${sample}_${experiment}_${R2_file}_filtered.fastq" > "${strain}/${sample}_${experiment}_${R2_file}_filtered.sam" 2>> "$stats"
              echo "" >> "$stats"  # Adds a blank line
              elapsed_time=$(( SECONDS - start_time ))
              echo "Bowtie SR alignment 18nt for R2 reads completed in ${elapsed_time} seconds" >> "$log_file"
              echo "" >> "$log_file"
                    
              # Select reads aligning for both R1 and R2
              samtools view -F 4 "${strain}/${sample}_${experiment}_${R1_file}_filtered.sam" > "${strain}/${sample}_${experiment}_${R1_file}_mapped.sam"
              samtools view -F 4 "${strain}/${sample}_${experiment}_${R2_file}_filtered.sam" > "${strain}/${sample}_${experiment}_${R2_file}_mapped.sam"

              # Extract read names, sort and find common reads
              cut -f1 "${strain}/${sample}_${experiment}_${R1_file}_mapped.sam" | sed 's/\/[12]//' > "${strain}/${sample}_${experiment}_${R1_file}_mapped.txt"
              cut -f1 "${strain}/${sample}_${experiment}_${R2_file}_mapped.sam" | sed 's/\/[12]//' > "${strain}/${sample}_${experiment}_${R2_file}_mapped.txt"
              sort "${strain}/${sample}_${experiment}_${R1_file}_mapped.txt" -o "${strain}/${sample}_${experiment}_${R1_file}_mapped_sorted.txt"
              sort "${strain}/${sample}_${experiment}_${R2_file}_mapped.txt" -o "${strain}/${sample}_${experiment}_${R2_file}_mapped_sorted.txt"

              comm -12 "${strain}/${sample}_${experiment}_${R1_file}_mapped_sorted.txt" "${strain}/${sample}_${experiment}_${R2_file}_mapped_sorted.txt" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_mapped.txt"
            
              # Remove intermediate files
              rm "${strain}/${sample}_${experiment}_${R1_file}_filtered.sam" "${strain}/${sample}_${experiment}_${R2_file}_filtered.sam"
              rm  "${strain}/${sample}_${experiment}_${R1_file}_mapped.sam" "${strain}/${sample}_${experiment}_${R2_file}_mapped.sam"
              rm "${strain}/${sample}_${experiment}_${R1_file}_mapped.txt" "${strain}/${sample}_${experiment}_${R2_file}_mapped.txt"
              rm "${strain}/${sample}_${experiment}_${R1_file}_mapped_sorted.txt" "${strain}/${sample}_${experiment}_${R2_file}_mapped_sorted.txt"
            

              # Bowtie2 mapping (in a forced -m1 -v0 mode)
              start_time=$SECONDS
              echo "### $(basename "$strain")/${sample} 18nt paired-end Bowtie2 alignment ###" >> "$stats"
              echo "${experiment}" >> "$stats"
              echo "${R1_file} and ${R2_file}" >> "$stats"
              bowtie2 \
                -p "$N_CPU" \
                --no-1mm-upfront \
                --score-min C,0,0 \
                -N 0 \
                --end-to-end \
                --fr \
                -x "${MYREF}/S_cerevisiae_indexed" \
                -1 "${strain}/${sample}_${experiment}_${R1_file}_filtered.fastq" \
                -2 "${strain}/${sample}_${experiment}_${R2_file}_filtered.fastq" \
                -S "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}.sam" 2>> "$stats" 

              echo "" >> "$stats"  # Adds a blank line
              elapsed_time=$(( SECONDS - start_time ))
              echo "Bowtie2 alignment 18nt for paired-end reads completed in ${elapsed_time} seconds" >> "$log_file"
              echo "" >> "$log_file"

              # Remove intermediate files
              rm "${strain}/${sample}_${experiment}_${R1_file}_filtered.fastq"
              rm "${strain}/${sample}_${experiment}_${R2_file}_filtered.fastq"

              # Bowtie2 SAM processing (inter-chromosomal discordant read-pairs)
              start_time=$SECONDS
              echo "### $(basename "$strain")/${sample} Bowtie2 SAM processing - inter-chromosomal discordant read pairs ###" >> "$log_file"
              echo "${experiment}" >> "$log_file"
              echo "${R1_file} and ${R2_file}" >> "$log_file"

              # Remove header for processing
              sed -n -e '1,19p' "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_header.sam"
              tail -n +20 "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment.sam"

              # Processing (set pairs in the same row, extract only those aligning both R1 and R2 completely)
              # Consider for further processing only reads pair aligning uniquely
              awk -vOFS='\t' '{$11="AAAAAAAAAAAAAAAAAA"; print}' "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment.sam" | \
              cut -f1-19 | \
              sed '$!N;s/\n/ /' | \
              awk '($3 != $7 && $7 != "=")' | \
              awk '($7 != "*")' | \
              awk '$6 == "18M"' | \
              awk '$25 == "18M"' | \
              awk '$13 == "XN:i:0"' | \
              awk '$32 == "XN:i:0"' | \
              sed 's/ /\t/g' | \
              awk '($19 != "YT:Z:UP")' | \
              awk '($38 != "YT:Z:UP")' > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed.sam"

              # Remove intermediate files
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment.sam"

              # Place read pairs in SAM standard output format
              cut -f1-19 "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R1.sam"
              cut -f20-38 "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R2.sam"
              cat "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R1.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R2.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12.sam"

              # Remove intermediate files
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R1.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R2.sam"

              # Add header back
              cat "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_header.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header.sam"

              # Remove intermediate files
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12.sam"

              # Extract R1 reads that aligned in -m1 -v0 in SR bowtie mapping
              samtools view -N "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_mapped.txt" -o "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header.sam"

              # Extract R2 reads that aligned in -m1 -v0 in SR bowtie mapping
              samtools view -N "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_mapped.txt" -o "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R2.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header.sam"

              # Cat mapping reads
              cat "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R2.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R12.sam"
            
              # Add header back
              cat "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_header.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R12.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs.sam"
              
              # Remove intermediate files
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_header.sam" 
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R12.sam"
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R1.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header_R2.sam"

              # Inter-chromosomal discordant read pairs - unique reads
              awk '!seen[$0]++' "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique.sam"

              # Remove intermediate files
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs.sam"
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed_R12_header.sam"
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_alignment_processed.sam"
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_mapped.txt"
              rm "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}.sam"

              # Extract discordant read pairs for MATa-MATa'
              sed -n -e '1,19p' "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_header.sam"
              awk ' ($3=="CHRIII" && $7=="CHRV" && $8>289178 && $8<290483) ' "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique_R1_MAT.sam"
              awk ' ($3=="CHRV" && $7=="CHRIII" && $4>289178 && $4<290483) ' "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique_R2_MAT.sam"
              cat "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique_R1_MAT.sam" "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique_R2_MAT.sam" > "${strain}/${sample}_${experiment}_${R1_file}_${R2_file}_inter_discordant_pairs_unique_MAT_r18.sam"

            
              echo "" >> "$log_file"  # Adds a blank line
              elapsed_time=$(( SECONDS - start_time ))
              echo "Inter-chromosomal discordant read pairs processing completed in ${elapsed_time} seconds" >> "$log_file"
              echo "" >> "$log_file"  # Adds a blank line 

          

            done
            # Calculate elapsed time
            elapsed_time=$((( SECONDS - start_time_total )))
            echo "Total MATs processing completed in ${elapsed_time} seconds" >> "$log_file"
            echo "" >> "$log_file"  # Adds a blank line 

            rm -f ${strain}/${sample}_${experiment}_*.fastq
            cat ${strain}/${sample}_${experiment}_*_inter_discordant_pairs_unique_MAT_r18.sam > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_noheader_r18.sam"
            #combined_file="${strain}/${sample}_${experiment}_MAT_noheader.sam"
            #find "${strain}" -name '*_inter_discordant_pairs_unique_MAT.sam' -print0 | xargs -0 cat > "$combined_file"
            cat "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_header.sam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_noheader_r18.sam" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.sam"

            #####
            rm -f ${strain}/${sample}_${experiment}_*_pairs_unique.sam
            rm -f ${strain}/${sample}_${experiment}_*_pairs_unique_R1.sam
            rm -f ${strain}/${sample}_${experiment}_*_pairs_unique_R2.sam
            rm -f ${strain}/${sample}_${experiment}_*_unique_header.sam
            rm -f ${strain}/${sample}_${experiment}_*_pairs_unique_R2.sam
            rm -f ${strain}/${sample}_${experiment}_*_unique_MAT_noheader_r18.sam
            ###### remove this too
            rm -f ${strain}/${sample}_${experiment}_R*_MAT.sam
            rm -f ${strain}/${sample}_${experiment}_*_header.sam
            rm -f ${strain}/${sample}_${experiment}_*_noheader_r18.sam
            rm -f ${strain}/${sample}_${experiment}_R*_unique.sam

          else
          echo "Warning: Decompressed files missing for sample $sample in $strain!" >> "$log_file"
          echo "" >> "$log_file"
          fi
        else
        echo "Warning: One or both compressed files for sample $sample are missing in $strain!" >> "$log_file"
        echo "" >> "$log_file"
        fi
        
      done
    done
done







#Coverage for MATa-MATa' discordant read pairs

# MATa-MATa' analysis


# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TLG; do
    for experiment in E1 E2 E3; do
      file_alignment="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.sam"
      if [[ -f "$file_alignment"  ]]; then
        echo "$(basename "$strain") ${sample} ${experiment}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing MATs for $file_alignment" >> "$log_file" 
        start_time_MATs=$SECONDS
        
        # Determine the number of cores available
        N_CPU=$(nproc)
        
        # convert SAM to sorted BAM (75nt)
        start_time=$SECONDS
        samtools sort -@ "$N_CPU" -o "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.bam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.sam"
        samtools index "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.bam" "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.bai"
        elapsed_time=$(( SECONDS - start_time ))
        echo "Bam and Bai 18nt MAT reads completed in ${elapsed_time} seconds" >> "$log_file"

        # Generate BedGraphs coverage files (75nt)
        start_time=$SECONDS
        bamCoverage -b "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.bam" -o "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.bedgraph" -of bedgraph -p "$N_CPU"  -bs 1 --smoothLength 1
        elapsed_time=$(( SECONDS - start_time ))
        echo "Bedgraphs 18nt reads completed in ${elapsed_time} seconds" >> "$log_file"

        # Sorting Bedgraphs files (75nt)
        samtools faidx "${MYREF}/RG_PMV_v9.fasta" # Create index file
        cut -f1,2 "${MYREF}/RG_PMV_v9.fasta.fai" > "${MYREF}/chrom_order.txt"
        bedtools sort -i "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.bedgraph" -g "${MYREF}/chrom_order.txt" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18_sorted.bedgraph"
             
        
        # Generate TSV files (75nt)
        start_time=$SECONDS
        #bedtools coverage -a "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bedgraph" -b "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.bam" -d > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT.tsv"
        bedtools coverage -a "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18_sorted.bedgraph" -b "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18.bam" -sorted -g "${MYREF}/chrom_order.txt" -d > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18_sorted.tsv"
            
        # Keep only coverage for chromosomes CHRIII and CHRV
        awk '$1=="CHRIII" || $1=="CHRV"' "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18_sorted.tsv" > "${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_MAT_complete_r18_filtered.tsv"

        # Remove intermediate files   
        rm "${strain}/${sample}_${experiment}_"*.bai
        rm "${strain}/${sample}_${experiment}_"*.bam
        rm "${strain}/${sample}_${experiment}_"*.bedgraph
        rm -f ${strain}/${sample}_${experiment}_*_MAT_complete_r18_sorted.tsv
       

      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time_MATs )))
        echo "Total MATs processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample/$experiment: $file_alignment" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done

# elapsed_time_total=$(( SECONDS - start_time ))
# echo "Inter-chromosomal discordant read pairs R processing completed in ${elapsed_time} seconds" >> "$log_file"

# Calculate total elapsed time
elapsed_time_total=$((( SECONDS - start_time_total_MATs_18 )/60))
echo "Total MATs processing completed in ${elapsed_time_total} minutes" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line  



# R plots for MATa-MATa' discordant read pairs

# Start timer for R processing

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      #echo "$root_dir"
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Plotting MATa-MATa' coverage" >> "$log_file"
        start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        #echo "ROOT_DIR: $ROOT_DIR"
        #echo "STRAIN: $STRAIN"
        Rscript - <<'EOF'
          # load libraries
          
          library(ggplot2)
          library(extrafont)
          library(svglite)
          library(ggdensity)
          library(purrr)
          library(stringr)
          library(readr)
          library(ggforce)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          options(dplyr.summarise.inform = FALSE)

          # Read environment variables
          root_dir <- Sys.getenv("ROOT_DIR")
          strain <- Sys.getenv("STRAIN")
          strain <- sub("/$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)

          print(paste("ROOT_DIR:", root_dir))

          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          # Define a function to process tsv files
          process_MATs_coverage_files <- function(file_path) {
            # Extract filename and directory parts
            file_base <- basename(file_path)
            strain_name <- basename(dirname(file_path))  # directory name above the file

            # 
            parts <- str_split(file_base, "_", simplify = TRUE)

            # Validate and extract parts safely
            if (ncol(parts) >= 3) {
              sample_name <- parts[1]
              experiment_name <- parts[2]
            } else {
              warning(paste("Filename does not match expected format:", file_base))
              return(NULL)
            }

            # Read file
            temp_file <- read_tsv(file_path, col_names = FALSE, show_col_types = FALSE)

            # Skip if empty
            if (nrow(temp_file) == 0) {
              return(NULL)
            }

            # Prepare coverage dataframe
            coverage_file <- temp_file %>%
              rename("chromosome" = !!names(.[1]), "coverage" = !!names(.[4])) %>%
              select(chromosome, coverage) %>%
              mutate(
                strain = strain_name,
                sample = sample_name,
                experiment = experiment_name
              )

            return(coverage_file)
          }
        

          log_step("Finding MATa-MATa' coverage files...")
          # Get all coverage.tsv files recursively in root folder
          MAT_coverage_files <- list.files(
            path = root_dir,
            pattern = "MAT_complete_r18_filtered\\.tsv$",
            recursive = TRUE,
            full.names = TRUE
          )
          MAT_coverage_files
          log_step("Processing MATa-MATa' coverage files...")
          MATs_processed_df <- purrr::map_dfr(MAT_coverage_files, process_MATs_coverage_files)
          

          log_step("Processing chromosome III...")
          III_df <- MATs_processed_df %>% filter(chromosome == "CHRIII") %>%
            group_by(strain, sample, experiment) %>% 
            mutate(position = row_number(), position_HO_centered = position - 200753) %>%
            ungroup() %>% 
            group_by(strain, sample, chromosome, position, position_HO_centered) %>%
            summarise(mean_coverage = mean(coverage, na.rm = TRUE), sd_coverage = sd(coverage, na.rm = TRUE))

          log_step("Processing chromosome V...")
          V_df <- MATs_processed_df %>% filter(chromosome == "CHRV") %>%
            group_by(strain, sample, experiment) %>% 
            mutate(position = row_number(), position_HO_centered = position - 289825) %>%
            ungroup() %>% 
            group_by(strain, sample, chromosome, position, position_HO_centered) %>%
            summarise(mean_coverage = mean(coverage, na.rm = TRUE), sd_coverage = sd(coverage, na.rm = TRUE))

          MAT_df <- bind_rows(III_df, V_df)
          log_step(paste("Number of samples found:", length(MAT_df)))
          

          # Set polymorphisms positions
          polymorphisms <- tibble(position_HO_centered = c(-634,-586,-541,-481,-427,-367,-304,-244,-211,-178,-118,-64,
                                                 0,64,129,194,259,324,395,454,519,584,649),
                        mean_coverage = rep(c(0)),
                        chromosome = rep(c("polymorphism")))

          log_step("Splitting by sample...")
          # Split by sample
          split_MAT_df <- split(MAT_df, 
                                MAT_df$sample)

          # Set output directory
          #svg_output_dir <- file.path(root_dir, "MAT_plots_r18")
          #dir.create(svg_output_dir, showWarnings = FALSE, recursive = TRUE)
          write_tsv(MAT_df, file.path(root_dir, paste0(strain_name, "_MAT_coverage_r18_df.tsv")))

          
          log_step("Plotting...")
          # Generate plots
          MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
            data_subset <- split_MAT_df[[sample]]
            
            p <- ggplot(data_subset, aes(x = position_HO_centered, y = mean_coverage, color = chromosome)) +
              geom_point(data = polymorphisms, aes(x = position_HO_centered, y = mean_coverage),
                        color = "chartreuse3", shape = 108, size = 5) +
              geom_line(linewidth = 1) + #1.2
              scale_color_manual(values = c("CHRIII" = "#2F2C7E", "CHRV" = "#A30000")) + #2F2C7E, A30000
              theme_classic(base_family = "Arial") +
              theme(
                panel.grid = element_line(color = "black", linewidth = 0.1),
                panel.background = element_blank(),
                plot.background = element_rect(fill = "transparent", colour = NA),
                legend.position = "none",
                aspect.ratio = 0.45,
                plot.title = element_text(hjust = 0.5),
                axis.title.x = element_text(hjust = 1)
              ) +
              theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 20),
              axis.title.y = element_text(vjust = 2, size = 20)) +
              theme(axis.text.x = element_text(vjust = 0, size = 15),
              axis.text.y = element_text(vjust = 0, size = 15)) +
              coord_cartesian(xlim = c(-1200, 1200), ylim = c(0, 30), expand = FALSE) +
              scale_x_continuous(limits = c(-1100, 1100), breaks = seq(-1100, 1100, 200)) +
              scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5)) +
              geom_vline(xintercept = 0, linetype = "dashed", color = "grey3", linewidth = 0.5) +
              labs(
                title = paste0("Average coverage of MATa-MATa' discordant reads r18 - ", strain_name, " - ", sample),
                x = "Relative Coordinate (bp)", #Relative Coordinate (bp)",
                y = "Average Coverage" #Average Coverage"
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("Average_MATa_MATa_coverage_r18_", strain_name, "_", sample, ".svg")),
              plot = p,
              #width = 8,
              #height = 3.6,
              device = svglite,
              bg = "transparent"
            )
            
            return(p)
            
          })

          # Generate plots for chromosome III (only coverage shape)
          MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
            data_subset <- split_MAT_df[[sample]]
            data_subset <- data_subset %>% filter(chromosome == "CHRIII")
            
            p <- ggplot(data_subset, aes(x = position_HO_centered, y = mean_coverage, color = chromosome)) +
              geom_line(linewidth = 1) +
              scale_color_manual(values = c("CHRIII" = "#2F2C7E")) +
              theme_classic(base_family = "Arial") +
              theme(
                panel.grid = element_line(color = "black", linewidth = 0.1),
                panel.background = element_blank(),
                plot.background = element_rect(fill = "transparent", colour = NA),
                legend.position = "none",
                aspect.ratio = 0.25,
                plot.title = element_text(hjust = 0.5),
                axis.title.x = element_text(hjust = 1)
              ) +
              theme(axis.line=element_blank(), axis.ticks=element_blank()) +
              theme(axis.text.x = element_text(vjust = 0, size = 0),
              axis.text.y = element_text(vjust = 0, size = 0))+
              coord_cartesian(xlim = c(-1200, 1200), ylim = c(0, 30), expand = FALSE) +
              scale_x_continuous(limits = c(-1100, 1100), breaks = seq(-1100, 1100, 200)) +
              scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5)) +
              labs(
                title = paste0("Average coverage of MATa-MATa' discordant reads chrIII r18 - ", strain_name, " - ", sample),
                x = "",
                y = ""
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("Average_MATa_MATa_coverage_r18_chrIII_", strain_name, "_", sample, ".svg")),
              plot = p,
              width = 8,
              height = 3.6,
              device = svglite,
              bg = "transparent"
            )
            
            return(p)
            
          })

          # Generate plots for chromosome V (only coverage shape)
          MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
            data_subset <- split_MAT_df[[sample]]
            data_subset <- data_subset %>% filter(chromosome == "CHRV")
            
            p <- ggplot(data_subset, aes(x = position_HO_centered, y = mean_coverage, color = chromosome)) +
              geom_line(linewidth = 1) +
              scale_color_manual(values = c("CHRV" = "#A30000")) +
              theme_classic(base_family = "Arial") +
              theme(
                panel.grid = element_line(color = "black", linewidth = 0.1),
                panel.background = element_blank(),
                plot.background = element_rect(fill = "transparent", colour = NA),
                legend.position = "none",
                aspect.ratio = 0.25,
                plot.title = element_text(hjust = 0.5),
                axis.title.x = element_text(hjust = 1)
              ) +
              theme(axis.line=element_blank(), axis.ticks=element_blank()) +
              theme(axis.text.x = element_text(vjust = 0, size = 0),
              axis.text.y = element_text(vjust = 0, size = 0))+
              coord_cartesian(xlim = c(1200, -1200), ylim = c(0, 30), expand = FALSE) +
              scale_x_continuous(limits = c(-1100, 1100), breaks = seq(-1100, 1100, 200)) +
              scale_y_continuous(limits = c(0, 30), breaks = seq(0, 30, 5)) +
              labs(
                title = paste0("Average coverage of MATa-MATa' discordant reads chrV r18 - ", strain_name, " - ", sample),
                x = "",
                y = ""
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("Average_MATa_MATa_coverage_r18chrV_", strain_name, "_", sample, ".svg")),
              plot = p,
              width = 8,
              height = 3.6,
              device = svglite,
              bg = "transparent"
            )
            
            return(p)
            
          })

          # Define a function to process sam files
          process_MATs_pairs_files <- function(file_path) {
            # Extract filename and directory parts
            file_base <- basename(file_path)
            strain_name <- basename(dirname(file_path))  # directory name above the file
            
            
            parts <- str_split(file_base, "_", simplify = TRUE)
            
            # Validate and extract parts safely
            if (ncol(parts) >= 3) {
              sample_name <- parts[1]
              experiment_name <- parts[2]
            } else {
              warning(paste("Filename does not match expected format:", file_base))
              return(NULL)
            }
            
            # Read file
            temp_file <- read_tsv(file_path, skip = 19, col_names = FALSE, show_col_types = FALSE)
            
            # Skip if empty
            if (nrow(temp_file) == 0) {
              return(NULL)
            }
            
            # Prepare coverage dataframe
            pairs_file <- temp_file %>%
              rename("chromosome_A" = !!names(.[3]), "position_A" = !!names(.[4]),
                    "chromosome_B" = !!names(.[7]), "position_B" = !!names(.[8])) %>%
              select(chromosome_A, position_A, chromosome_B, position_B) %>%
              mutate(
                strain = strain_name,
                sample = sample_name,
                experiment = experiment_name
              )
            
            return(pairs_file)
          }

          log_step("Finding MATa-MATa' pairs files...")
          # Get all pairs files recursively in root folder
          MAT_pairs_files <- list.files(
            path = root_dir,
            pattern = "unique_MAT_complete_r18\\.sam$",
            recursive = TRUE,
            full.names = TRUE
          )
          MAT_pairs_files
          log_step("Processing MATa-MATa' pairs files...")
          MATs_pairs_processed_df <- purrr::map_dfr(MAT_pairs_files, process_MATs_pairs_files)

          MAT_pairs_III <- MATs_pairs_processed_df %>% filter(chromosome_A == "CHRIII" & chromosome_B == "CHRV") %>% 
            rename(X_value_III = position_A, Y_value_V = position_B) %>% 
            select(X_value_III, Y_value_V, strain, sample, experiment)

          MAT_pairs_V <- MATs_pairs_processed_df %>% filter(chromosome_A == "CHRV" & chromosome_B == "CHRIII") %>% 
            rename(X_value_III = position_B, Y_value_V = position_A) %>% 
            select(X_value_III, Y_value_V, strain, sample, experiment)

          MAT_combined <- bind_rows(MAT_pairs_III, MAT_pairs_V)
          log_step("Saving MATa-MATa' pairs files...")
          write_tsv(MAT_combined, file.path(root_dir, paste0(strain_name, "_MAT_pairs_r18_df.tsv")))

          # ### Calculate proportion of GC and CO events

          log_step("Calculating proportion of GC and CO events...")

          poly_III <- tibble(Polymorphism = c("P_-12","P_-11","P_-10","P_-9","P_-8","P_-7","P_-6",
                                    "P_-5","P_-4","P_-3","P_-2","P_-1","P_0","P_1","P_2",
                                    "P_3","P_4","P_5","P_6","P_7","P_8","P_9","P_10"),
                   Start = c(200102,200150,200195,200255,200309,200369,200432,
                             200492,200525,200558,200618,200672,200736,200800,200865,
                             200930,200995,201060,201131,201190,201255,201320,201385),
                   End = c(200136,200184,200229,200289,200343,200403,200466,
                           200526,200559,200592,200652,200706,200770,200834,200899,
                           200964,201029,201094,201165,201224,201289,201354,201419))

          poly_V <- tibble(Polymorphism = c("P_-12","P_-11","P_-10","P_-9","P_-8","P_-7","P_-6",
                                              "P_-5","P_-4","P_-3","P_-2","P_-1","P_0","P_1","P_2",
                                              "P_3","P_4","P_5","P_6","P_7","P_8","P_9","P_10"),
                            Start = c(289174,289222,289267,289327,289381,289441,289504,
                                      289564,289597,289630,289690,289744,289808,289872,289937,
                                      290002,290067,290132,290203,290262,290327,290392,290457),
                            End = c(289208,289256,289301,289361,289415,289475,289538,
                                    289598,289631,289664,289724,289778,289842,289906,289971,
                                    290036,290101,290166,290237,290296,290361,290426,290491))


          process_MATs_18 <- function(MAT_combined_df, poly_III_df, poly_V_df){
            breaks_V <- c(poly_V_df$Start, tail(poly_V_df$End, 1))
            breaks_III <- c(poly_III_df$Start, tail(poly_III_df$End, 1))
            MAT_combined_df$Polymorphism_V <- cut(MAT_combined_df$Y_value_V, 
                                              breaks = breaks_V, 
                                              labels = poly_V_df$Polymorphism,
                                              include.lowest = FALSE,
                                              right = FALSE)
            
            MAT_combined_df$Polymorphism_III <- cut(MAT_combined_df$X_value_III, 
                                                breaks = breaks_III, 
                                                labels = poly_III_df$Polymorphism,
                                                include.lowest = FALSE,
                                                right = FALSE)
            
            MAT_combined <- MAT_combined_df %>% mutate(III_HO_centered = X_value_III - 200753,
                                                    V_HO_centered = Y_value_V -289825,
                                                    abs = abs(III_HO_centered) - abs(V_HO_centered),
                                                    left_right = ifelse(X_value_III <= 200753, "left", "right"),
                                                    group = ifelse(left_right == "left" & abs > 0, 1,
                                                                  ifelse(left_right == "left" & abs < 0, 4,
                                                                          ifelse(left_right == "right" & abs > 0, 3,
                                                                                ifelse(left_right == "right" & abs < 0, 2, NA_real_)))),
                                                    GC_CO = ifelse(group == 1 | group == 3, "GC", "CO"),
                                                    group_GC = ifelse(group == 1, "GC_left",
                                                               ifelse(group == 3 & X_value_III < 200834, "GC_left",
                                                                      ifelse(group ==3 & X_value_III > 200834, "GC_right", 
                                                                             ifelse(group == 2, "d_GC_right",
                                                                                    ifelse(group == 4, "d_GC_left", NA_real_))))))
            
            MAT_combined_A <- MAT_combined %>% mutate(start = ifelse(group == 1, -1.5708,
                                                                    ifelse(group == 2, -1.5708,
                                                                            ifelse(group == 3, 1.5708,
                                                                                  ifelse(group == 4, 1.5708, NA_real_))))) %>% 
              mutate(AB = rep(c("A")))
            
            MAT_combined_B <- MAT_combined %>% mutate(start = ifelse(group == 1, 1.5708,
                                                                    ifelse(group == 2, 1.5708,
                                                                            ifelse(group == 3, -1.5708,
                                                                                  ifelse(group == 4, -1.5708, NA_real_))))) %>% 
              mutate(AB = rep(c("B")))
            
            MAT_combined_AB <- bind_rows(MAT_combined_A, MAT_combined_B)
            
            return(MAT_combined_AB)
            
          }


          MAT_combined_processed <- process_MATs_18(MAT_combined, poly_III, poly_V)

          

          write_tsv(MAT_combined_processed, file.path(root_dir, paste0(strain_name, "_MAT_pairs_r18_processed_df.tsv")))

          log_step("Calculating GC and CO distribution...")

          GC_CO_summary <- MAT_combined_processed %>% filter(AB == "A") %>% 
            select(strain, sample, experiment, GC_CO) %>% 
            group_by(strain, sample, experiment, GC_CO) %>% 
            summarise(n_experiment = n()) %>%
            mutate(total_experiment = sum(n_experiment)) %>%                  
            mutate(percentage_experiment = 100 * n_experiment / total_experiment) %>%         
            ungroup() %>% select(!c(n_experiment, total_experiment)) 

          # Define the fixed order of groups
          GC_CO_levels <- c("GC", "CO")

          GC_CO_combined_summary <- GC_CO_summary %>% 
            complete(strain, sample, experiment, GC_CO = GC_CO_levels, fill = list(percentage_experiment = 0)) %>% 
            group_by(strain, sample, GC_CO) %>% 
            summarise(average_percentage = mean(percentage_experiment, na.rm = TRUE),
                      sd_percentage = sd(percentage_experiment, na.rm = TRUE)) %>%
            ungroup()

          write_tsv(GC_CO_combined_summary, file.path(root_dir, paste0(strain_name, "_MAT_pairs_r18_GC_CO_summary_df.tsv")))

          # Define the fixed order of groups
          GC_CO_levels <- c("GC", "CO")

          # Set the GC_CO factor with all levels
          GC_CO_combined_summary <-GC_CO_combined_summary %>%
            mutate(GC_CO = factor(GC_CO, levels = GC_CO_levels))

          GC_CO_combined_summary <-GC_CO_combined_summary %>%
            complete(sample, GC_CO = GC_CO_levels,
            fill = list(average_percentage = 0, sd_percentage = 0))


          log_step("Calculating GC groups distribution...")


          GC_groups_summary <- MAT_combined_processed %>% filter(AB == "A") %>% 
            select(strain, sample, experiment, group_GC) %>% 
            group_by(strain, sample, experiment, group_GC) %>% 
            summarise(n_experiment = n()) %>%
            mutate(total_experiment = sum(n_experiment)) %>%                  
            mutate(percentage_experiment = 100 * n_experiment / total_experiment) %>%         
            ungroup() %>% select(!c(n_experiment, total_experiment)) 

          all_groups <- c("GC_left", "GC_right", "d_GC_left", "d_GC_right")
          GC_groups_combined_summary <- GC_groups_summary %>% 
            complete(strain, sample, experiment, group_GC = all_groups, fill = list(percentage_experiment = 0)) %>% 
            group_by(strain, sample, group_GC) %>%
            summarise(average_percentage = mean(percentage_experiment, na.rm = TRUE),
                      sd_percentage = sd(percentage_experiment, na.rm = TRUE)) %>%
            ungroup()

          write_tsv(GC_groups_combined_summary, file.path(root_dir, paste0(strain_name, "_MAT_pairs_r18_groups_summary_df.tsv")))

          # Define the fixed order of groups
          GC_groups_levels <- c("GC_left", "GC_right", "d_GC_left", "d_GC_right")

          # Set the group factor with all levels
          GC_groups_combined_summary <-GC_groups_combined_summary %>%
            mutate(GC_group = factor(group_GC, levels = GC_groups_levels))

          GC_groups_combined_summary <-GC_groups_combined_summary %>%
            complete(sample, GC_group = GC_groups_levels,
            fill = list(average_percentage = 0, sd_percentage = 0))


          # Calculate proportion of polymorphism insertion for each polymorphism (III and V) - total-reads
          
          MAT_r18_count_total_reads <- MAT_combined_processed %>% filter(AB == "A") %>% 
            select(X_value_III, Y_value_V, strain, sample, experiment, Polymorphism_V, Polymorphism_III) %>% 
            pivot_longer(cols= !c(X_value_III, Y_value_V, strain, sample, experiment)) %>% 
            rename(chromosome = name, polymorphism = value) %>% 
            group_by(strain, sample, experiment, chromosome, polymorphism) %>% 
            summarise(n_experiment = n()) %>%
            mutate(total_experiment = sum(n_experiment)) %>%                  
            mutate(percentage_experiment = 100 * n_experiment / total_experiment) %>%         
            ungroup() %>% select(!c(n_experiment, total_experiment)) 

          # Define the fixed order of polymorphisms
          polymorphism_levels <- c("P_-12","P_-11","P_-10","P_-9","P_-8","P_-7","P_-6",
                                  "P_-5","P_-4","P_-3","P_-2","P_-1","P_0","P_1","P_2",
                                  "P_3","P_4","P_5","P_6","P_7","P_8","P_9","P_10")

          MAT_r18_count_total_reads_summary <- MAT_r18_count_total_reads %>% 
            complete(strain, sample, chromosome, experiment, polymorphism = polymorphism_levels, fill = list(percentage_experiment = 0)) %>%
            group_by(strain, sample, chromosome, polymorphism) %>% 
            summarise(average_percentage = mean(percentage_experiment, na.rm = TRUE),
                      sd_percentage = sd(percentage_experiment, na.rm = TRUE)) %>% 
            ungroup()

          #   # Define the fixed order of polymorphisms
          # polymorphism_levels <- c("P_-12","P_-11","P_-10","P_-9","P_-8","P_-7","P_-6",
          #                         "P_-5","P_-4","P_-3","P_-2","P_-1","P_0","P_1","P_2",
          #                         "P_3","P_4","P_5","P_6","P_7","P_8","P_9","P_10")

          # Set the polymorphism factor with all levels
          MAT_r18_count_total_reads_summary <- MAT_r18_count_total_reads_summary %>%
            mutate(polymorphism = factor(polymorphism, levels = polymorphism_levels)) 

          MAT_r18_count_total_reads_summary <- MAT_r18_count_total_reads_summary %>%
            complete(sample, polymorphism = polymorphism_levels, chromosome,
            fill = list(average_percentage = 0, sd_percentage = 0))

          

          write_tsv(MAT_r18_count_total_reads_summary, file.path(root_dir, paste0(strain_name, "_MAT_pairs_r18_count_total_reads_summary_df.tsv")))

          # Calculate proportion of polymorphism insertion for each polymorphism (III and V) - HOinc-reads

          MAT_r18_count_HOinc_reads <- MAT_combined_processed %>% filter(AB == "A") %>% 
            select(X_value_III, Y_value_V, strain, sample, experiment, Polymorphism_V, Polymorphism_III) %>% 
            pivot_longer(cols= !c(X_value_III, Y_value_V, strain, sample, experiment)) %>% 
            rename(chromosome = name, polymorphism = value) %>% 
            group_by(strain, sample, experiment, chromosome, polymorphism) %>% 
            summarise(n_HOinc = n(), .groups = "drop") %>%
            mutate(n_P0_V = if_else(polymorphism == "P_0", n_HOinc, 0L)) %>% 
            group_by(strain, sample, experiment) %>% 
            mutate(n_P0_V_total = sum(n_P0_V, na.rm = TRUE)) %>%
            rename(count = n_HOinc) %>% 
            select(!c(n_P0_V)) %>% 
            mutate(percentage_experiment = 100 * count / n_P0_V_total) %>%         
            ungroup() %>% select(!c(count, n_P0_V_total)) 


          MAT_r18_count_HOinc_reads_summary <- MAT_r18_count_HOinc_reads %>% 
            complete(strain, sample, chromosome, experiment, polymorphism = polymorphism_levels, fill = list(percentage_experiment = 0)) %>%
            group_by(strain, sample, chromosome, polymorphism) %>% 
            summarise(average_percentage = mean(percentage_experiment, na.rm = TRUE),
                      sd_percentage = sd(percentage_experiment, na.rm = TRUE)) %>% 
            ungroup()

          # Define the fixed order of polymorphisms
          polymorphism_levels <- c("P_-12","P_-11","P_-10","P_-9","P_-8","P_-7","P_-6",
                                  "P_-5","P_-4","P_-3","P_-2","P_-1","P_0","P_1","P_2",
                                  "P_3","P_4","P_5","P_6","P_7","P_8","P_9","P_10")

          # Set the polymorphism factor with all levels
          MAT_r18_count_HOinc_reads_summary <- MAT_r18_count_HOinc_reads_summary %>%
            mutate(polymorphism = factor(polymorphism, levels = polymorphism_levels))
          
          MAT_r18_count_HOinc_reads_summary <- MAT_r18_count_HOinc_reads_summary %>%
            complete(sample, polymorphism = polymorphism_levels, chromosome,
            fill = list(average_percentage = 0, sd_percentage = 0))

          write_tsv(MAT_r18_count_HOinc_reads_summary, file.path(root_dir, paste0(strain_name, "_MAT_pairs_r18_count_HOinc_reads_summary_df.tsv")))



          # GC_CO plotting

          split_MAT_df <- split(MAT_combined_processed, 
                                MAT_combined_processed$sample)


          log_step("Plotting...")
          # Generate plots for MATa-MATa' pairs
          MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
            data_subset <- split_MAT_df[[sample]]
            
            p <- ggplot(data_subset) + theme_light(base_family = "Arial") +
              geom_arc_bar(aes(x0 = X_value_III, y0 = Y_value_V, r0 = 0, r = 35,
                              start = (start)+(pi/2), end = (start)+(pi/2) + pi, fill = AB),
                          color = NA, alpha = 0.15) +
              scale_fill_manual(values = c("A" = "#A30000", "B" = "#2F2C7E")) +
              #scale_fill_manual(values = c("A" = "#B86029", "B" = "#081D5C")) +
              coord_cartesian(xlim = c(199653,201853), ylim = c(288725, 290925), expand=FALSE) +
              scale_x_continuous(limits = c(199653, 201853),
                                breaks = seq(199653,201853,1100),
                                expand = FALSE) +
              scale_y_continuous(limits = c(288725, 290925),
                                breaks = seq(288725, 290925, 1100)) +
              geom_vline(xintercept=c(200753),
                        linetype="dashed", color = "grey3", linewidth=0.1) +
              geom_hline(yintercept=c(289825),
                        linetype="dashed", color = "grey3", linewidth=0.1) +
              theme_bw(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                          panel.background = element_blank()) +
              theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) +
              theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank()) +
              theme(legend.position="none") + 
              theme(aspect.ratio = 1) + 
              labs(
                title = paste0("MATa-MATa' discordant reads pairs r18 - ", strain_name, " - ",sample),
                x = "Chr.III coordinates",
                y = "Chr.V coordinates"
              )
            
            # Save SVG
            ggsave(
              filename = file.path(root_dir, paste0("MATa_MATa_pairs_r18_", strain_name, "_", sample, ".svg")),
              plot = p,
              width = 8,
              height = 3.6,
              device = svglite,
              bg = "transparent"
            )
            
            return(p)
            
          })


          
        
        # Bar plot distribution of polymorphisms vs HOinc reads
        MAT_r18_count_HOinc_reads_summary<- MAT_r18_count_HOinc_reads_summary %>%
          mutate(polymorphism = factor(polymorphism, levels = polymorphism_levels)) %>%
          filter(polymorphism != "NA")

        split_MAT_df <- split(MAT_r18_count_HOinc_reads_summary, 
                              MAT_r18_count_HOinc_reads_summary$sample)


        log_step("Plotting...")
        # Generate plots for MATa-MATa' pairs distribution
        MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
          data_subset <- split_MAT_df[[sample]]
          
          p <- ggplot(data_subset, aes(x = polymorphism, y = average_percentage, fill = chromosome)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = average_percentage - sd_percentage, ymax = average_percentage + sd_percentage), 
                          linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
            scale_fill_manual(values=c("#2F2C7E", "#A30000")) +
            #scale_fill_manual(values=c("#081D5C", "#B86029")) +
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(ylim = c(0, 100),expand=FALSE) +
            theme(aspect.ratio = 1) + 
            scale_x_discrete(drop = FALSE) +
            scale_y_continuous(name = expression("Percentage"),
                              #limits = c(0, 100),
                              breaks = seq(0,100,10)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 15),  #25
                  axis.title.y = element_text(vjust = 1, size = 15)) + 
            theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 10, angle = 90), #20
                  axis.text.y = element_text(vjust = 0, size = 10)) +
            labs(
              title = paste0("MATa-MATa' poly distribution vs HOinc r18 - ", strain_name, " - ",sample),
              x = "Polymorphism",
              y = "Percentage"
            )
          
          # Save SVG
          ggsave(
            filename = file.path(root_dir, paste0("MATa_MATa_poly_distrib_vs_HOinc_r18_", strain_name, "_", sample, ".svg")),
            plot = p,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
          
          return(p)
          
        })

        # Bar plot distribution of polymorphisms vs total reads for III or V
        MAT_r18_count_HOinc_reads_summary<- MAT_r18_count_total_reads_summary %>%
          mutate(polymorphism = factor(polymorphism, levels = polymorphism_levels)) %>%
          filter(polymorphism != "NA")

        split_MAT_df <- split(MAT_r18_count_HOinc_reads_summary, 
                              MAT_r18_count_HOinc_reads_summary$sample)


        log_step("Plotting...")
        # Generate plots for MATa-MATa' pairs distribution
        MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
          data_subset <- split_MAT_df[[sample]]
          
          p <- ggplot(data_subset, aes(x = polymorphism, y = average_percentage, fill = chromosome)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = average_percentage - sd_percentage, ymax = average_percentage + sd_percentage), 
                          linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
            scale_fill_manual(values=c("#2F2C7E", "#A30000")) +
            #scale_fill_manual(values=c("#081D5C", "#B86029")) +
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(ylim = c(0, 100), expand=FALSE) +
            theme(aspect.ratio = 0.45) + 
            scale_x_discrete(drop = FALSE) +
            scale_y_continuous(name = expression("Percentage"),
                              #limits = c(0, 100),
                              breaks = seq(0,100,20)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 20), 
                  axis.title.y = element_text(vjust = 1, size = 20)) + 
            theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 15, angle = 90), 
                  axis.text.y = element_text(vjust = 0, size = 15)) +
            labs(
              title = paste0("MATa-MATa' poly distribution vs total r18 - ", strain_name, " - ",sample),
              x = "Polymorphism",
              y = "Percentage"
            )
          
          # Save SVG
          ggsave(
            filename = file.path(root_dir, paste0("MATa_MATa_poly_distrib_vs_total_r18_", strain_name, "_", sample, ".svg")),
            plot = p,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
          
          return(p)
          
        })

        # Bar plot of GC or CO
      
        split_MAT_df <- split(GC_CO_combined_summary, 
                              GC_CO_combined_summary$sample)


        log_step("Plotting...")
        # Generate plots for GC-CO
        MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
          data_subset <- split_MAT_df[[sample]]
          
          p <- ggplot(data_subset, aes(x = GC_CO, y = average_percentage, fill = GC_CO)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = average_percentage - sd_percentage, ymax = average_percentage + sd_percentage), 
                          linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
            #scale_fill_manual(values=c("black", "chartreuse3")) +
            scale_fill_manual(values = c("CO" = "black", "GC" = "chartreuse3")) + 
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(ylim = c(0, 100),expand=FALSE) +
            theme(aspect.ratio = 1) + 
            scale_x_discrete(drop = FALSE) +
            scale_y_continuous(name = expression("Percentage"),
                              #limits = c(0, 100),
                              breaks = seq(0,100,10)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                  axis.title.y = element_text(vjust = 1, size = 25)) + 
            theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 20, angle = 90), 
                  axis.text.y = element_text(vjust = 0, size = 20)) +
            labs(
              title = paste0("GC vs CO percentage - ", strain_name, " - ",sample),
              x = "Repair product",
              y = "Percentage"
            )
          
          # Save SVG
          ggsave(
            filename = file.path(root_dir, paste0("MATa_MATa_GC_CO_r18_", strain_name, "_", sample, ".svg")),
            plot = p,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
          
          return(p)
          
        })

        # Bar plot of GC groups
      
        split_MAT_df <- split(GC_groups_combined_summary, 
                              GC_groups_combined_summary$sample)


        log_step("Plotting...")
        # Generate plots for GC-groups
        MAT_plot_list <- lapply(names(split_MAT_df), function(sample) {
          data_subset <- split_MAT_df[[sample]]
          
          p <- ggplot(data_subset, aes(x = GC_group, y = average_percentage, fill = GC_group)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = average_percentage - sd_percentage, ymax = average_percentage + sd_percentage), 
                          linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
            #scale_fill_manual(values=c("black", "chartreuse3")) +
            #scale_fill_manual(values = c("CO" = "black", "GC" = "chartreuse3")) + 
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(ylim = c(0, 100), expand=FALSE) +
            theme(aspect.ratio = 1) + 
            scale_x_discrete(drop = FALSE) +
            scale_y_continuous(name = expression("Percentage"),
                              #limits = c(0, 100),
                              breaks = seq(0,100,10)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                  axis.title.y = element_text(vjust = 1, size = 25)) + 
            theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 20, angle = 90), 
                  axis.text.y = element_text(vjust = 0, size = 20)) +
            labs(
              title = paste0("GC group percentage - ", strain_name, " - ",sample),
              x = "Repair product",
              y = "Percentage"
            )
          
          # Save SVG
          ggsave(
            filename = file.path(root_dir, paste0("MATa_MATa_GC_group_r18_", strain_name, "_", sample, ".svg")),
            plot = p,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
          
          return(p)
          
        })

   
          
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total R processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 

done

# Calculate alignment and processing total elapsed time
elapsed_time_total_r18=$((( SECONDS - start_time_total_MATs_18 )/60))
echo "================================" >> "$log_file"
echo "" >> "$log_file"
echo "ALIGNMENT AND SAM PROCESSING COMPLETED IN ${elapsed_time_total_r18} MINUTES" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line


##### MODULE MATs - DATA ORGANIZATION #####
# Move data into subfolders
for subdir in "$MYWD"*/; do
  mkdir -p "${subdir}/Discordant_alignments" "${subdir}/Discordant_MAT_analysis"
  mkdir -p "${subdir}/Discordant_alignments/FASTQP_75nt" "${subdir}/Discordant_alignments/FASTQP_18nt" "${subdir}/Discordant_alignments/SAM_75nt" "${subdir}/Discordant_alignments/SAM_18nt" 
  mkdir -p "${subdir}/Discordant_MAT_analysis/MAT_Data_75nt" "${subdir}/Discordant_MAT_analysis/MAT_Plots_75nt" "${subdir}/Discordant_MAT_analysis/MAT_Data_18nt" "${subdir}/Discordant_MAT_analysis/MAT_Plots_18nt" 
  
  mv "${subdir}"/*_75nt.fastq.html "${subdir}/Discordant_alignments/FASTQP_75nt/" 2> /dev/null
  mv "${subdir}"/*_75nt.fastq.json "${subdir}/Discordant_alignments/FASTQP_75nt/" 2> /dev/null
  mv "${subdir}"/*_18nt.fastq.html "${subdir}/Discordant_alignments/FASTQP_18nt/" 2> /dev/null
  mv "${subdir}"/*_18nt.fastq.json "${subdir}/Discordant_alignments/FASTQP_18nt/" 2> /dev/null

  mv "${subdir}"/*_inter_discordant_pairs_unique_MAT_filtered.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_MAT.sam "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null

  mv "${subdir}"/*_inter_discordant_pairs_unique_MAT_complete_r18_filtered.tsv "${subdir}/Discordant_alignments/SAM_18nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_MAT_complete_r18.sam "${subdir}/Discordant_alignments/SAM_18nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_MAT_r18.sam "${subdir}/Discordant_alignments/SAM_18nt/" 2> /dev/null

  mv "${subdir}"/*_MAT_coverage_r18_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_18nt/" 2> /dev/null
  mv "${subdir}"/*_MAT_pairs_r18_count_HOinc_reads_summary_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_18nt/" 2> /dev/null
  mv "${subdir}"/*_MAT_pairs_r18_count_total_reads_summary_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_18nt/" 2> /dev/null
  mv "${subdir}"/*_MAT_pairs_r18_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_18nt/" 2> /dev/null
  mv "${subdir}"/*_MAT_pairs_r18_GC_CO_summary_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_18nt/" 2> /dev/null
  mv "${subdir}"/*_MAT_pairs_r18_groups_summary_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_18nt/" 2> /dev/null
  mv "${subdir}"/*_MAT_pairs_r18_processed_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_18nt/" 2> /dev/null

  mv "${subdir}"/MATa_MATa_GC_CO_r18_*.svg "${subdir}/Discordant_MAT_analysis/MAT_Plots_18nt/" 2> /dev/null
  mv "${subdir}"/MATa_MATa_GC_group_r18_*.svg "${subdir}/Discordant_MAT_analysis/MAT_Plots_18nt/" 2> /dev/null
  mv "${subdir}"/MATa_MATa_pairs_r18_*.svg "${subdir}/Discordant_MAT_analysis/MAT_Plots_18nt/" 2> /dev/null
  mv "${subdir}"/MATa_MATa_poly_*.svg "${subdir}/Discordant_MAT_analysis/MAT_Plots_18nt/" 2> /dev/null
  mv "${subdir}"/Average_MATa_MATa_coverage_r18*.svg "${subdir}/Discordant_MAT_analysis/MAT_Plots_18nt/" 2> /dev/null

  mv "${subdir}"/*_MAT_coverage_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_MAT_pairs_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_MAT_pairs_summary_df.tsv "${subdir}/Discordant_MAT_analysis/MAT_Data_75nt/" 2> /dev/null

  mv "${subdir}"/Average_MATa_MATa_coverage_*.svg "${subdir}/Discordant_MAT_analysis/MAT_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/MATa_MATa_pairs_*.svg  "${subdir}/Discordant_MAT_analysis/MAT_Plots_75nt/" 2> /dev/null

done
  

##### MODULE MATs - END #####


##### MODULE WHOLE GENOME ANALYSIS - START #####

############## R processing of 75bp reads ############

# R processing for inter-chromosomal discordant read pairs
# After processing all samples, all discordant pairs are associated to their genomic features
# and only discordant pairs not present at T0 are kept for further BLAST validation.

start_time_total_R=$SECONDS


echo "================================" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
echo "### R processing for new discordant read pairs, 75bp analysis ###" >> "$log_file"
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Initiated at ${current_time}" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line 

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
    for experiment in E1 E2 E3; do
      echo "### $(basename "$strain")/${sample} ${experiment} ###" >> "$log_file"
      echo "" >> "$log_file"  # Adds a blank line
      file1="${strain}/T0_${experiment}_inter_discordant_pairs_unique.tsv"
      file2="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique.tsv"
      if [[ -f "$file1" && -f "$file2" ]]; then
        # echo "$(basename "$strain") ${sample} ${experiment}" >> "$log_file"
        # echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant tsv files for $file1 and $file2" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries
          
          library(readr)
          library(stringr)
          library(extrafont)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          category_path <- "${CATEGORY_PATH}"
          strain <- "${strain}"
          sample <- "${sample}"
          experiment <- "${experiment}" 
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"

          
        
          path_to_categories_file <- file.path(category_path, "PMV_categories.tsv")
          path_to_categories_near_file <- file.path(category_path, "PMV_categories_near.tsv")

          # Load categories dataframe 
          # and categories_near_features dataframe
          df_categories <- read_tsv(path_to_categories_file,col_names = FALSE, show_col_types = FALSE)
          df_categories <- type.convert(df_categories, as.is = TRUE)
          df_categories_near_features <- read_tsv(path_to_categories_near_file,col_names = TRUE, show_col_types = FALSE)


          chromosomes <- c(
            "CHRI", "CHRII", "CHRIII", "CHRIV", "CHRV", "CHRVI", "CHRVII",
            "CHRVIII", "CHRIX", "CHRX", "CHRXI", "CHRXII", "CHRXIII", 
            "CHRXIV", "CHRXV", "CHRXVI", "CHRDISC")

          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
            }
          process_df_categories_file <- function(df_categories_file, chromosomes_vector) {
            # Rename columns 
            all_df <- df_categories_file %>%
              rename(
                Category = !!names(.)[1],
                Feature_name = !!names(.)[2],
                Start_pos = !!names(.)[3],
                End_pos = !!names(.)[4],
                Chromosome = !!names(.)[5]
              )
            
            # Create a list to store results
            result_list <- list()
            
            for (chrom in chromosomes_vector) {
              # Filter by chromosome
              df_chrom <- filter(all_df, Chromosome == chrom)
              
              # If empty, skip
              if (nrow(df_chrom) == 0) next
              
              # For each unique Feature_name create a dataframe subset
              list_of_dfs <- lapply(unique(df_chrom\$Feature_name), function(feat) {
                df_sub <- df_chrom %>%
                  filter(Feature_name == feat) %>%
                  select(Chromosome, Start_pos, End_pos, Category)
                df_sub\$Feature_name <- feat
                df_sub
              })
              
              # Convert factor columns to proper types
              list_of_dfs <- lapply(list_of_dfs, function(x) type.convert(x, as.is = TRUE))
              
              names(list_of_dfs) <- unique(df_chrom\$Feature_name)
              
              # Store in result list with chromosome name
              result_list[[chrom]] <- list_of_dfs
            }
            
            return(result_list)
          }


          filter_by_chromosome_A <- function(discordant_pairs_file, chromosomes_vector, df_categories_list_file) {
            
            chromosome_A_filter_results <- list()
            
            for (i in seq_along(chromosomes)) {
              chrom <- chromosomes[i]
              df_chr <- discordant_pairs_file %>% filter(Chr_name_A == chrom)
              
              list_of_dfs_chr <- df_categories_list_file[[i]]
              
              filtered_data_list <- list()
              
              for (j in seq_along(list_of_dfs_chr)) {
                current_df <- list_of_dfs_chr[[j]]
                
                filtered_data <- df_chr %>%
                  filter(Start_pos_A >= current_df\$Start_pos, Start_pos_A <= current_df\$End_pos)
                
                filtered_data\$Feature_name_A <- current_df\$Feature_name
                filtered_data\$Category_A <- current_df\$Category
                filtered_data\$Chromosome_A <- current_df\$Chromosome
                
                filtered_data_list[[j]] <- filtered_data
              }
              
              chromosome_A_filter_results[[i]] <- bind_rows(filtered_data_list)
            }
            
            chromosome_A_filter_results_complete <- bind_rows(chromosome_A_filter_results) %>% unique()
            return(chromosome_A_filter_results)
          }

          filter_by_chromosome_B <- function(df_chr_A_filtered_file, chromosomes_vector, df_categories_list_file) {
            
            chromosome_B_filter_results <- list()
            
            for (i in seq_along(chromosomes)) {
              chrom <- chromosomes[i]
              df_chr <- df_chr_A_filtered_file %>% filter(Chr_name_B == chrom)
              
              list_of_dfs_chr <- df_categories_list_file[[i]]
              
              filtered_data_list <- list()
              
              for (j in seq_along(list_of_dfs_chr)) {
                current_df <- list_of_dfs_chr[[j]]
                
                filtered_data <- df_chr %>%
                  filter(Start_pos_B >= current_df\$Start_pos, Start_pos_B <= current_df\$End_pos)
                
                filtered_data\$Feature_name_B <- current_df\$Feature_name
                filtered_data\$Category_B <- current_df\$Category
                filtered_data\$Chromosome_B <- current_df\$Chromosome
                
                filtered_data_list[[j]] <- filtered_data
              }
              
              chromosome_B_filter_results[[i]] <- bind_rows(filtered_data_list)
            }
            
            chromosome_B_filter_results_complete <- bind_rows(chromosome_B_filter_results) %>% unique()
            return(chromosome_B_filter_results)
          }

          prepare_for_blast <- function(df_chr_AB_filtered_file_X_ID) {
            blast_df <- df_chr_AB_filtered_file_X_ID %>% 
              filter (Category_A != "control") %>% 
              filter(Category_A != "control_norm") %>% 
              filter (Category_B != "control") %>% 
              filter(Category_B != "control_norm") %>% 
              mutate(Read_name_ID = with(., paste0(Read_name, "_", pair_group))) %>% 
              select(Read_name_ID, Sequence, Feature_name_B, Feature_name_B_prev, Feature_name_B_next)
            return(blast_df)
          }
          
          log_step("Loading categories list...")
          # Get categories list
          df_categories_list <- process_df_categories_file(df_categories, chromosomes)

          log_step(paste0("Processing file: " , path_to_file_1,  "..."))

          # Process File_1 : from T0
          file_1 <- read_tsv(path_to_file_1, col_names = FALSE, show_col_types = FALSE)

          file_1 <- file_1 %>%
            rename(
              Read_name = !!names(.)[1],
              Chr_name_A = !!names(.)[2],
              Start_pos_A = !!names(.)[3],
              Chr_name_B = !!names(.)[4],
              Start_pos_B = !!names(.)[5],
              Sequence = !!names(.)[6]
            )

          log_step("Filtering by Feature_name_A...") 


          df_chr_A_filtered_file_1 <- filter_by_chromosome_A(file_1, chromosomes, df_categories_list) %>% 
            bind_rows(.)

          log_step("Filtering by Feature_name_B...")   

          df_chr_AB_filtered_file_1 <- filter_by_chromosome_B(df_chr_A_filtered_file_1, chromosomes, df_categories_list) %>% 
            bind_rows(.) %>% 
            mutate(strain = rep(c(strain_name)), sample = rep(c("T0")), experiment = rep(c(experiment)))

          df_chr_AB_filtered_file_1_nocontrols <- df_chr_AB_filtered_file_1 %>%
          filter (Category_A != "control", Category_B != "control" | Category_A != "control_norm", Category_B != "control_norm")

          remove(df_chr_A_filtered_file_1)

          log_step("Processing for BLAST analysis...") 

          df_chr_AB_filtered_file_1_ID <- df_chr_AB_filtered_file_1_nocontrols %>%
            mutate(pair_id = pmin(paste(Feature_name_A, Feature_name_B, sep = "_"), paste(Feature_name_B, Feature_name_A, sep = "_"))) %>%
            group_by(Read_name, pair_id) %>%
            mutate(pair_group = paste0("id", cur_group_id(), "-", row_number())) %>%
            separate(pair_group, c("pair_group_name", "number"), "-", remove = FALSE)  %>% 
            mutate(Read_name_ID = paste0(Read_name, "_", pair_group)) %>%  
            ungroup() %>%
            select(-pair_id) %>% 
            left_join(., df_categories_near_features, by = "Feature_name_B")

          control_file_1 <- df_chr_AB_filtered_file_1 %>% 
          filter (Category_A == "control" & Category_B == "control" | Category_A == "control_norm" & Category_B == "control_norm")

          blast_df_file_1 <- prepare_for_blast(df_chr_AB_filtered_file_1_ID) %>% select(Read_name_ID, Sequence, Feature_name_B)
          blast_df_file_1_prev <- prepare_for_blast(df_chr_AB_filtered_file_1_ID) %>% select(Read_name_ID, Sequence, Feature_name_B_prev)
          blast_df_file_1_next <- prepare_for_blast(df_chr_AB_filtered_file_1_ID) %>% select(Read_name_ID, Sequence, Feature_name_B_next)

      

          # Write the new TSV
          log_step("Saving processed dataframes...") 
          log_step(paste0("Saving tsv files for: ", strain_name,  " T0 ", experiment, "..."))


          write_tsv(df_chr_AB_filtered_file_1_ID, file = paste0(strain, "/", "T0", "_", experiment, "_inter_discordant_pairs_unique_processed.tsv"))
          write_tsv(control_file_1, file = paste0(strain, "/", "T0", "_", experiment, "_inter_discordant_pairs_unique_processed_control.tsv"))
          write_tsv(blast_df_file_1, file = paste0(strain, "/", "T0", "_", experiment, "_inter_discordant_pairs_unique_processed_blast_center.tsv"))
          write_tsv(blast_df_file_1_prev, file = paste0(strain, "/", "T0", "_", experiment, "_inter_discordant_pairs_unique_processed_blast_prev.tsv"))
          write_tsv(blast_df_file_1_next, file = paste0(strain, "/", "T0", "_", experiment, "_inter_discordant_pairs_unique_processed_blast_next.tsv"))

          
          log_step(paste0("Processing file: " , path_to_file_2,  "..."))
          # Process File_2 : from TSG/TLG/TLR

          file_2 <- read_tsv(path_to_file_2, col_names = FALSE, show_col_types = FALSE)

          file_2 <- file_2 %>%
            rename(
              Read_name = !!names(.)[1],
              Chr_name_A = !!names(.)[2],
              Start_pos_A = !!names(.)[3],
              Chr_name_B = !!names(.)[4],
              Start_pos_B = !!names(.)[5],
              Sequence = !!names(.)[6]
            )

          log_step("Filtering by Feature_name_A...") 

          df_chr_A_filtered_file_2 <- filter_by_chromosome_A(file_2, chromosomes, df_categories_list) %>% 
            bind_rows(.)

          log_step("Filtering by Feature_name_B...") 

          df_chr_AB_filtered_file_2 <- filter_by_chromosome_B(df_chr_A_filtered_file_2, chromosomes, df_categories_list) %>% 
            bind_rows(.) %>% 
            mutate(strain = rep(c(strain_name)), sample = rep(c(sample)), experiment = rep(c(experiment)))

          df_chr_AB_filtered_file_2_nocontrols <- df_chr_AB_filtered_file_2 %>%
          filter (Category_A != "control", Category_B != "control" | Category_A != "control_norm", Category_B != "control_norm")


          remove(df_chr_A_filtered_file_2)

          log_step("Finding discordant_pairs not present in T0 sample...")

          uncommon_pairs <- anti_join(df_chr_AB_filtered_file_2_nocontrols, df_chr_AB_filtered_file_1_nocontrols, by = c("Feature_name_A", "Feature_name_B")) 

          log_step("Processing for BLAST analysis...") 

          df_chr_AB_filtered_file_2_ID <- uncommon_pairs %>%
            mutate(pair_id = pmin(paste(Feature_name_A, Feature_name_B, sep = "_"), paste(Feature_name_B, Feature_name_A, sep = "_"))) %>%
            group_by(Read_name, pair_id) %>%
            mutate(pair_group = paste0("id", cur_group_id(), "-", row_number())) %>%
            separate(pair_group, c("pair_group_name", "number"), "-", remove = FALSE)  %>%  
            mutate(Read_name_ID = paste0(Read_name, "_", pair_group)) %>% 
            ungroup() %>%
            select(-pair_id) %>% 
            left_join(., df_categories_near_features, by = "Feature_name_B")

          control_file_2 <- df_chr_AB_filtered_file_2 %>% filter (Category_A == "control" & Category_B == "control" | Category_A == "control_norm" & Category_B == "control_norm")

          blast_df_file_2 <- prepare_for_blast(df_chr_AB_filtered_file_2_ID) %>% select(Read_name_ID, Sequence, Feature_name_B)
          blast_df_file_2_prev <- prepare_for_blast(df_chr_AB_filtered_file_2_ID) %>% select(Read_name_ID, Sequence, Feature_name_B_prev)
          blast_df_file_2_next <- prepare_for_blast(df_chr_AB_filtered_file_2_ID) %>% select(Read_name_ID, Sequence, Feature_name_B_next)


          # Write the new TSV
          log_step("Saving processed dataframes...") 
          log_step(paste0("Saving tsv files for: ", strain_name, " ",  sample, " ", experiment, "..."))

          write_tsv(df_chr_AB_filtered_file_2_ID, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed.tsv"))
          write_tsv(control_file_2, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_control.tsv"))
          write_tsv(blast_df_file_2, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_blast_center.tsv"))
          write_tsv(blast_df_file_2_prev, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_blast_prev.tsv"))
          write_tsv(blast_df_file_2_next, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_blast_next.tsv"))
EOF
      
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample/$experiment: $file1 or $file2" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done


# Calculate total elapsed time
elapsed_time_total_R=$((( SECONDS - start_time_total_R )/60))
echo "================================" >> "$log_file"
echo "" >> "$log_file"
echo "TOTAL INTER-CHROMOSOMAL DISCORDANT READ PAIRS R PROCESSING COMPLETED IN ${elapsed_time_total_R} MINUTES" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
          


############## BLAST processing of 75bp reads ############

# BLAST processing for inter-chromosomal discordant read pairs
# For each inter-chromosomal discordant read pair not present in T0,
# a BLAST cross-validation is performed to discard false positives arising from 
# PCR mutation after library amplification or sequencing errors.

start_time_total_blast=$SECONDS
# Loop through each directory inside MYWD

echo "================================" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
echo "### BLAST cross-validation for inter-chromosomal discordant read pairs ###" >> "$log_file"
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Initiated at ${current_time}" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line 

for strain in "$MYWD"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
  start_time_total=$SECONDS

  # Loop through sample prefixes (TSG, TLG, TLR)
    for sample in TSG TLG TLR; do
      for experiment in E1 E2 E3; do
        for pos in center prev next; do
          input_file="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_blast_${pos}.tsv"
          if [[ -f "$input_file" ]]; then
            echo "### $(basename "$strain")/${sample} ${experiment} ###" >> "$log_file"
            echo "### ${pos} ###" >> "$log_file"
            echo "" >> "$log_file"
            echo "Processing: Input file ${input_file} " >> "$log_file"
            echo "" >> "$log_file"
            cp "$input_file" "$MYBLAST" 
            # Start timer for blast processing
            start_time=$SECONDS
            file_name=$(basename "${input_file%.tsv}")
            output_dir="${MYBLAST}/1.blast_results"
            # Create output directory if it doesn't exist
            mkdir -p "$output_dir"
            (
                cd "$MYBLAST" || exit

                    while IFS=$'\t' read -r nombre_read query_A reference_B || [ -n "$nombre_read" ]; do # -n to read last row also if it doesn't end with a newline
                        if [[ -z "$nombre_read" || -z "$query_A" || -z "$reference_B" ]]; then
                            echo "WARNING: Malformed line in $file_name.tsv - skipping" >> "$log_file"
                            continue
                        fi
                        reference_ext="_seq.fasta" 
                        reference_name=$reference_B
                        reference_file_path="${reference_name}${reference_ext}"
                        read_name=$nombre_read
                        query=$query_A
                        random_id=$RANDOM
                        # # Debug output
                        # echo "Read: $read_name" >> "$log_file"
                        # echo "Query: $query" >> "$log_file"
                        # echo "Reference: $reference_file_path" >> "$log_file"

                        if [[ ! -f "$reference_file_path" ]]; then
                            echo "WARNING: Reference file $reference_file_path not found - skipping" >> "$log_file"
                            continue
                        fi
                        echo -e ">$read_name\n$query" > "$file_name".fasta
                        makeblastdb -in "$reference_file_path" -dbtype nucl -out "$reference_name"
                        blastn -db "$reference_name" -query "$file_name".fasta -outfmt "7 qseqid sseqid mismatch length" -out "$read_name"_"$reference_name"_randomid"$random_id"_results.tsv
                        mv *_results.tsv "$output_dir"
                        rm $file_name.fasta
                        rm -f *.nhr *.nin *.nsq *.ndb *.njs *.not *.ntf *.nto
                        # Process the result inside blast_results
                        result_file="${output_dir}/${read_name}_${reference_name}_randomid${random_id}_results.tsv"
                        file_base="${result_file%.tsv}"
                        grep -E 'Query|Database|hits|E25|V35' "$result_file" > "${file_base}_selected.tsv"
                        tr ' ' '\t' < "${file_base}_selected.tsv" > "${file_base}_selected_tab.tsv"
                        tr '\n ' '\t' < "${file_base}_selected_tab.tsv" > "${file_base}_selected_tab_n.tsv"
                        cut -f3,6,8,13,14 "${file_base}_selected_tab_n.tsv" > "${file_base}_results_processed.tsv"
                        rm -f "${file_base}_selected.tsv" "${file_base}_selected_tab.tsv" "${file_base}_selected_tab_n.tsv" "${result_file}"
                        
                        
                    done < "$input_file"  
                # Combine all processed results into a single file
                combined_file="${output_dir}/${file_name}_combined_results.tsv"
                find "${output_dir}" -name '*_results_results_processed.tsv' -print0 | xargs -0 cat > "$combined_file"
                #rm -f "${output_dir}"/*_results_processed.tsv
                find "${output_dir}" -name '*_results_results_processed.tsv' -delete
                #find . -name "*_processed.tsv" -delete
                # cat "${output_dir}"/*_results_results_processed.tsv > "$combined_file"
                # rm -f "${output_dir}"/*_results_processed.tsv
            
            cp "$combined_file" "${strain}"
            rm -r "${output_dir}"
            rm "${MYBLAST}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_blast_${pos}.tsv"
            
            echo "" >> "$log_file"
            echo "Blast processing for $input_file completed and results saved to ${strain}" >> "$log_file"
            echo "" >> "$log_file"

            )  # End subshell to change directory  
            
            
            # End timer for blast processing
            elapsed_time=$((( SECONDS - start_time )/60))
            echo "Blast processing completed in ${elapsed_time} minutes" >> "$log_file"
            echo "" >> "$log_file"  # Adds a blank line
          else
            echo "Warning: Input file $input_file does not exist!" >> "$log_file"
          fi

        done
      done
    done
  # End timer for the current strain processing
  elapsed_time_total=$((( SECONDS - start_time_total )/60))
  echo "" >> "$log_file"
  echo "Processing for strain $(basename "$strain") completed in ${elapsed_time_total} minutes" >> "$log_file"
  echo "" >> "$log_file"  # Adds a blank line
done  

# Calculate total elapsed time in BLAST processing
elapsed_time_total_blast=$((( SECONDS - start_time_total_blast )/60))
echo "================================" >> "$log_file"
echo "" >> "$log_file"
echo "BLAST CROSS-VALIDATION FOR INTER-CHROMOSOMAL DISCORDANT READ PAIRS COMPLETED IN ${elapsed_time_total_blast} MINUTES" >> "$log_file"
echo "" >> "$log_file"


############## R processing of 75bp VALID reads ############

# R processing for inter-chromosomal discordant read pairs after BLAST cross-validation
# After processing all samples, only valid discordant reads are kept for further analysis.
# With this script, valid reads are identified and saved in a df.
# Start timer for R processing

start_time_total_R_valid=$SECONDS

echo "================================" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
echo "### R processing for new valid discordant read pairs, 75bp analysis ###" >> "$log_file"
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Initiated at ${current_time}" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line 

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
    for experiment in E1 E2 E3; do
      file1="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_blast_center_combined_results.tsv"
      file2="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_blast_prev_combined_results.tsv"
      file3="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_blast_next_combined_results.tsv"
      fileorig="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed.tsv"
      filecontrol="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_control.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" && -f "$fileorig" && -f "$filecontrol" ]]; then
        echo "$(basename "$strain") ${sample} ${experiment}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant tsv files for $file1 , $file2 , $file3 and $fileorig" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(stringr)
          library(extrafont)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          category_path <- "${CATEGORY_PATH}"
          strain <- "${strain}"
          sample <- "${sample}"
          experiment <- "${experiment}" 
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"
          path_to_file_original <- "${fileorig}"
          path_to_file_control <- "${filecontrol}"
          path_to_categories_pairs_file <- file.path(category_path, "PMV_categories_pairs.tsv")
          path_to_features_pairs_file <- file.path(category_path, "PMV_features_pairs.tsv")

       
          #path_to_file_1
          #path_to_file_2
          #path_to_file_3
          #path_to_file_original

          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          process_blast_filtered_files <- function (blast_filtered_file_path) {
            blast_filtered_df <- read.table(blast_filtered_file_path,
                                            header=FALSE, sep = "\t", 
                                            col.names = paste0("V",seq_len(5)), fill = TRUE) %>% 
              rename("pair_group" = !!names(.[1]), "Feature_name_B" = !!names(.[2]), "hits" = !!names(.[3]), 
                    "mismatch" = !!names(.[4]), "length" = !!names(.[5])) %>% 
              mutate(valid = ifelse(hits == 0, "yes", "no"))
            
            return(blast_filtered_df)
              
          }


          get_blast_validated_complete_df <- function (center_file, prev_file, next_file) {
            
            complete_df <- left_join(prev_file, next_file, by = "pair_group") %>% 
              left_join(center_file, ., by = "pair_group") %>% 
              rename("valid_prev" = !!names(.[11]), "valid_next" = !!names(.[16])) %>% 
              separate(pair_group, c("pair_group_name", "number"), "-", remove = FALSE) %>% 
              mutate_at(vars(valid_prev, valid_next), ~replace_na(., "yes")) %>% 
              mutate(valid_all = ifelse(valid == "yes" & valid_prev == "yes" & valid_next == "yes", "yes", "no")) %>% 
              group_by(pair_group_name, pair_group) %>%
              mutate(all_yes_T_F = all(valid_all == "yes")) %>%
              group_by(pair_group_name) %>%
              mutate(group_all_yes_T_F = all(all_yes_T_F)) %>%
              ungroup() %>%
              mutate(valid_def = ifelse(group_all_yes_T_F, "yes", "no")) %>% 
              filter(valid_def == "yes") %>% select(pair_group) %>% 
              rename(Read_name_ID = pair_group) 
              
            return(complete_df)
            
          }


          center_df <- process_blast_filtered_files(path_to_file_1)
          prev_df <- process_blast_filtered_files(path_to_file_2)
          next_df <- process_blast_filtered_files(path_to_file_3)

          #head(center_df)
          #head(prev_df)
          #head(next_df)

          log_step("Finding valid reads...") 

          valid_read_name <- get_blast_validated_complete_df(center_df, prev_df, next_df)
          #head(valid_read_name)


          original_df <- read_tsv(path_to_file_original,col_names = TRUE) %>% 
            mutate(Read_name_ID = with(., paste0(Read_name, "_", pair_group)))

          log_step("Comparing with original file...") 

          valid_pairs_df <- semi_join(original_df, valid_read_name)

          n_valid_reads <- nrow(valid_pairs_df)
          n_original_reads <- nrow(original_df)

          log_step("Calculating error rate...")

          error_rate <- tibble(strain = strain_name, 
                     sample = sample,
                     experiment = experiment,
                     original_reads = n_original_reads,
                     valid_reads = n_valid_reads) %>% 
                  mutate(valid_rate = (valid_reads/original_reads)*100)

          
         
          # Write the new TSV
          log_step("Saving processed dataframe...") 
          log_step(paste0("Saving tsv files for: ", strain_name, " ",  sample, " ", experiment, "..."))

          write_tsv(valid_pairs_df, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_valid.tsv"))
          write_tsv(error_rate, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_valid_error_rate.tsv"))

          # Calculate distribution of valid reads
          df_categories_pairs <- read_tsv(path_to_categories_pairs_file,col_names = FALSE, show_col_types = FALSE) %>%
            rename("Category_A" = !!names(.[1]), "Category_B" = !!names(.[2]))

          # Categories
          categories <- unique(df_categories_pairs\$Category_A)

          # Process_categories
          process_categories <- function(categories_i, valid_pairs_df_file, categories_df_file) {
            # Possible combinations
            combinations <- categories_df_file %>%
              filter(Category_A == categories_i) %>%
              distinct(Category_B) %>%
              pull()
            
            # Filter discordant pairs for each Category_A
            valid_pairs_filtered <- filter(valid_pairs_df_file, Category_A == categories_i)
            
            # Calculate number of reads 
            map_dfr(combinations, function(categoryB) {
              n <- valid_pairs_filtered %>% filter(Category_B == categoryB) %>% nrow()
              tibble(Category_A = categories_i, Category_B = categoryB, count = n)
            })
          }
          
          # Write the new TSV
          log_step("Calculating discordant reads distribution along genomic categories...") 
          
          # Get counts
          count_df <- map_dfr(categories, process_categories, valid_pairs_df_file = valid_pairs_df, categories_df_file = df_categories_pairs) %>% 
            mutate(strain = strain_name,
                  sample = sample,
                  experiment = experiment)
          write_tsv(count_df, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_valid_counts.tsv"))


          # Set genomic categories order
          genomic_categories_order <- c(
            "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
            "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
            "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
          )

        
          log_step("Calculating global inter-chromosomal discordant read pairs distribution...")
          # Calculate global inter-chromosomal discordant read pairs distribution 
          global_distribution <- count_df %>% 
            group_by(strain, sample, experiment) %>% 
            mutate(global_percentage = (count / sum(count))*100,
                  strain_sample_comb = paste0(strain, "_", sample)) %>% 
            replace(is.na(.), 0) %>% 
            group_by(strain, sample, experiment, strain_sample_comb,  Category_A, Category_B) %>%
            summarise(mean_global_percentage = mean(global_percentage, na.rm = TRUE),
                      sd_global_percentage = sd(global_percentage, na.rm = TRUE)) %>%
            # Apply genomic_categories_order
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                  Category_B = factor(Category_B, levels = genomic_categories_order)) %>%
            arrange(strain, sample, experiment, Category_A, Category_B)

          write_tsv(global_distribution, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv"))

          log_step("Calculating category inter-chromosomal discordant read pairs distribution...")
          # Calculate average per_category inter-chromosomal discordant read pairs distribution 
          category_distribution <- count_df %>% 
            group_by(strain, sample, experiment, Category_A) %>% 
            mutate(category_percentage = (count / sum(count))*100,
                  strain_sample_comb = paste0(strain, "_", sample)) %>% 
            replace(is.na(.), 0) %>%
            group_by(strain, sample, experiment, strain_sample_comb, Category_A, Category_B) %>%
            summarise(mean_category_percentage = mean(category_percentage, na.rm = TRUE),
                      sd_category_percentage = sd(category_percentage, na.rm = TRUE)) %>%
            # Apply genomic_categories_order
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                  Category_B = factor(Category_B, levels = genomic_categories_order)) %>%
            arrange(strain, sample, experiment,Category_A, Category_B)
          
          write_tsv(category_distribution, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv"))


          # Inter-chromosomal discordant read pairs matrix
          df_features_pairs <- read_tsv(path_to_features_pairs_file, col_names = TRUE, show_col_types = FALSE)
          #all_pairs <- expand.grid(Feature_name_A = sort(unique(df_features_pairs\$Feature_name_A)), Feature_name_B = sort(unique(df_features_pairs\$Feature_name_B)))
          control_df <- read_tsv(path_to_file_control,col_names = TRUE) %>% filter(Category_A=="control_norm", Category_B=="control_norm")
          
          #head(all_pairs)
          
          get_discordant_matrix <- function(valid_pairs_df_file, all_pairs_df, control_df_file) {
            posA_info <- all_pairs_df %>%
              select(Feature_name_A, Position_A = Position, Essential_A = Essential) %>%
              distinct()
            
            posB_info <- all_pairs_df %>%
              select(Feature_name_B, Position_B = Position, Essential_B = Essential) %>%
              distinct()
            
            valid_pairs_df_posA <- valid_pairs_df_file %>%
              left_join(posA_info, by = "Feature_name_A")
            
            valid_pairs_df_posAB <- valid_pairs_df_posA %>%
              left_join(posB_info, by = "Feature_name_B")
            
            pair_counts <- valid_pairs_df_posAB %>%
              group_by(strain, sample, experiment, Feature_name_A, Feature_name_B) %>%
              summarise(count = n(), .groups = "drop")
            
            complete_matrix <- left_join(valid_pairs_df_posAB, pair_counts,
                                        by = c("Feature_name_A", "Feature_name_B", "strain", "sample", "experiment")) %>%
              distinct()
            
            count_total <- nrow(control_df_file)
            complete_matrix <- complete_matrix %>%
              mutate(count_norm = (count / count_total) * 100) %>% 
              select(!c(pair_group, pair_group_name, number, Feature_name_B_prev, Feature_name_B_next))
            
            return(complete_matrix)
          }

          log_step("Generating discordant matrix...")
          complete_matrix <- get_discordant_matrix(valid_pairs_df, df_features_pairs, control_df)
          complete_matrix_noORF_nointergenic <- complete_matrix %>% filter(Category_A != "ORF", Category_B != "ORF", Category_A != "intergenic", Category_B != "intergenic")

          log_step("Saving discordant matrix...")
          write_tsv(complete_matrix, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_valid_discordant_matrix.tsv"))
          write_tsv(complete_matrix_noORF_nointergenic, file = paste0(strain, "/", sample, "_", experiment, "_inter_discordant_pairs_unique_processed_valid_discordant_matrix_noORF_nointergenic.tsv"))

          log_step("Plotting discordant matrix...")
          matrix_plot <-ggplot(complete_matrix, aes(y = Position_B, x = Position_A)) +
            #geom_hdr(xlim = c(0,14518), ylim = c(14518,0), method = "kde", fill = "brown4") + 
            geom_point(aes(colour = count_norm), alpha = 1, size = 0.8) +
            scale_colour_gradient2(low= "white", mid = "#4ae034", high = "#00641b",
                                  midpoint = 1,
                                  limits = c (0, 5),
                                  oob = scales::squish) + 
            theme_bw(base_family = "Arial") + 
            theme(panel.background = element_blank()) +
            theme(plot.background = element_rect(fill = "transparent", colour = NA))+
            theme(legend.position="right") +
            theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
            guides (colour = guide_colourbar(barwidth = 0.5, barheight = 5,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            coord_cartesian(xlim = c(0,14518), ylim = c(14518, 0), expand=FALSE) +
            theme(aspect.ratio = 1) +
            scale_x_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487), position = "top") +
            scale_y_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            geom_hline(yintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_hline(yintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 144877),
                      linetype="dashed", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="dashed", color = "black", linewidth=0.05) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks = element_blank()) +
            geom_abline(intercept = 0, slope = 1, color = "black", linetype = "solid", linewidth = 0.05) +
            labs(
              title = paste0("Inter_chromosomal discordant matrix - ", strain_name, " - ", sample, " - ", experiment),
              colour = "Freq (%)")
          
          #paste0(subdir, "/plot_", chr_name, "_75nt_", gsub("\\.tsv$", "", suffix), ".svg")
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_matrix_plot_", strain_name, "_", sample, "_", experiment, ".svg"),
            plot = matrix_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

          log_step("Plotting discordant matrix - no ORF no intergenic...")
          matrix_plot <-ggplot(complete_matrix_noORF_nointergenic, aes(y = Position_B, x = Position_A)) +
            #geom_hdr(xlim = c(0,14518), ylim = c(14518,0), method = "kde", fill = "brown4") + 
            geom_point(aes(colour = count_norm), alpha = 1, size = 2) +
            scale_colour_gradient2(low= "white", mid = "#4ae034", high = "#00641b",
                                  midpoint = 1,
                                  limits = c (0, 5),
                                  oob = scales::squish) + 
            theme_bw(base_family = "Arial") + 
            theme(panel.background = element_blank()) +
            theme(plot.background = element_rect(fill = "transparent", colour = NA))+
            theme(legend.position="right") +
            theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
            guides (colour = guide_colourbar(barwidth = 0.5, barheight = 5,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            coord_cartesian(xlim = c(13195,14518), ylim = c(14518, 13195), expand=FALSE) +
            theme(aspect.ratio = 1) +
            scale_x_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487), position = "top") +
            scale_y_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            geom_hline(yintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_hline(yintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 144877),
                      linetype="dashed", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="dashed", color = "black", linewidth=0.05) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks = element_blank()) +
            geom_abline(intercept = 0, slope = 1, color = "black", linetype = "solid", linewidth = 0.05) +
            labs(
              title = paste0("Inter_chromosomal discordant matrix no ORF no intergenic - ", strain_name, " - ", sample, " - ", experiment),
              colour = "Freq (%)")
          
          #paste0(subdir, "/plot_", chr_name, "_75nt_", gsub("\\.tsv$", "", suffix), ".svg")
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_matrix_reduced_plot_", strain_name, "_", sample, "_", experiment, ".svg"),
            plot = matrix_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )



EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample/$experiment: $file1 or $file2 or $file3 or $fileorig" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done



      
          

# R processing for inter-chromosomal discordant read pairs global distribution
# Start timer for R processing

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
      file1="${strain}/${sample}_E1_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv"
      file2="${strain}/${sample}_E2_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv"
      file3="${strain}/${sample}_E3_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" ]]; then
        echo "$(basename "$strain") ${sample}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant global distribution tsv files for $file1 , $file2 and $file3" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(extrafont)
          library(stringr)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          strain <- "${strain}"
          sample <- "${sample}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"


          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          file1 <- read_tsv(path_to_file_1, col_names = TRUE)
          file2 <- read_tsv(path_to_file_2, col_names = TRUE)
          file3 <- read_tsv(path_to_file_3, col_names = TRUE)

          discordant_reads_count <- bind_rows(file1, file2, file3)

          # Set genomic categories order
          genomic_categories_order <- c(
            "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
            "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
            "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
          )


          # Calculate average global inter-chromosomal discordant read pairs distribution 
          global_distribution <- discordant_reads_count %>% 
            group_by(strain, sample, strain_sample_comb,  Category_A, Category_B) %>%
            summarise(all_mean_global_percentage = mean(mean_global_percentage, na.rm = TRUE),
                      all_sd_global_percentage = sd(mean_global_percentage, na.rm = TRUE)) %>%
            # Apply genomic_categories_order
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                  Category_B = factor(Category_B, levels = genomic_categories_order)) %>%
            arrange(strain, sample, Category_A, Category_B) %>% 
            ungroup()

          heatmap <- ggplot(global_distribution, aes(x = Category_B, y = Category_A, fill =all_mean_global_percentage)) +
            geom_tile(color = "black", linewidth = 0.2) +
            scale_fill_gradientn(
              colors = c("white", "#e31a1c", "#8b2500"),
              values = scales::rescale(c(0, 2, 100)),
              na.value = "gray90",
              limits = c(0, 100),
              oob = scales::squish) +
            guides (fill = guide_colourbar(barwidth = 0.5, barheight = 10,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            labs(title = paste0("Inter_chromosomal discordant global distribution - ", strain_name, " - ", sample),
                fill = "%") +
            scale_x_discrete(labels = c("ORF","Intergenic", "LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
            scale_y_discrete(limits = rev, labels = c("Telomere", "Centromere", "ARS", "snoRNA", "snRNA", "ncRNA", "rRNA", 
                                                      "tRNA", "Ty", "TEG", "LTR", "Intergenic", "ORF")) +
            theme_minimal(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") + 
            theme(axis.text.y=element_text(size=8)) +
            theme(axis.text.x=element_text(size=8, angle = 90, hjust = 1)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) + 
            theme(aspect.ratio = 1)
          
          
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_pairs_global_distribution_heatmap_", strain_name, "_", sample, ".svg"),
            plot = heatmap,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample: $file1 or $file2 or $file3" >> "$log_file"
      echo "" >> "$log_file"
      fi

  done
done



# R processing for inter-chromosomal discordant read pairs category distribution


# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
      file1="${strain}/${sample}_E1_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv"
      file2="${strain}/${sample}_E2_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv"
      file3="${strain}/${sample}_E3_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" ]]; then
        echo "$(basename "$strain") ${sample}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant category distribution tsv files for $file1 , $file2 and $file3" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(extrafont)
          library(stringr)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          strain <- "${strain}"
          sample <- "${sample}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"


          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          file1 <- read_tsv(path_to_file_1, col_names = TRUE)
          file2 <- read_tsv(path_to_file_2, col_names = TRUE)
          file3 <- read_tsv(path_to_file_3, col_names = TRUE)

          discordant_reads_count <- bind_rows(file1, file2, file3)

          # Set genomic categories order
          genomic_categories_order <- c(
            "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
            "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
            "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
          )


          # Calculate average category inter-chromosomal discordant read pairs distribution 
          category_distribution <- discordant_reads_count %>% 
            group_by(strain, sample, strain_sample_comb,  Category_A, Category_B) %>%
            summarise(all_mean_category_percentage = mean(mean_category_percentage, na.rm = TRUE),
                      all_sd_category_percentage = sd(mean_category_percentage, na.rm = TRUE)) %>%
            # Apply genomic_categories_order
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                  Category_B = factor(Category_B, levels = genomic_categories_order)) %>%
            arrange(strain, sample, Category_A, Category_B) %>% 
            ungroup()

          heatmap <- ggplot(category_distribution, aes(x = Category_B, y = Category_A, fill =all_mean_category_percentage)) +
            geom_tile(color = "black", linewidth = 0.2) +
            scale_fill_gradientn(
              colors = c("white", "#e31a1c", "#8b2500"),
              values = scales::rescale(c(0, 50, 100)),
              na.value = "gray90",
              limits = c(0, 100),
              oob = scales::squish) +
            guides (fill = guide_colourbar(barwidth = 0.5, barheight = 10,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            labs(title = paste0("Inter_chromosomal discordant category distribution - ", strain_name, " - ", sample),
                fill = "%") +
            scale_x_discrete(labels = c("ORF","Intergenic", "LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
            scale_y_discrete(limits = rev, labels = c("Telomere", "Centromere", "ARS", "snoRNA", "snRNA", "ncRNA", "rRNA", 
                                                      "tRNA", "Ty", "TEG", "LTR", "Intergenic", "ORF")) +
            theme_minimal(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") + 
            theme(axis.text.y=element_text(size=8)) +
            theme(axis.text.x=element_text(size=8, angle = 90, hjust = 1)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) + 
            theme(aspect.ratio = 1)
          
          
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_pairs_category_distribution_heatmap_", strain_name, "_", sample, ".svg"),
            plot = heatmap,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample: $file1 or $file2 or $file3" >> "$log_file"
      echo "" >> "$log_file"
      fi

  done
done



# R processing for inter-chromosomal discordant read pairs matrix (merge all experiments)


# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
      file1="${strain}/${sample}_E1_inter_discordant_pairs_unique_processed_valid.tsv"
      file2="${strain}/${sample}_E2_inter_discordant_pairs_unique_processed_valid.tsv"
      file3="${strain}/${sample}_E3_inter_discordant_pairs_unique_processed_valid.tsv"
      control1="${strain}/${sample}_E1_inter_discordant_pairs_unique_processed_control.tsv"
      control2="${strain}/${sample}_E2_inter_discordant_pairs_unique_processed_control.tsv"
      control3="${strain}/${sample}_E3_inter_discordant_pairs_unique_processed_control.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" && -f "$control1" && -f "$control2" && -f "$control3" ]]; then
        echo "$(basename "$strain") ${sample}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant valid reads tsv files for $file1 , $file2 and $file3" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(extrafont)
          library(stringr)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          category_path <- "${CATEGORY_PATH}"
          strain <- "${strain}"
          sample <- "${sample}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"
          path_to_control_1 <- "${control1}"
          path_to_control_2 <- "${control2}"
          path_to_control_3 <- "${control3}"
          path_to_features_pairs_file <- file.path(category_path, "PMV_features_pairs.tsv")


          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          log_step("Finding possible pairs...")

          # Inter-chromosomal discordant read pairs matrix
          df_features_pairs <- read_tsv(path_to_features_pairs_file, col_names = TRUE, show_col_types = FALSE)

          log_step("Loading valid reads...")
          # Load valid reads
          file1 <- read_tsv(path_to_file_1, col_names = TRUE)
          file2 <- read_tsv(path_to_file_2, col_names = TRUE)
          file3 <- read_tsv(path_to_file_3, col_names = TRUE)

          valid_pairs_df <- bind_rows(file1, file2, file3)

          log_step("Loading control reads...")
          # Load control reads
          control1 <- read_tsv(path_to_control_1, col_names = TRUE)
          control2 <- read_tsv(path_to_control_2, col_names = TRUE)
          control3 <- read_tsv(path_to_control_3, col_names = TRUE)

          control_df <- bind_rows(control1, control2, control3) %>% 
            filter(Category_A=="control_norm", Category_B=="control_norm")

          get_discordant_matrix <- function(valid_pairs_df_file, all_pairs_df, control_df_file) {
            posA_info <- all_pairs_df %>%
              select(Feature_name_A, Position_A = Position, Essential_A = Essential) %>%
              distinct()
            
            posB_info <- all_pairs_df %>%
              select(Feature_name_B, Position_B = Position, Essential_B = Essential) %>%
              distinct()
            
            valid_pairs_df_posA <- valid_pairs_df_file %>%
              left_join(posA_info, by = "Feature_name_A")
            
            valid_pairs_df_posAB <- valid_pairs_df_posA %>%
              left_join(posB_info, by = "Feature_name_B")
            
            pair_counts <- valid_pairs_df_posAB %>%
              group_by(strain, sample, Feature_name_A, Feature_name_B) %>%
              summarise(count = n(), .groups = "drop")
            
            complete_matrix <- left_join(valid_pairs_df_posAB, pair_counts,
                                        by = c("Feature_name_A", "Feature_name_B", "strain", "sample")) %>%
              distinct()
            
            count_total <- nrow(control_df_file)
            complete_matrix <- complete_matrix %>%
              mutate(count_norm = (count / count_total) * 100) %>% 
              select(!c(pair_group, pair_group_name, number, Feature_name_B_prev, Feature_name_B_next))
            
            return(complete_matrix)
          }

          log_step("Generating discordant matrix...")
          complete_matrix <- get_discordant_matrix(valid_pairs_df, df_features_pairs, control_df)
          complete_matrix_noORF_nointergenic <- complete_matrix %>% filter(Category_A != "ORF", Category_B != "ORF", Category_A != "intergenic", Category_B != "intergenic")

          log_step("Saving discordant matrix...")
          write_tsv(complete_matrix, file = paste0(strain, "/", sample, "_inter_discordant_pairs_unique_processed_valid_discordant_matrix_allexperiments.tsv"))
          write_tsv(complete_matrix_noORF_nointergenic, file = paste0(strain, "/", sample, "_inter_discordant_pairs_unique_processed_valid_discordant_matrix_noORF_nointergenic_allexperiments.tsv"))

          log_step("Plotting discordant matrix...")
          matrix_plot <-ggplot(complete_matrix, aes(y = Position_B, x = Position_A)) +
            #geom_hdr(xlim = c(0,14518), ylim = c(14518,0), method = "kde", fill = "brown4") + 
            geom_point(aes(colour = count_norm), alpha = 1, size = 0.8) +
            scale_colour_gradient2(low= "white", mid = "#4ae034", high = "#00641b",
                                  midpoint = 1,
                                  limits = c (0, 5),
                                  oob = scales::squish) + 
            theme_bw(base_family = "Arial") + 
            theme(panel.background = element_blank()) +
            theme(plot.background = element_rect(fill = "transparent", colour = NA))+
            theme(legend.position="right") +
            theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
            guides (colour = guide_colourbar(barwidth = 0.5, barheight = 5,
                                            frame.colour = "black", frame.linewidth = 0.25,
                                            ticks.colour = NA)) + 
            coord_cartesian(xlim = c(0,14518), ylim = c(14518, 0), expand=FALSE) +
            theme(aspect.ratio = 1) +
            scale_x_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487), position = "top") +
            scale_y_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            geom_hline(yintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_hline(yintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 144877),
                      linetype="dashed", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="dashed", color = "black", linewidth=0.05) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks = element_blank()) +
            geom_abline(intercept = 0, slope = 1, color = "black", linetype = "solid", linewidth = 0.05) +
            labs(
              title = paste0("Inter_chromosomal discordant matrix - ", strain_name, " - ", sample),
              colour = "Freq (%)")

          
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_matrix_plot_", strain_name, "_", sample, ".svg"),
            plot = matrix_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

          log_step("Plotting discordant matrix - no ORF no intergenic...")
          matrix_plot <-ggplot(complete_matrix_noORF_nointergenic, aes(y = Position_B, x = Position_A)) +
            #geom_hdr(xlim = c(0,14518), ylim = c(14518,0), method = "kde", fill = "brown4") + 
            geom_point(aes(colour = count_norm), alpha = 1, size = 2) +
            scale_colour_gradient2(low= "white", mid = "#4ae034", high = "#00641b",
                                  midpoint = 1,
                                  limits = c (0, 5),
                                  oob = scales::squish) + 
            theme_bw(base_family = "Arial") + 
            theme(panel.background = element_blank()) +
            theme(plot.background = element_rect(fill = "transparent", colour = NA))+
            theme(legend.position="right") +
            theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
            guides (colour = guide_colourbar(barwidth = 0.5, barheight = 5,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            coord_cartesian(xlim = c(13195,14518), ylim = c(14518, 13195), expand=FALSE) +
            theme(aspect.ratio = 1) +
            scale_x_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487), position = "top") +
            scale_y_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            geom_hline(yintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_hline(yintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 144877),
                      linetype="dashed", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="dashed", color = "black", linewidth=0.05) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks = element_blank()) +
            geom_abline(intercept = 0, slope = 1, color = "black", linetype = "solid", linewidth = 0.05) +
            labs(
              title = paste0("Inter_chromosomal discordant matrix no ORF no intergenic - ", strain_name, " - ", sample),
              colour = "Freq (%)")
          
          #paste0(subdir, "/plot_", chr_name, "_75nt_", gsub("\\.tsv$", "", suffix), ".svg")
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_matrix_reduced_plot_", strain_name, "_", sample, ".svg"),
            plot = matrix_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
          
          


EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total R processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample: $file1 or $file2 or $file3" >> "$log_file"
      echo "" >> "$log_file"
      fi

  done
done



##### Calculate % of discordant reads in each Category_A and plot bar plot with SD
# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      #echo "$root_dir"
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing discordant reads distribution by Category_A" >> "$log_file"
        start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        #echo "ROOT_DIR: $ROOT_DIR"
        #echo "STRAIN: $STRAIN"
        Rscript - <<'EOF'
          # load libraries
          
          library(ggplot2)
          library(extrafont)
          library(svglite)
          library(purrr)
          library(stringr)
          library(readr)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          options(dplyr.summarise.inform = FALSE)

          # Read environment variables
          root_dir <- Sys.getenv("ROOT_DIR")
          strain <- Sys.getenv("STRAIN")
          strain <- sub("/$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)

          print(paste("ROOT_DIR:", root_dir))

          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          # Define a function to process tsv files
          process_valid_counts_files <- function(file_path) {
            # Extract filename and directory parts
            file_base <- basename(file_path)
            strain_name <- basename(dirname(file_path))  # directory name above the file

            # Expect filename like T4_E07_MAT_filtered.tsv
            parts <- str_split(file_base, "_", simplify = TRUE)

            # Validate and extract parts safely
            if (ncol(parts) >= 3) {
              sample_name <- parts[1]
              experiment_name <- parts[2]
            } else {
              warning(paste("Filename does not match expected format:", file_base))
              return(NULL)
            }

            # Read file
            temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)

            # Skip if empty
            if (nrow(temp_file) == 0) {
              return(NULL)
            }

            # Prepare counts distribution dataframe
            counts_distribution_file <- temp_file %>%
                group_by(strain, sample, experiment, Category_A) %>%
                summarise(total_count = sum(count), .groups = "drop_last") %>%
                mutate(
                  group_total = sum(total_count),
                  percent = 100 * (total_count / group_total)
                ) %>%
                ungroup()

            return(counts_distribution_file)
          }
        

          log_step("Finding valid_counts files...")
          # Get all valid counts.tsv files recursively in root folder
          valid_counts_files <- list.files(
            path = root_dir,
            pattern = "valid_counts\\.tsv$",
            recursive = TRUE,
            full.names = TRUE
          )
          valid_counts_files
          log_step("Processing valid_counts files...")
          valid_counts_processed_df <- purrr::map_dfr(valid_counts_files, process_valid_counts_files)

          genomic_categories_order <- c(
            "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
            "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
            "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
          )

          samples_order <- c("TSG", "TLG", "TLR")

          valid_counts_processed_df_summary <- valid_counts_processed_df %>%
            group_by(strain, sample, Category_A) %>%
            summarise(
              mean_percent = mean(percent, na.rm = TRUE),
              sd_percent = sd(percent, na.rm = TRUE),
              .groups = "drop"
            )

          valid_counts_processsed_df_summary_ordered <- valid_counts_processed_df_summary %>% mutate(Category_A = factor(Category_A, levels = genomic_categories_order)) %>%
            arrange(strain, sample, Category_A)

          #write_tsv(valid_counts_processed_df_summary, file.path(root_dir, paste0(strain_name, "_valid_counts_summary.tsv")))
          write_tsv(valid_counts_processsed_df_summary_ordered, file.path(root_dir, paste0(strain_name, "_valid_counts_summary_ordered.tsv")))
          #write_tsv(valid_counts_processed_df, file.path(root_dir, paste0(strain_name, "_valid_counts.tsv")))

          log_step("Plotting...")
          # Generate plots

          valid_counts_processsed_df_summary_ordered <-  valid_counts_processsed_df_summary_ordered %>% 
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order)) %>% 
            mutate(sample = factor(sample, levels = samples_order))

          bar_plot <- ggplot(valid_counts_processsed_df_summary_ordered, aes(x = Category_A, y = mean_percent, fill = sample)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = mean_percent - sd_percent, ymax = mean_percent + sd_percent), 
                          linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
            scale_fill_manual(values=c("#252159", "#469CD7", "#8BE0FC")) +
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(expand=FALSE) +
            #coord_cartesian(ylim = c(0, 6), expand=FALSE) +
            coord_cartesian(ylim = c(0, 100), expand=FALSE) +
            theme(aspect.ratio = 0.75) + 
            scale_x_discrete(name = expression("Category"), 
                              labels = c("ORF", "Intergenic","LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
            scale_y_continuous(name = expression("Percentage"),
                              limits = c(0, 100),
                              breaks = seq(0,100,10)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                  axis.title.y = element_text(vjust = 1, size = 25)) + 
            theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 20, angle = 90), 
                  axis.text.y = element_text(vjust = 0, size = 20)) +
            labs(
                title = paste0("Discordant reads distribution - ", strain_name)
              )
          
          ggsave(
            filename = paste0(strain,"/", "Discordant_reads_distribution_plot_", strain_name, ".svg"),
            plot = bar_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

          bar_plot_reduced <- ggplot(valid_counts_processsed_df_summary_ordered, aes(x = Category_A, y = mean_percent, fill = sample)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = mean_percent - sd_percent, ymax = mean_percent + sd_percent), 
                          linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
            scale_fill_manual(values=c("#252159", "#469CD7", "#8BE0FC")) +
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(expand=FALSE) +
            coord_cartesian(ylim = c(0, 6), expand=FALSE) +
            #coord_cartesian(ylim = c(0, 100), expand=FALSE) +
            theme(aspect.ratio = 0.75) + 
            scale_x_discrete(name = expression("Category"), 
                              labels = c("ORF", "Intergenic","LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
            scale_y_continuous(name = expression("Percentage"),
                              limits = c(0, 100),
                              breaks = seq(0,100,2)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                  axis.title.y = element_text(vjust = 1, size = 25)) + 
            theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 20, angle = 90), 
                  axis.text.y = element_text(vjust = 0, size = 20)) +
            labs(
                title = paste0("Discordant reads distribution - reduced - ", strain_name)
              )
          
          ggsave(
            filename = paste0(strain,"/", "Discordant_reads_distribution_plot_reduced_", strain_name, ".svg"),
            plot = bar_plot_reduced,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

          
          
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total R processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 

done

# R processing for inter-chromosomal discordant read pairs hotspots (all experiments)

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
      file1="${strain}/${sample}_E1_inter_discordant_pairs_unique_processed_valid_discordant_matrix.tsv"
      file2="${strain}/${sample}_E2_inter_discordant_pairs_unique_processed_valid_discordant_matrix.tsv"
      file3="${strain}/${sample}_E3_inter_discordant_pairs_unique_processed_valid_discordant_matrix.tsv"
      freqs="${strain}/${sample}_inter_discordant_pairs_unique_processed_valid_discordant_matrix_allexperiments.tsv"
      
      if [[ -f "$file1" && -f "$file2" && -f "$file3" && -f "$freqs" ]]; then
        echo "$(basename "$strain") ${sample}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant valid reads tsv files for $file1 , $file2 and $file3" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(stringr)
          library(svglite)
          library(extrafont)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          category_path <- "${CATEGORY_PATH}"
          strain <- "${strain}"
          sample <- "${sample}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"
          path_to_freqs <- "${freqs}"

          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

        
          log_step("Loading matrix files...")
          # Load valid reads
          file1 <- read_tsv(path_to_file_1, col_names = TRUE,
            col_select = c("Feature_name_A", "Category_A", "Chromosome_A", "Essential_A",
                                                    "Feature_name_B", "Category_B", "Chromosome_B", "Essential_B",
                                                    "strain", "sample", "experiment", "Read_name_ID")) 

          file2 <- read_tsv(path_to_file_2, col_names = TRUE,
            col_select = c("Feature_name_A", "Category_A", "Chromosome_A", "Essential_A",
                                                    "Feature_name_B", "Category_B", "Chromosome_B", "Essential_B",
                                                    "strain", "sample", "experiment", "Read_name_ID")) 
                                          
          file3 <- read_tsv(path_to_file_3, col_names = TRUE,
            col_select = c("Feature_name_A", "Category_A", "Chromosome_A", "Essential_A",
                                                    "Feature_name_B", "Category_B", "Chromosome_B", "Essential_B",
                                                    "strain", "sample", "experiment", "Read_name_ID")) 

          
          log_step("Finding recombination hotspots...")
          hotspots_feature_A <-  merge(file1, file2, by= c("Feature_name_A")) %>% 
            merge(., file3, by= c("Feature_name_A")) %>% select(1, 2, 3, 4) %>% rename("Category_A" = !!names(.[2]),
                                                                                      "Chromosome_A" = !!names(.[3]),
                                                                                      "Essential_A" = !!names(.[4])) %>% 
            unique()

          

          log_step("Loading freq file...")
          # Load control reads
          freq_1_2_3 <- read_tsv(path_to_freqs, col_names = TRUE) %>% select("Feature_name_A", "Position_A", "count_norm") %>% 
            group_by(Feature_name_A) %>% 
            mutate(global_freq = sum(count_norm)) %>%  select(!c("count_norm")) %>%  unique()

          hotspots_freq <- merge(hotspots_feature_A, freq_1_2_3, by = c("Feature_name_A")) %>% unique()

          log_step("Saving hotspots dataframe...")
          write_tsv(hotspots_freq, file = paste0(strain, "/", sample, "_inter_discordant_pairs_unique_processed_valid_discordant_hotspots.tsv"))
          
          log_step("Plotting hotspots...")
          hotspots_plot <- ggplot(hotspots_freq, aes(y = Position_A, x = 0)) +
            #geom_segment(aes(xend = 0.95, yend = Position_A, color = global_freq), alpha = 1)+
            geom_tile(aes(color = global_freq), alpha = 1)+
            scale_color_gradientn(
              colors = c("white", "#e31a1c", "#8b2500"),
              #values = scales::rescale(c(0, 25, 50)),
              na.value = "gray90",
              #limits = c(0, 50),
              limits = c(0, 25),
              oob = scales::squish) +
            guides (color = guide_colourbar(barwidth = 0.5, barheight = 10,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            labs(color = "%") +
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(panel.background = element_rect(fill = "white")) +
            theme(legend.position="right") +
            #coord_cartesian(ylim = c(13195,14518), expand=FALSE) +
            #coord_cartesian(ylim = c(1, 14519), xlim = c(0,1), expand=FALSE) +
            coord_cartesian(ylim = c(1, 14519), xlim = c(0,0.1), expand=FALSE) +
            theme(aspect.ratio = 20) +
            scale_y_continuous(breaks = c(1, 6570,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks.x = element_blank()) +
            labs(
              title = paste0("Hotspots - ", strain_name, " - ", sample)
            )

          
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_hotspots_plot_", strain_name, "_", sample, ".svg"),
            plot = hotspots_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

          

EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total R processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample: $file1 or $file2 or $file3" >> "$log_file"
      echo "" >> "$log_file"
      fi

  done
done


##### R processing for recombination rate

# Get all processed_control.tsv files recursively in root folder

echo "Calculating recombination rate" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
echo "Calculating HO-pGAL read count" >> "$log_file"
start_time=$SECONDS

echo "Processing directory: ${MYWD}" >> "$log_file"
      root_dir="${MYWD}"
      #echo "$root_dir"
        #echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Finding all processed_control.tsv files..." >> "$log_file"
        
        # Export variables for R access
        export ROOT_DIR="$root_dir"

        Rscript - <<'EOF'
        # load libraries

        library(ggplot2)
        library(extrafont)
        library(svglite)
        library(purrr)
        library(stringr)
        library(readr)
        library(tidyverse, warn.conflicts = FALSE)
        library(tidyr, warn.conflicts = FALSE)
        library(dplyr, warn.conflicts = FALSE)
        options(dplyr.summarise.inform = FALSE)

        # Read environment variables
        root_dir <- Sys.getenv("ROOT_DIR")
        root_dir <- sub("/$", "", root_dir)  # Remove trailing slash


        print(paste("ROOT_DIR:", root_dir))

        log_step <- function(message) {
          timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
          message(sprintf("[%s] %s", timestamp, message))
        }

        # Define a function to process tsv files
        process_control_files <- function(file_path) {
          
          # Read file
          temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
          
          # Skip if empty
          if (nrow(temp_file) == 0) {
            return(NULL)
          }
          
          
          # Prepare control dataframe
          control_count_file <- temp_file %>%
            select(strain, sample, experiment, Category_A, Category_B) %>% 
            filter(Category_A == "control_norm" & Category_B == "control_norm")
          
          ncontrol <- nrow(control_count_file)
          
          control_count_file_processed <- control_count_file %>% 
            mutate(control_count = ncontrol) %>% unique() %>%
            select(strain, sample, experiment, control_count)
            
            return(control_count_file_processed)
        }


        log_step("Finding control files...")
        # Get all processed_control.tsv files recursively in root folder
        control_files <- list.files(
          path = root_dir,
          pattern = "processed_control\\.tsv$",
          recursive = TRUE,
          full.names = TRUE
        )



        log_step("Processing control files...")
        control_count_processed_df <- purrr::map_dfr(control_files, process_control_files)

        write_tsv(control_count_processed_df, file.path(root_dir,"control_count.tsv"))

        wt_control_count_processed_df <- control_count_processed_df %>%
          filter(strain == "1_Wt") %>%
          rename(Wt_control_count = control_count) %>%
          select(-strain)


        control_count_processed_df_ratio <- control_count_processed_df %>%
          left_join(wt_control_count_processed_df, by = c("sample", "experiment")) %>%
          mutate(Ratio_vs_Wt = control_count / Wt_control_count)

        write_tsv(control_count_processed_df_ratio, file.path(root_dir,"control_count_ratio.tsv"))

      
        
EOF



# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      wd_dir="${MYWD}"
      #echo "$root_dir"
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Calculating recombination rate" >> "$log_file"
        #start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        export WD_DIR="$wd_dir"
        #echo "ROOT_DIR: $ROOT_DIR"
        #echo "STRAIN: $STRAIN"
        Rscript - <<'EOF'
        # load libraries

        library(ggplot2)
        library(extrafont)
        library(svglite)
        library(purrr)
        library(stringr)
        library(readr)
        library(tidyverse, warn.conflicts = FALSE)
        library(tidyr, warn.conflicts = FALSE)
        library(dplyr, warn.conflicts = FALSE)
        options(dplyr.summarise.inform = FALSE)

        # Read environment variables
        root_dir <- Sys.getenv("ROOT_DIR")
        wd_dir <- Sys.getenv("WD_DIR")
        strain <- Sys.getenv("STRAIN")
        strain <- sub("/$", "", strain)  # Remove trailing slash
        strain_name <- basename(strain)

        print(paste("ROOT_DIR:", root_dir))

        log_step <- function(message) {
          timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
          message(sprintf("[%s] %s", timestamp, message))
        }

        # Define a function to process tsv files
        process_concordant_row_count_files <- function(file_path) {
          # Extract filename and directory parts
          file_base <- basename(file_path)
          strain_name <- basename(dirname(file_path))  # directory name above the file
          
          # 
          parts <- str_split(file_base, "_", simplify = TRUE)
          
          # Validate and extract parts safely
          if (ncol(parts) >= 3) {
            sample_name <- parts[1]
            experiment_name <- parts[2]
          } else {
            warning(paste("Filename does not match expected format:", file_base))
            return(NULL)
          }
          
          # Read file
          temp_file <- read_tsv(file_path, col_names = FALSE, show_col_types = FALSE)
          
          # Skip if empty
          if (nrow(temp_file) == 0) {
            return(NULL)
          }
          
          # Prepare nconcordant dataframe
          concordant_count_file <- temp_file %>%
            rename("concordant_count" = !!names(.[1])) %>%
            mutate(
              strain = strain_name,
              sample = sample_name,
              experiment = experiment_name
            )
          
          return(concordant_count_file)
        }

        # Define a function to process tsv files
        process_discordant_valid_files <- function(file_path) {
          # Extract filename and directory parts
          file_base <- basename(file_path)
          strain_name <- basename(dirname(file_path))  # directory name above the file
          
          # 
          parts <- str_split(file_base, "_", simplify = TRUE)
          
          # Validate and extract parts safely
          if (ncol(parts) >= 3) {
            sample_name <- parts[1]
            experiment_name <- parts[2]
          } else {
            warning(paste("Filename does not match expected format:", file_base))
            return(NULL)
          }
          
          # Read file
          temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
          
          # Skip if empty
          if (nrow(temp_file) == 0) {
            return(NULL)
          }
          
          # Prepare ndisc dataframe
          ndisc = nrow(temp_file)
          discordant_count_file <- tibble(discordant_count = ndisc) %>% 
            mutate(
              strain = strain_name,
              sample = sample_name,
              experiment = experiment_name
            )
          
          return(discordant_count_file)
        }

        log_step("Finding concordant row count files...")
        # Get all concordant_row_count.tsv files recursively in root folder
        concordant_row_count_files <- list.files(
          path = root_dir,
          pattern = "row_count\\.tsv$",
          recursive = TRUE,
          full.names = TRUE
        )

        log_step("Finding discordant row count files...")

        discordant_row_count_files <- list.files(
          path = root_dir,
          pattern = "unique_processed_valid\\.tsv$",
          recursive = TRUE,
          full.names = TRUE
        )

        log_step("Finding ratio control file...")

        ratio_control_file <- read_tsv(file.path(wd_dir, "control_count_ratio.tsv"), col_names = TRUE)

        

        log_step("Processing concordant row count files...")
        concordant_processed_df <- purrr::map_dfr(concordant_row_count_files, process_concordant_row_count_files)

        log_step("Processing discordant row count files...")
        discordant_processed_df <- purrr::map_dfr(discordant_row_count_files, process_discordant_valid_files)

        recombination_df <- left_join(concordant_processed_df, discordant_processed_df, by = c("strain", "sample", "experiment")) %>%
        select(strain, sample, experiment, concordant_count, discordant_count)

        recombination_df$concordant_count <- as.numeric(recombination_df$concordant_count)
        recombination_df$discordant_count <- as.numeric(recombination_df$discordant_count)
        
        log_step("Calculation recombination rate...")

        
        complete_recombination_df <- left_join(recombination_df, ratio_control_file) %>%  
          mutate(discordant_count_norm = discordant_count / Ratio_vs_Wt,
                discordant_concordant_ratio = discordant_count / concordant_count,
                discordant_concordant_ratio_norm = discordant_concordant_ratio / Ratio_vs_Wt) %>% 
          mutate(concordant_percentage = concordant_count / (concordant_count + discordant_count_norm) * 100,
                discordant_percentage = discordant_count_norm / (concordant_count + discordant_count_norm) * 100) %>%
          select(strain, sample, experiment, concordant_count, discordant_count, Ratio_vs_Wt, concordant_percentage, discordant_percentage,
            discordant_count_norm, discordant_concordant_ratio, discordant_concordant_ratio_norm)


        write_tsv(complete_recombination_df, file.path(root_dir, paste0(strain_name, "_recombination_df.tsv")))



        log_step("Calculation recombination summary...")

        
        recombination_summary <- complete_recombination_df %>%  group_by(strain, sample) %>% 
          summarise(mean_concordant_percentage = mean(concordant_percentage, na.rm = TRUE), 
                    sd_concordant_percentage = sd(concordant_percentage, na.rm = TRUE),
                    mean_discordant_percentage = mean(discordant_percentage, na.rm = TRUE),
                    sd_discordant_percentage = sd(discordant_percentage, na.rm = TRUE),
                    mean_discordant_concordant_ratio_norm = mean(discordant_concordant_ratio_norm, na.rm = TRUE),
                    sd_discordant_concordant_ratio_norm = sd(discordant_concordant_ratio_norm, na.rm = TRUE)) %>%
          select(strain, sample, mean_discordant_percentage, sd_discordant_percentage,
                mean_discordant_concordant_ratio_norm, sd_discordant_concordant_ratio_norm)
        
        write_tsv(recombination_summary, file.path(root_dir, paste0(strain_name, "_recombination_summary.tsv")))



        samples_order <- c("TSG", "TLG", "TLR")

        log_step("Plotting...")
          # Generate plots

        

        recombination_summary_graphs <- recombination_summary %>% ungroup() %>% filter(sample != "T0") %>% 
          pivot_longer(cols = c(
                                mean_discordant_percentage, sd_discordant_percentage), 
                      names_to = "category",
                      values_to = "value") %>% 
          separate(category, into = c("metric", "type", "trash"), sep = "_") %>% 
          select(-trash) %>%
          pivot_wider(
            names_from = metric,
            values_from = value
          ) %>% mutate(sample = factor(sample, levels = samples_order))


  


          log_step("Plotting...")
          # Generate plots

          bar_plot <- ggplot(recombination_summary_graphs, aes(x = sample, y = mean, fill = type)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), 
                          linewidth = 0.8, width = 0.2, colour = "gray10", position = position_dodge(width = 0.9)) +
            scale_fill_manual(values=c("grey")) +
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(expand=FALSE) +
            coord_cartesian(ylim = c(0, 0.2), expand=FALSE) +
            theme(aspect.ratio = 0.75) + 
            scale_x_discrete(name = expression("Sample")) +
            scale_y_continuous(name = expression("Percentage"),
                              #limits = c(0, 1),
                              breaks = seq(0,0.2,0.1)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                  axis.title.y = element_text(vjust = 1, size = 25)) + 
            theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 20, angle = 0), 
                  axis.text.y = element_text(vjust = 0, size = 20)) +
            labs(
              title = paste0("Recombination rate - ", strain_name)
            )

          ggsave(
            filename = paste0(strain,"/", "Recombination_rate_plot_", strain_name, ".svg"),
            plot = bar_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )


          recombination_summary_ratio_graphs <- recombination_summary %>% ungroup() %>% filter(sample != "T0") %>% 
          pivot_longer(cols = c(
                                mean_discordant_concordant_ratio_norm, sd_discordant_concordant_ratio_norm), 
                      names_to = "category",
                      values_to = "value") %>% 
          separate(category, into = c("metric", "type", "trash"), sep = "_") %>% 
          select(-trash) %>%
          pivot_wider(
            names_from = metric,
            values_from = value
          ) %>% mutate(sample = factor(sample, levels = samples_order))


  


          log_step("Plotting...")
          # Generate plots

          bar_plot <- ggplot(recombination_summary_ratio_graphs, aes(x = sample, y = mean, fill = type)) +
            geom_col(position = "dodge2") +
            geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), 
                          linewidth = 0.8, width = 0.2, colour = "gray10", position = position_dodge(width = 0.9)) +
            scale_fill_manual(values=c("grey")) +
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +  
            coord_cartesian(expand=FALSE) +
            coord_cartesian(ylim = c(0, 0.002), expand=FALSE) +
            theme(aspect.ratio = 0.75) + 
            scale_x_discrete(name = expression("Sample")) +
            scale_y_continuous(name = expression("Ratio"),
                              #limits = c(0, 1),
                              breaks = seq(0,0.002,0.001)) +
            theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                  axis.title.y = element_text(vjust = 1, size = 25)) + 
            theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 20, angle = 0), 
                  axis.text.y = element_text(vjust = 0, size = 20)) +
            labs(
              title = paste0("Recombination rate ratio - ", strain_name)
            )

          ggsave(
            filename = paste0(strain,"/", "Recombination_rate_ratio_plot_", strain_name, ".svg"),
            plot = bar_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )


          

   
          
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 

done


### R script to calculate Category_A read number and plot all timepoints###
# Loop inside each subdirectory of MYWD 
for strain in "${MYWD}"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      wd_dir="${MYWD}"
      #echo "$root_dir"
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Calculating Category_A read number" >> "$log_file"
        start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        export WD_DIR="$wd_dir"
        #echo "ROOT_DIR: $ROOT_DIR"
        #echo "STRAIN: $STRAIN"
        Rscript - <<'EOF'
        # load libraries

        library(ggplot2)
        library(extrafont)
        library(svglite)
        library(purrr)
        library(stringr)
        library(readr)
        library(ggbreak)
        library(tidyverse, warn.conflicts = FALSE)
        library(tidyr, warn.conflicts = FALSE)
        library(dplyr, warn.conflicts = FALSE)
        options(dplyr.summarise.inform = FALSE)

        # Read environment variables
        root_dir <- Sys.getenv("ROOT_DIR")
        wd_dir <- Sys.getenv("WD_DIR")
        strain <- Sys.getenv("STRAIN")
        strain <- sub("/$", "", strain)  # Remove trailing slash
        strain_name <- basename(strain)

        print(paste("ROOT_DIR:", root_dir))

        log_step <- function(message) {
          timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
          message(sprintf("[%s] %s", timestamp, message))
        }

        # Define a function to process tsv files
        process_valid_counts_files <- function(file_path) {
        # Extract filename and directory parts
        file_base <- basename(file_path)
        strain_name <- basename(dirname(file_path))  # directory name above the file
        
        # 
        parts <- str_split(file_base, "_", simplify = TRUE)
        
        # Validate and extract parts safely
        if (ncol(parts) >= 3) {
            sample_name <- parts[1]
            experiment_name <- parts[2]
        } else {
            warning(paste("Filename does not match expected format:", file_base))
            return(NULL)
        }
        
        # Read file
        temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
        
        # Skip if empty
        if (nrow(temp_file) == 0) {
            return(NULL)
        }
  
        # Prepare counts distribution dataframe
        counts_distribution_file <- temp_file %>%
            group_by(strain, sample, experiment, Category_A) %>%
            summarise(total_count = sum(count), .groups = "drop_last") %>%
            mutate(
            group_total = sum(total_count),
            percent = 100 * (total_count / group_total)
            ) %>%
            ungroup()
        
        return(counts_distribution_file)
        }


        log_step("Finding valid_counts files...")
        # Get all coverage.tsv files recursively in root folder
        valid_counts_files <- list.files(
        path = root_dir,
        pattern = "valid_counts\\.tsv$",
        recursive = TRUE,
        full.names = TRUE
        )
        valid_counts_files
        log_step("Processing valid_counts files...")
        valid_counts_processed_df <- purrr::map_dfr(valid_counts_files, process_valid_counts_files)



        log_step("Finding ratio control file...")

        ratio_control_file <- read_tsv(file.path(wd_dir, "control_count_ratio.tsv"), col_names = TRUE)



        complete_valid_counts_df <- left_join(valid_counts_processed_df, ratio_control_file) %>%  
        mutate(total_count_norm = total_count / Ratio_vs_Wt)

        complete_valid_counts_summary_df <- complete_valid_counts_df %>% 
        group_by(strain, sample, Category_A) %>% 
        summarise(mean_total_count = mean(total_count),
                    sd_total_count = sd(total_count),
                    mean_total_count_norm = mean(total_count_norm),
                    sd_total_count_norm = sd(total_count_norm))


        genomic_categories_order <- c(
        "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
        "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
        "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
        )

        samples_order <- c("TSG", "TLG", "TLR")



        complete_valid_counts_summary_df_ordered <- complete_valid_counts_summary_df %>% mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                                                                                                sample = factor(sample, levels = samples_order)) %>%
        arrange(strain, sample, Category_A)

        write_tsv(complete_valid_counts_summary_df_ordered, file.path(root_dir, paste0(strain_name, "_category_A_valid_counts_summary_df.tsv")))
        


        log_step("Plotting...")
          # Generate plots
        
        bar_plot <- ggplot(complete_valid_counts_summary_df_ordered, aes(x = Category_A, y = mean_total_count_norm, fill = sample)) +
        geom_col(position = "dodge2") +
        geom_errorbar(aes(ymin = mean_total_count_norm - sd_total_count_norm, ymax = mean_total_count_norm + sd_total_count_norm),
                        linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
        scale_fill_manual(values=c("#252159", "#469CD7", "#8BE0FC")) +
        theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                        panel.background = element_blank(), 
                                                        plot.background = element_rect(fill = "transparent", colour = NA)) +
        theme(legend.position="right") +  
        coord_cartesian(expand=FALSE) +
        scale_x_discrete(name = expression(""),
                        labels = c("ORF", "Intergenic","LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
        scale_y_break(c(125, 1000), scales = 0.5, ticklabels = c(seq(0, 125, 25), 1000, 3000, 5000, 7000)) +
        scale_y_continuous(
            limits = c(-10, 10000),
            expand = expansion(mult = c(0.05, 0.05))
        ) +
        theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                axis.title.y = element_text(vjust = 1, size = 25)) + 
        theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 20, angle = 90), 
                axis.text.y = element_text(vjust = 0, size = 20)) +
        theme(
            axis.line.y.right = element_blank(),
            axis.ticks.y.right = element_blank(),
            axis.text.y.right = element_blank(),
            axis.title.y.right = element_blank()
        ) +
        labs(
              title = paste0("Category_A norm.read number  - ", strain_name)
            )

          ggsave(
            filename = paste0(strain,"/", "Category_A_read_number_norm_plot_", strain_name, ".svg"),
            plot = bar_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

        log_step("Plotting...")
          # Generate plots
        
        bar_plot <- ggplot(complete_valid_counts_summary_df_ordered, aes(x = Category_A, y = mean_total_count, fill = sample)) +
        geom_col(position = "dodge2") +
        geom_errorbar(aes(ymin = mean_total_count - sd_total_count, ymax = mean_total_count + sd_total_count),
                        linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
        scale_fill_manual(values=c("#252159", "#469CD7", "#8BE0FC")) +
        theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                        panel.background = element_blank(), 
                                                        plot.background = element_rect(fill = "transparent", colour = NA)) +
        theme(legend.position="right") +  
        coord_cartesian(expand=FALSE) +
        scale_x_discrete(name = expression(""),
                        labels = c("ORF", "Intergenic","LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
        scale_y_break(c(125, 1000), scales = 0.5, ticklabels = c(seq(0, 125, 25), 1000, 3000, 5000, 7000)) +
        scale_y_continuous(
            limits = c(-10, 10000),
            expand = expansion(mult = c(0.05, 0.05))
        ) +
        theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                axis.title.y = element_text(vjust = 1, size = 25)) + 
        theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 20, angle = 90), 
                axis.text.y = element_text(vjust = 0, size = 20)) +
        theme(
            axis.line.y.right = element_blank(),
            axis.ticks.y.right = element_blank(),
            axis.text.y.right = element_blank(),
            axis.title.y.right = element_blank()
        ) +
        labs(
              title = paste0("Category_A read number  - ", strain_name)
            )

          ggsave(
            filename = paste0(strain,"/", "Category_A_read_number_no_norm_plot_", strain_name, ".svg"),
            plot = bar_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

EOF

done

# R processing for error rate

# Get all processed_valid_error_rate.tsv files recursively in root folder

echo "Calculating error rate" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
start_time=$SECONDS

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      wd_dir="${MYWD}"
      #echo "$root_dir"
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        
        start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        export WD_DIR="$wd_dir"
      #echo "$root_dir"
        #echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Finding all processed_valid_error_rate.tsv files..." >> "$log_file"
        
    

        Rscript - <<'EOF'
        # load libraries

        library(ggplot2)
        library(extrafont)
        library(svglite)
        library(purrr)
        library(stringr)
        library(readr)
        library(tidyverse, warn.conflicts = FALSE)
        library(tidyr, warn.conflicts = FALSE)
        library(dplyr, warn.conflicts = FALSE)
        options(dplyr.summarise.inform = FALSE)

        # Read environment variables
        root_dir <- Sys.getenv("ROOT_DIR")
        root_dir <- sub("/$", "", root_dir)  # Remove trailing slash
        strain <- Sys.getenv("STRAIN")
        strain <- sub("/$", "", strain)  # Remove trailing slash
        strain_name <- basename(strain)

        #root_dir <- "/Users/lab2.3/GWS3/WD_test_complete"

        print(paste("ROOT_DIR:", root_dir))

        log_step <- function(message) {
        timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
        message(sprintf("[%s] %s", timestamp, message))
        }

        # Define a function to process tsv files
        process_error_rate_files <- function(file_path) {
        
        # Read file
        temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
        
        # Skip if empty
        if (nrow(temp_file) == 0) {
            return(NULL)
        }
        
        
        # Prepare error_rate dataframe
        error_rate_file <- temp_file %>%
            select(strain, sample, experiment, valid_rate) 
        
        error_rate_file_processed <- error_rate_file %>% 
            mutate(error_rate = 100-valid_rate) 
            
        
        return(error_rate_file_processed)
        }


        log_step("Finding error_rate files...")
        # Get all error_rate.tsv files recursively in root folder
        error_rate_files <- list.files(
        path = root_dir,
        pattern = "processed_valid_error_rate\\.tsv$",
        recursive = TRUE,
        full.names = TRUE
        )



        log_step("Processing error_rate files...")
        error_rate_processed_df <- purrr::map_dfr(error_rate_files, process_error_rate_files)

        error_rate_processed_summary_df <- error_rate_processed_df %>%  group_by(strain, sample) %>% 
        summarise(mean_error_rate = mean(error_rate, na.rm = TRUE), 
                    sd_error_rate = sd(error_rate, na.rm = TRUE)) %>% 
        filter(sample != "T0") %>% 
        ungroup

        write_tsv(error_rate_processed_summary_df, file.path(root_dir, paste0(strain_name, "_error_rate_summary.tsv")))


        samples_order <- c("TSG", "TLG", "TLR")

        log_step("Plotting...")
        # Generate plots

        error_rate_processed_summary_df <- error_rate_processed_summary_df %>% 
        mutate(sample = factor(sample, levels = samples_order))





        log_step("Plotting...")
        # Generate plots

        bar_plot <- ggplot(error_rate_processed_summary_df, aes(x = sample, y = mean_error_rate, fill = sample)) +
        geom_col(position = "dodge2") +
        geom_errorbar(aes(ymin = mean_error_rate - sd_error_rate, ymax = mean_error_rate + sd_error_rate), 
                        linewidth = 0.8, width = 0.2, colour = "gray10", position = position_dodge(width = 0.9)) +
        scale_fill_manual(values=c("#252159", "#469CD7", "#8BE0FC")) +
        theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                        panel.background = element_blank(), 
                                                        plot.background = element_rect(fill = "transparent", colour = NA)) +
        theme(legend.position="right") +  
        coord_cartesian(expand=FALSE) +
        coord_cartesian(ylim = c(0, 50), expand=FALSE) +
        theme(aspect.ratio = 0.75) + 
        scale_x_discrete(name = expression("Sample")) +
        scale_y_continuous(name = expression("Percentage"),
                            #limits = c(0, 1),
                            breaks = seq(0,50,10)) +
        theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                axis.title.y = element_text(vjust = 1, size = 25)) + 
        theme(axis.text.x = element_text(hjust = 0.5, vjust = 0, size = 20, angle = 0), 
                axis.text.y = element_text(vjust = 0, size = 20)) +
        labs(
            title = paste0("Error rate - ", strain_name)
        )

        ggsave(
        filename = paste0(strain,"/", "Error_rate_plot_", strain_name, ".svg"),
        plot = bar_plot,
        #width = 8,
        #height = 3.6,
        device = svglite,
        bg = "transparent"
        )



          
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 

done



### Added BLAST levels of validation
############## R processing of 75bp VALID reads ############

# R processing for inter-chromosomal discordant read pairs after BLAST cross-validation
# After processing all samples, only valid discordant reads are kept for further analysis.
# With this script, valid reads are identified and saved in a df.
# We have defined 5 different levels of validation for each read pair:
# Start timer for R processing

start_time_total_R_valid=$SECONDS

echo "================================" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line
echo "### R processing for new valid discordant read pairs, 75bp analysis, different BLAST levels ###" >> "$log_file"
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Initiated at ${current_time}" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line 

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
    for experiment in E1 E2 E3; do
      file1="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_blast_center_combined_results.tsv"
      file2="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_blast_prev_combined_results.tsv"
      file3="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_blast_next_combined_results.tsv"
      fileorig="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed.tsv"
      filecontrol="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_control.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" && -f "$fileorig" && -f "$filecontrol" ]]; then
        echo "$(basename "$strain") ${sample} ${experiment}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant tsv files for $file1 , $file2 , $file3 and $fileorig" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(extrafont)
          library(stringr)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          category_path <- "${CATEGORY_PATH}"
          strain <- "${strain}"
          sample <- "${sample}"
          experiment <- "${experiment}" 
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"
          path_to_file_original <- "${fileorig}"
          path_to_file_control <- "${filecontrol}"
          path_to_categories_pairs_file <- file.path(category_path, "PMV_categories_pairs.tsv")
          path_to_features_pairs_file <- file.path(category_path, "PMV_features_pairs.tsv")


          # Functions

          #path_to_file_1
          #path_to_file_2
          #path_to_file_3
          #path_to_file_original

          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          # 0 hits: valid
          process_blast_filtered_files_option1 <- function (blast_filtered_file_path) {
            blast_filtered_df <- read.table(blast_filtered_file_path,
                                            header=FALSE, sep = "\t", 
                                            col.names = paste0("V",seq_len(5)), fill = TRUE) %>% 
              rename("pair_group" = !!names(.[1]), "Feature_name_B" = !!names(.[2]), "hits" = !!names(.[3]), 
                    "mismatch" = !!names(.[4]), "length" = !!names(.[5])) %>% 
              mutate(valid = ifelse(hits == 0, "yes", "no"))
            
            return(blast_filtered_df)
            
          }

          # Valid: >=1 hit & >= 3 mismatch & lenght = 75nt + 0hits
          process_blast_filtered_files_option2 <- function (blast_filtered_file_path) {
            blast_filtered_df <- read.table(blast_filtered_file_path,
                                            header=FALSE, sep = "\t", 
                                            col.names = paste0("V",seq_len(5)), fill = TRUE) %>% 
              rename("pair_group" = !!names(.[1]), "Feature_name_B" = !!names(.[2]), "hits" = !!names(.[3]), 
                    "mismatch" = !!names(.[4]), "length" = !!names(.[5])) %>% 
              mutate(valid = ifelse(hits == 0, "yes", ifelse(hits !=0 & mismatch >2 & length == 75, "yes", "no")))
            
            return(blast_filtered_df)
            
          }

          # Valid: >=1 hit & = 2 mismatch & lenght = 75nt + >=1 hit & >= 3 mismatch & lenght = 75nt + 0hits 
          process_blast_filtered_files_option3 <- function (blast_filtered_file_path) {
            blast_filtered_df <- read.table(blast_filtered_file_path,
                                            header=FALSE, sep = "\t", 
                                            col.names = paste0("V",seq_len(5)), fill = TRUE) %>% 
              rename("pair_group" = !!names(.[1]), "Feature_name_B" = !!names(.[2]), "hits" = !!names(.[3]), 
                    "mismatch" = !!names(.[4]), "length" = !!names(.[5])) %>% 
              mutate(valid = ifelse(hits == 0, "yes", 
                                    ifelse(hits !=0 & mismatch >2 & length == 75, "yes", 
                                          ifelse(hits !=0 & mismatch == 2 & length == 75, "yes", "no"))))
            
            return(blast_filtered_df)
            
          }

          # Valid: >=1 hit & = 1 mismatch & lenght = 75nt + >=1 hit & = 2 mismatch & lenght = 75nt + >=1 hit & >= 3 mismatch & lenght = 75nt + 0hits 
          process_blast_filtered_files_option4 <- function (blast_filtered_file_path) {
            blast_filtered_df <- read.table(blast_filtered_file_path,
                                            header=FALSE, sep = "\t", 
                                            col.names = paste0("V",seq_len(5)), fill = TRUE) %>% 
              rename("pair_group" = !!names(.[1]), "Feature_name_B" = !!names(.[2]), "hits" = !!names(.[3]), 
                    "mismatch" = !!names(.[4]), "length" = !!names(.[5])) %>% 
              mutate(valid = ifelse(hits == 0, "yes", 
                                    ifelse(hits !=0 & mismatch >2 & length == 75, "yes", 
                                          ifelse(hits !=0 & mismatch == 2 & length == 75, "yes", 
                                                  ifelse(hits != 0 & mismatch == 1 & length == 75, "yes", "no")))))
            
            return(blast_filtered_df)
            
          }

          # Valid: all + >=1 hit & = 1 mismatch & lenght = 75nt + >=1 hit & = 2 mismatch & lenght = 75nt + >=1 hit & >= 3 mismatch & lenght = 75nt + 0hits 
          process_blast_filtered_files_option5 <- function (blast_filtered_file_path) {
            blast_filtered_df <- read.table(blast_filtered_file_path,
                                            header=FALSE, sep = "\t", 
                                            col.names = paste0("V",seq_len(5)), fill = TRUE) %>% 
              rename("pair_group" = !!names(.[1]), "Feature_name_B" = !!names(.[2]), "hits" = !!names(.[3]), 
                    "mismatch" = !!names(.[4]), "length" = !!names(.[5])) %>% 
              mutate(valid = "yes")
            
            return(blast_filtered_df)
            
          }


          get_blast_validated_complete_df <- function (center_file, prev_file, next_file) {
            
            complete_df <- left_join(prev_file, next_file, by = "pair_group") %>% 
              left_join(center_file, ., by = "pair_group") %>% 
              rename("valid_prev" = !!names(.[11]), "valid_next" = !!names(.[16])) %>% 
              separate(pair_group, c("pair_group_name", "number"), "-", remove = FALSE) %>% 
              mutate_at(vars(valid_prev, valid_next), ~replace_na(., "yes")) %>% 
              mutate(valid_all = ifelse(valid == "yes" & valid_prev == "yes" & valid_next == "yes", "yes", "no")) %>% 
              group_by(pair_group_name, pair_group) %>%
              mutate(all_yes_T_F = all(valid_all == "yes")) %>%
              group_by(pair_group_name) %>%
              mutate(group_all_yes_T_F = all(all_yes_T_F)) %>%
              ungroup() %>%
              mutate(valid_def = ifelse(group_all_yes_T_F, "yes", "no")) %>% 
              filter(valid_def == "yes") %>% select(pair_group) %>% 
              rename(Read_name_ID = pair_group) 
            
            return(complete_df)
            
          }


          center_df_option1 <- process_blast_filtered_files_option1(path_to_file_1)
          center_df_option2 <- process_blast_filtered_files_option2(path_to_file_1)
          center_df_option3 <- process_blast_filtered_files_option3(path_to_file_1)
          center_df_option4 <- process_blast_filtered_files_option4(path_to_file_1)
          center_df_option5 <- process_blast_filtered_files_option5(path_to_file_1)

          next_df_option1 <- process_blast_filtered_files_option1(path_to_file_1)
          next_df_option2 <- process_blast_filtered_files_option2(path_to_file_1)
          next_df_option3 <- process_blast_filtered_files_option3(path_to_file_1)
          next_df_option4 <- process_blast_filtered_files_option4(path_to_file_1)
          next_df_option5 <- process_blast_filtered_files_option5(path_to_file_1)

          prev_df_option1 <- process_blast_filtered_files_option1(path_to_file_1)
          prev_df_option2 <- process_blast_filtered_files_option2(path_to_file_1)
          prev_df_option3 <- process_blast_filtered_files_option3(path_to_file_1)
          prev_df_option4 <- process_blast_filtered_files_option4(path_to_file_1)
          prev_df_option5 <- process_blast_filtered_files_option5(path_to_file_1)


          

          log_step("Finding valid reads...") 

          valid_read_name_option1 <- get_blast_validated_complete_df(center_df_option1, prev_df_option1, next_df_option1)
          valid_read_name_option2 <- get_blast_validated_complete_df(center_df_option2, prev_df_option2, next_df_option2)
          valid_read_name_option3 <- get_blast_validated_complete_df(center_df_option3, prev_df_option3, next_df_option3)
          valid_read_name_option4 <- get_blast_validated_complete_df(center_df_option4, prev_df_option4, next_df_option4)
          valid_read_name_option5 <- get_blast_validated_complete_df(center_df_option5, prev_df_option5, next_df_option5)
          #head(valid_read_name)


          original_df <- read_tsv(path_to_file_original,col_names = TRUE) %>% 
            mutate(Read_name_ID = with(., paste0(Read_name, "_", pair_group))) %>%
            filter(Category_A != "control_norm", Category_B != "control_norm", Category_A != "control", Category_B != "control")

          log_step("Comparing with original file...") 

          valid_pairs_df_option1 <- semi_join(original_df, valid_read_name_option1)
          valid_pairs_df_option2 <- semi_join(original_df, valid_read_name_option2)
          valid_pairs_df_option3 <- semi_join(original_df, valid_read_name_option3)
          valid_pairs_df_option4 <- semi_join(original_df, valid_read_name_option4)
          valid_pairs_df_option5 <- semi_join(original_df, valid_read_name_option5)

          n_valid_reads_option1 <- nrow(valid_pairs_df_option1)
          n_valid_reads_option2 <- nrow(valid_pairs_df_option2)
          n_valid_reads_option3 <- nrow(valid_pairs_df_option3)
          n_valid_reads_option4 <- nrow(valid_pairs_df_option4)
          n_valid_reads_option5 <- nrow(valid_pairs_df_option5)

          n_original_reads <- nrow(original_df)

          log_step("Calculating error rate...")

          error_rate_option1 <- tibble(strain = strain_name, 
                              sample = sample,
                              experiment = experiment,
                              original_reads = n_original_reads,
                              valid_reads = n_valid_reads_option1) %>% 
            mutate(valid_rate = (valid_reads/original_reads)*100)

          error_rate_option2 <- tibble(strain = strain_name, 
                              sample = sample,
                              experiment = experiment,
                              original_reads = n_original_reads,
                              valid_reads = n_valid_reads_option2) %>% 
            mutate(valid_rate = (valid_reads/original_reads)*100)

          error_rate_option3 <- tibble(strain = strain_name, 
                              sample = sample,
                              experiment = experiment,
                              original_reads = n_original_reads,
                              valid_reads = n_valid_reads_option3) %>% 
            mutate(valid_rate = (valid_reads/original_reads)*100)

          error_rate_option4 <- tibble(strain = strain_name, 
                              sample = sample,
                              experiment = experiment,
                              original_reads = n_original_reads,
                              valid_reads = n_valid_reads_option4) %>% 
            mutate(valid_rate = (valid_reads/original_reads)*100)

          error_rate_option5 <- tibble(strain = strain_name, 
                              sample = sample,
                              experiment = experiment,
                              original_reads = n_original_reads,
                              valid_reads = n_valid_reads_option5) %>% 
            mutate(valid_rate = (valid_reads/original_reads)*100)


          
         
          # Write the new TSV
          log_step("Saving processed dataframe...") 
          log_step(paste0("Saving tsv files for: ", strain_name, " ",  sample, " ", experiment, "..."))

          write_tsv(valid_pairs_df_option1, file = paste0(strain, "/", sample, "_", experiment, "_option1","_inter_discordant_pairs_unique_processed_valid.tsv"))
          write_tsv(valid_pairs_df_option2, file = paste0(strain, "/", sample, "_", experiment, "_option2","_inter_discordant_pairs_unique_processed_valid.tsv"))
          write_tsv(valid_pairs_df_option3, file = paste0(strain, "/", sample, "_", experiment, "_option3","_inter_discordant_pairs_unique_processed_valid.tsv"))
          write_tsv(valid_pairs_df_option4, file = paste0(strain, "/", sample, "_", experiment, "_option4","_inter_discordant_pairs_unique_processed_valid.tsv"))
          write_tsv(valid_pairs_df_option5, file = paste0(strain, "/", sample, "_", experiment, "_option5","_inter_discordant_pairs_unique_processed_valid.tsv"))
          
          
          write_tsv(error_rate_option1, file = paste0(strain, "/", sample, "_", experiment, "_option1", "_inter_discordant_pairs_unique_processed_valid_error_rate.tsv"))
          write_tsv(error_rate_option2, file = paste0(strain, "/", sample, "_", experiment, "_option2", "_inter_discordant_pairs_unique_processed_valid_error_rate.tsv"))
          write_tsv(error_rate_option3, file = paste0(strain, "/", sample, "_", experiment, "_option3", "_inter_discordant_pairs_unique_processed_valid_error_rate.tsv"))
          write_tsv(error_rate_option4, file = paste0(strain, "/", sample, "_", experiment, "_option4", "_inter_discordant_pairs_unique_processed_valid_error_rate.tsv"))
          write_tsv(error_rate_option5, file = paste0(strain, "/", sample, "_", experiment, "_option5", "_inter_discordant_pairs_unique_processed_valid_error_rate.tsv"))
          

EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing for different blast options completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample/$experiment: $file1 or $file2 or $file3 or $fileorig" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done


# R script to repeat discordant analysis with all blast options
# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
    for experiment in E1 E2 E3; do
        for blast_option in option1 option2 option3 option4 option5 ; do
        file1="${strain}/${sample}_${experiment}_${blast_option}_inter_discordant_pairs_unique_processed_valid.tsv"
        file2="${strain}/${sample}_${experiment}_${blast_option}_inter_discordant_pairs_unique_processed_valid_error_rate.tsv"
        filecontrol="${strain}/${sample}_${experiment}_inter_discordant_pairs_unique_processed_control.tsv"
      if [[ -f "$file1" && -f "$file2" ]]; then
        echo "$(basename "$strain") ${sample} ${experiment} ${blast_option}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant tsv files for $file1 , $file2" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(extrafont)
          library(stringr)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          category_path <- "${CATEGORY_PATH}"
          strain <- "${strain}"
          sample <- "${sample}"
          experiment <- "${experiment}" 
          blast_option <- "${blast_option}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_control <- "${filecontrol}"
          path_to_categories_pairs_file <- file.path(category_path, "PMV_categories_pairs.tsv")
          path_to_features_pairs_file <- file.path(category_path, "PMV_features_pairs.tsv")


          # Functions

          #path_to_file_1
          #path_to_file_2
          #path_to_file_3
          #path_to_file_original

          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }


          # Calculate distribution of valid reads
          df_categories_pairs <- read_tsv(path_to_categories_pairs_file,col_names = FALSE, show_col_types = FALSE) %>%
            rename("Category_A" = !!names(.[1]), "Category_B" = !!names(.[2]))

          # Categories
          categories <- unique(df_categories_pairs\$Category_A)

          # Process_categories
          process_categories <- function(categories_i, valid_pairs_df_file, categories_df_file) {
            # Possible combinations
            combinations <- categories_df_file %>%
              filter(Category_A == categories_i) %>%
              distinct(Category_B) %>%
              pull()
            
            # Filter discordant pairs for each Category_A
            valid_pairs_filtered <- filter(valid_pairs_df_file, Category_A == categories_i)
            
            # Calculate number of reads 
            map_dfr(combinations, function(categoryB) {
              n <- valid_pairs_filtered %>% filter(Category_B == categoryB) %>% nrow()
              tibble(Category_A = categories_i, Category_B = categoryB, count = n)
            })
          }
          
          # Write the new TSV
          log_step("Calculating discordant reads distribution along genomic categories...") 

          valid_pairs_df <- read_tsv(path_to_file_1,col_names = TRUE)
          #valid_pairs_df 
          
          # Get counts
          count_df <- map_dfr(categories, process_categories, valid_pairs_df_file = valid_pairs_df, categories_df_file = df_categories_pairs) %>% 
            mutate(strain = strain_name,
                  sample = sample,
                  experiment = experiment)
          write_tsv(count_df, file = paste0(strain, "/", sample, "_", experiment,  "_", blast_option, "_inter_discordant_pairs_unique_processed_valid_counts.tsv"))


          # Set genomic categories order
          genomic_categories_order <- c(
            "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
            "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
            "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
          )

        
          log_step("Calculating global inter-chromosomal discordant read pairs distribution...")
          # Calculate global inter-chromosomal discordant read pairs distribution 
          global_distribution <- count_df %>% 
            group_by(strain, sample, experiment) %>% 
            mutate(global_percentage = (count / sum(count))*100,
                  strain_sample_comb = paste0(strain, "_", sample)) %>% 
            replace(is.na(.), 0) %>% 
            group_by(strain, sample, experiment, strain_sample_comb,  Category_A, Category_B) %>%
            summarise(mean_global_percentage = mean(global_percentage, na.rm = TRUE),
                      sd_global_percentage = sd(global_percentage, na.rm = TRUE)) %>%
            # Apply genomic_categories_order
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                  Category_B = factor(Category_B, levels = genomic_categories_order)) %>%
            arrange(strain, sample, experiment, Category_A, Category_B)

          write_tsv(global_distribution, file = paste0(strain, "/", sample, "_", experiment, "_", blast_option, "_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv"))

          log_step("Calculating category inter-chromosomal discordant read pairs distribution...")
          # Calculate average per_category inter-chromosomal discordant read pairs distribution 
          category_distribution <- count_df %>% 
            group_by(strain, sample, experiment, Category_A) %>% 
            mutate(category_percentage = (count / sum(count))*100,
                  strain_sample_comb = paste0(strain, "_", sample)) %>% 
            replace(is.na(.), 0) %>%
            group_by(strain, sample, experiment, strain_sample_comb, Category_A, Category_B) %>%
            summarise(mean_category_percentage = mean(category_percentage, na.rm = TRUE),
                      sd_category_percentage = sd(category_percentage, na.rm = TRUE)) %>%
            # Apply genomic_categories_order
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                  Category_B = factor(Category_B, levels = genomic_categories_order)) %>%
            arrange(strain, sample, experiment,Category_A, Category_B)
          
          write_tsv(category_distribution, file = paste0(strain, "/", sample, "_", experiment, "_", blast_option, "_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv"))


          # Inter-chromosomal discordant read pairs matrix
          df_features_pairs <- read_tsv(path_to_features_pairs_file, col_names = TRUE, show_col_types = FALSE)
          #all_pairs <- expand.grid(Feature_name_A = sort(unique(df_features_pairs\$Feature_name_A)), Feature_name_B = sort(unique(df_features_pairs\$Feature_name_B)))
          control_df <- read_tsv(path_to_file_control,col_names = TRUE) %>% filter(Category_A=="control_norm", Category_B=="control_norm")
          
          #head(all_pairs)
          
          get_discordant_matrix <- function(valid_pairs_df_file, all_pairs_df, control_df_file) {
            posA_info <- all_pairs_df %>%
              select(Feature_name_A, Position_A = Position, Essential_A = Essential) %>%
              distinct()
            
            posB_info <- all_pairs_df %>%
              select(Feature_name_B, Position_B = Position, Essential_B = Essential) %>%
              distinct()
            
            valid_pairs_df_posA <- valid_pairs_df_file %>%
              left_join(posA_info, by = "Feature_name_A")
            
            valid_pairs_df_posAB <- valid_pairs_df_posA %>%
              left_join(posB_info, by = "Feature_name_B")
            
            pair_counts <- valid_pairs_df_posAB %>%
              group_by(strain, sample, experiment, Feature_name_A, Feature_name_B) %>%
              summarise(count = n(), .groups = "drop")
            
            complete_matrix <- left_join(valid_pairs_df_posAB, pair_counts,
                                        by = c("Feature_name_A", "Feature_name_B", "strain", "sample", "experiment")) %>%
              distinct()
            
            count_total <- nrow(control_df_file)
            complete_matrix <- complete_matrix %>%
              mutate(count_norm = (count / count_total) * 100) %>% 
              select(!c(pair_group, pair_group_name, number, Feature_name_B_prev, Feature_name_B_next))
            
            return(complete_matrix)
          }

          log_step("Generating discordant matrix...")
          complete_matrix <- get_discordant_matrix(valid_pairs_df, df_features_pairs, control_df)
          complete_matrix_noORF_nointergenic <- complete_matrix %>% filter(Category_A != "ORF", Category_B != "ORF", Category_A != "intergenic", Category_B != "intergenic")

          log_step("Saving discordant matrix...")
          write_tsv(complete_matrix, file = paste0(strain, "/", sample, "_", experiment, "_", blast_option, "_inter_discordant_pairs_unique_processed_valid_discordant_matrix.tsv"))
          write_tsv(complete_matrix_noORF_nointergenic, file = paste0(strain, "/", sample, "_", experiment, "_", blast_option, "_inter_discordant_pairs_unique_processed_valid_discordant_matrix_noORF_nointergenic.tsv"))
          

          log_step("Plotting discordant matrix...")
          matrix_plot <-ggplot(complete_matrix, aes(y = Position_B, x = Position_A)) +
            #geom_hdr(xlim = c(0,14518), ylim = c(14518,0), method = "kde", fill = "brown4") + 
            geom_point(aes(colour = count_norm), alpha = 1, size = 0.8) +
            scale_colour_gradient2(low= "white", mid = "#4ae034", high = "#00641b",
                                  midpoint = 1,
                                  limits = c (0, 5),
                                  oob = scales::squish) + 
            theme_bw(base_family = "Arial") + 
            theme(panel.background = element_blank()) +
            theme(plot.background = element_rect(fill = "transparent", colour = NA))+
            theme(legend.position="right") +
            theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
            guides (colour = guide_colourbar(barwidth = 0.5, barheight = 5,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            coord_cartesian(xlim = c(0,14518), ylim = c(14518, 0), expand=FALSE) +
            theme(aspect.ratio = 1) +
            scale_x_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487), position = "top") +
            scale_y_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            geom_hline(yintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_hline(yintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 144877),
                      linetype="dashed", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="dashed", color = "black", linewidth=0.05) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks = element_blank()) +
            geom_abline(intercept = 0, slope = 1, color = "black", linetype = "solid", linewidth = 0.05) +
            labs(
              title = paste0("Inter_chromosomal discordant matrix - ", strain_name, " - ", sample, " - ", experiment, " - ", blast_option),
              colour = "Freq (%)")
          
          #paste0(subdir, "/plot_", chr_name, "_75nt_", gsub("\\.tsv$", "", suffix), ".svg")
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_matrix_plot_", strain_name, "_", sample, "_", experiment, "_", blast_option, ".svg"),
            plot = matrix_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

          log_step("Plotting discordant matrix - no ORF no intergenic...")
          matrix_plot <-ggplot(complete_matrix_noORF_nointergenic, aes(y = Position_B, x = Position_A)) +
            #geom_hdr(xlim = c(0,14518), ylim = c(14518,0), method = "kde", fill = "brown4") + 
            geom_point(aes(colour = count_norm), alpha = 1, size = 2) +
            scale_colour_gradient2(low= "white", mid = "#4ae034", high = "#00641b",
                                  midpoint = 1,
                                  limits = c (0, 5),
                                  oob = scales::squish) + 
            theme_bw(base_family = "Arial") + 
            theme(panel.background = element_blank()) +
            theme(plot.background = element_rect(fill = "transparent", colour = NA))+
            theme(legend.position="right") +
            theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
            guides (colour = guide_colourbar(barwidth = 0.5, barheight = 5,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            coord_cartesian(xlim = c(13195,14518), ylim = c(14518, 13195), expand=FALSE) +
            theme(aspect.ratio = 1) +
            scale_x_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487), position = "top") +
            scale_y_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            geom_hline(yintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_hline(yintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 144877),
                      linetype="dashed", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="dashed", color = "black", linewidth=0.05) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks = element_blank()) +
            geom_abline(intercept = 0, slope = 1, color = "black", linetype = "solid", linewidth = 0.05) +
            labs(
              title = paste0("Inter_chromosomal discordant matrix no ORF no intergenic - ", strain_name, " - ", sample, " - ", experiment, " - ", blast_option),
              colour = "Freq (%)")
          
          #paste0(subdir, "/plot_", chr_name, "_75nt_", gsub("\\.tsv$", "", suffix), ".svg")
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_matrix_reduced_plot_", strain_name, "_", sample, "_", experiment, "_", blast_option, ".svg"),
            plot = matrix_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )


EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample/$experiment: $file1 or $file2 or $filecontrol" >> "$log_file"
      echo "" >> "$log_file"
      fi
      done
    done
  done
done


# R processing for inter-chromosomal discordant read pairs global distribution
# Start timer for R processing

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
    for blast_option in option1 option2 option3 option4 option5 ; do
      file1="${strain}/${sample}_E1_${blast_option}_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv"
      file2="${strain}/${sample}_E2_${blast_option}_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv"
      file3="${strain}/${sample}_E3_${blast_option}_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" ]]; then
        echo "$(basename "$strain") ${sample}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant global distribution tsv files for $file1 , $file2 and $file3" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(extrafont)
          library(stringr)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          strain <- "${strain}"
          sample <- "${sample}"
          blast_option <- "${blast_option}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"


          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          file1 <- read_tsv(path_to_file_1, col_names = TRUE)
          file2 <- read_tsv(path_to_file_2, col_names = TRUE)
          file3 <- read_tsv(path_to_file_3, col_names = TRUE)

          discordant_reads_count <- bind_rows(file1, file2, file3)

          # Set genomic categories order
          genomic_categories_order <- c(
            "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
            "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
            "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
          )


          # Calculate average global inter-chromosomal discordant read pairs distribution 
          global_distribution <- discordant_reads_count %>% 
            group_by(strain, sample, strain_sample_comb,  Category_A, Category_B) %>%
            summarise(all_mean_global_percentage = mean(mean_global_percentage, na.rm = TRUE),
                      all_sd_global_percentage = sd(mean_global_percentage, na.rm = TRUE)) %>%
            # Apply genomic_categories_order
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                  Category_B = factor(Category_B, levels = genomic_categories_order)) %>%
            arrange(strain, sample, Category_A, Category_B) %>% 
            ungroup()

          heatmap <- ggplot(global_distribution, aes(x = Category_B, y = Category_A, fill =all_mean_global_percentage)) +
            geom_tile(color = "black", linewidth = 0.2) +
            scale_fill_gradientn(
              colors = c("white", "#e31a1c", "#8b2500"),
              values = scales::rescale(c(0, 2, 100)),
              na.value = "gray90",
              limits = c(0, 100),
              oob = scales::squish) +
            guides (fill = guide_colourbar(barwidth = 0.5, barheight = 10,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            labs(title = paste0("Inter_chromosomal discordant global distribution - ", strain_name, " - ", sample, " - ", blast_option),
                fill = "%") +
            scale_x_discrete(labels = c("ORF","Intergenic", "LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
            scale_y_discrete(limits = rev, labels = c("Telomere", "Centromere", "ARS", "snoRNA", "snRNA", "ncRNA", "rRNA", 
                                                      "tRNA", "Ty", "TEG", "LTR", "Intergenic", "ORF")) +
            theme_minimal(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") + 
            theme(axis.text.y=element_text(size=8)) +
            theme(axis.text.x=element_text(size=8, angle = 90, hjust = 1)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) + 
            theme(aspect.ratio = 1)
          
          
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_pairs_global_distribution_heatmap_", strain_name, "_", sample, "_", blast_option, ".svg"),
            plot = heatmap,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample/$blast_option: $file1 or $file2 or $file3" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done



# R processing for inter-chromosomal discordant read pairs category distribution


# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
    for blast_option in option1 option2 option3 option4 option5 ; do
      file1="${strain}/${sample}_E1_${blast_option}_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv"
      file2="${strain}/${sample}_E2_${blast_option}_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv"
      file3="${strain}/${sample}_E3_${blast_option}_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" ]]; then
        echo "$(basename "$strain") ${sample}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant category distribution tsv files for $file1 , $file2 and $file3" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(extrafont)
          library(stringr)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          strain <- "${strain}"
          sample <- "${sample}"
          blast_option <- "${blast_option}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"


          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          file1 <- read_tsv(path_to_file_1, col_names = TRUE)
          file2 <- read_tsv(path_to_file_2, col_names = TRUE)
          file3 <- read_tsv(path_to_file_3, col_names = TRUE)

          discordant_reads_count <- bind_rows(file1, file2, file3)

          # Set genomic categories order
          genomic_categories_order <- c(
            "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
            "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
            "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
          )


          # Calculate average category inter-chromosomal discordant read pairs distribution 
          category_distribution <- discordant_reads_count %>% 
            group_by(strain, sample, strain_sample_comb,  Category_A, Category_B) %>%
            summarise(all_mean_category_percentage = mean(mean_category_percentage, na.rm = TRUE),
                      all_sd_category_percentage = sd(mean_category_percentage, na.rm = TRUE)) %>%
            # Apply genomic_categories_order
            mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                  Category_B = factor(Category_B, levels = genomic_categories_order)) %>%
            arrange(strain, sample, Category_A, Category_B) %>% 
            ungroup()

          heatmap <- ggplot(category_distribution, aes(x = Category_B, y = Category_A, fill =all_mean_category_percentage)) +
            geom_tile(color = "black", linewidth = 0.2) +
            scale_fill_gradientn(
              colors = c("white", "#e31a1c", "#8b2500"),
              values = scales::rescale(c(0, 50, 100)),
              na.value = "gray90",
              limits = c(0, 100),
              oob = scales::squish) +
            guides (fill = guide_colourbar(barwidth = 0.5, barheight = 10,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            labs(title = paste0("Inter_chromosomal discordant category distribution - ", strain_name, " - ", sample, " - ", blast_option),
                fill = "%") +
            scale_x_discrete(labels = c("ORF","Intergenic", "LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
            scale_y_discrete(limits = rev, labels = c("Telomere", "Centromere", "ARS", "snoRNA", "snRNA", "ncRNA", "rRNA", 
                                                      "tRNA", "Ty", "TEG", "LTR", "Intergenic", "ORF")) +
            theme_minimal(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") + 
            theme(axis.text.y=element_text(size=8)) +
            theme(axis.text.x=element_text(size=8, angle = 90, hjust = 1)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) + 
            theme(aspect.ratio = 1)
          
          
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_pairs_category_distribution_heatmap_", strain_name, "_", sample, "_", blast_option, ".svg"),
            plot = heatmap,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )/60))
        echo "Total R processing completed in ${elapsed_time} minutes" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample: $file1 or $file2 or $file3" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done



# R processing for inter-chromosomal discordant read pairs matrix (merge all experiments)


# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
  for blast_option in option1 option2 option3 option4 option5 ; do
      file1="${strain}/${sample}_E1_${blast_option}_inter_discordant_pairs_unique_processed_valid.tsv"
      file2="${strain}/${sample}_E2_${blast_option}_inter_discordant_pairs_unique_processed_valid.tsv"
      file3="${strain}/${sample}_E3_${blast_option}_inter_discordant_pairs_unique_processed_valid.tsv"
      control1="${strain}/${sample}_E1_inter_discordant_pairs_unique_processed_control.tsv"
      control2="${strain}/${sample}_E2_inter_discordant_pairs_unique_processed_control.tsv"
      control3="${strain}/${sample}_E3_inter_discordant_pairs_unique_processed_control.tsv"
      if [[ -f "$file1" && -f "$file2" && -f "$file3" && -f "$control1" && -f "$control2" && -f "$control3" ]]; then
        echo "$(basename "$strain") ${sample}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant valid reads tsv files for $file1 , $file2 and $file3" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(extrafont)
          library(stringr)
          library(svglite)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          category_path <- "${CATEGORY_PATH}"
          strain <- "${strain}"
          sample <- "${sample}"
          blast_option <- "${blast_option}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"
          path_to_control_1 <- "${control1}"
          path_to_control_2 <- "${control2}"
          path_to_control_3 <- "${control3}"
          path_to_features_pairs_file <- file.path(category_path, "PMV_features_pairs.tsv")


          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

          log_step("Finding possible pairs...")

          # Inter-chromosomal discordant read pairs matrix
          df_features_pairs <- read_tsv(path_to_features_pairs_file, col_names = TRUE, show_col_types = FALSE)

          log_step("Loading valid reads...")
          # Load valid reads
          file1 <- read_tsv(path_to_file_1, col_names = TRUE)
          file2 <- read_tsv(path_to_file_2, col_names = TRUE)
          file3 <- read_tsv(path_to_file_3, col_names = TRUE)

          valid_pairs_df <- bind_rows(file1, file2, file3)

          log_step("Loading control reads...")
          # Load control reads
          control1 <- read_tsv(path_to_control_1, col_names = TRUE)
          control2 <- read_tsv(path_to_control_2, col_names = TRUE)
          control3 <- read_tsv(path_to_control_3, col_names = TRUE)

          control_df <- bind_rows(control1, control2, control3) %>% 
            filter(Category_A=="control_norm", Category_B=="control_norm")

          get_discordant_matrix <- function(valid_pairs_df_file, all_pairs_df, control_df_file) {
            posA_info <- all_pairs_df %>%
              select(Feature_name_A, Position_A = Position, Essential_A = Essential) %>%
              distinct()
            
            posB_info <- all_pairs_df %>%
              select(Feature_name_B, Position_B = Position, Essential_B = Essential) %>%
              distinct()
            
            valid_pairs_df_posA <- valid_pairs_df_file %>%
              left_join(posA_info, by = "Feature_name_A")
            
            valid_pairs_df_posAB <- valid_pairs_df_posA %>%
              left_join(posB_info, by = "Feature_name_B")
            
            pair_counts <- valid_pairs_df_posAB %>%
              group_by(strain, sample, Feature_name_A, Feature_name_B) %>%
              summarise(count = n(), .groups = "drop")
            
            complete_matrix <- left_join(valid_pairs_df_posAB, pair_counts,
                                        by = c("Feature_name_A", "Feature_name_B", "strain", "sample")) %>%
              distinct()
            
            count_total <- nrow(control_df_file)
            complete_matrix <- complete_matrix %>%
              mutate(count_norm = (count / count_total) * 100) %>% 
              select(!c(pair_group, pair_group_name, number, Feature_name_B_prev, Feature_name_B_next))
            
            return(complete_matrix)
          }

          log_step("Generating discordant matrix...")
          complete_matrix <- get_discordant_matrix(valid_pairs_df, df_features_pairs, control_df)
          complete_matrix_noORF_nointergenic <- complete_matrix %>% filter(Category_A != "ORF", Category_B != "ORF", Category_A != "intergenic", Category_B != "intergenic")

          log_step("Saving discordant matrix...")
          write_tsv(complete_matrix, file = paste0(strain, "/", sample, "_", blast_option, "_inter_discordant_pairs_unique_processed_valid_discordant_matrix_allexperiments.tsv"))
          write_tsv(complete_matrix_noORF_nointergenic, file = paste0(strain, "/", sample, "_", blast_option, "_inter_discordant_pairs_unique_processed_valid_discordant_matrix_noORF_nointergenic_allexperiments.tsv"))

          log_step("Plotting discordant matrix...")
          matrix_plot <-ggplot(complete_matrix, aes(y = Position_B, x = Position_A)) +
            #geom_hdr(xlim = c(0,14518), ylim = c(14518,0), method = "kde", fill = "brown4") + 
            geom_point(aes(colour = count_norm), alpha = 1, size = 0.8) +
            scale_colour_gradient2(low= "white", mid = "#4ae034", high = "#00641b",
                                  midpoint = 1,
                                  limits = c (0, 5),
                                  oob = scales::squish) + 
            theme_bw(base_family = "Arial") + 
            theme(panel.background = element_blank()) +
            theme(plot.background = element_rect(fill = "transparent", colour = NA))+
            theme(legend.position="right") +
            theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
            guides (colour = guide_colourbar(barwidth = 0.5, barheight = 5,
                                            frame.colour = "black", frame.linewidth = 0.25,
                                            ticks.colour = NA)) + 
            coord_cartesian(xlim = c(0,14518), ylim = c(14518, 0), expand=FALSE) +
            theme(aspect.ratio = 1) +
            scale_x_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487), position = "top") +
            scale_y_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            geom_hline(yintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_hline(yintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 144877),
                      linetype="dashed", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="dashed", color = "black", linewidth=0.05) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks = element_blank()) +
            geom_abline(intercept = 0, slope = 1, color = "black", linetype = "solid", linewidth = 0.05) +
            labs(
              title = paste0("Inter_chromosomal discordant matrix - ", strain_name, " - ", sample, "-", blast_option),
              colour = "Freq (%)")

          
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_matrix_plot_", strain_name, "_", sample, "_", blast_option, ".svg"),
            plot = matrix_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

          log_step("Plotting discordant matrix - no ORF no intergenic...")
          matrix_plot <-ggplot(complete_matrix_noORF_nointergenic, aes(y = Position_B, x = Position_A)) +
            #geom_hdr(xlim = c(0,14518), ylim = c(14518,0), method = "kde", fill = "brown4") + 
            geom_point(aes(colour = count_norm), alpha = 1, size = 2) +
            scale_colour_gradient2(low= "white", mid = "#4ae034", high = "#00641b",
                                  midpoint = 1,
                                  limits = c (0, 5),
                                  oob = scales::squish) + 
            theme_bw(base_family = "Arial") + 
            theme(panel.background = element_blank()) +
            theme(plot.background = element_rect(fill = "transparent", colour = NA))+
            theme(legend.position="right") +
            theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
            guides (colour = guide_colourbar(barwidth = 0.5, barheight = 5,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            coord_cartesian(xlim = c(13195,14518), ylim = c(14518, 13195), expand=FALSE) +
            theme(aspect.ratio = 1) +
            scale_x_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487), position = "top") +
            scale_y_continuous(breaks = c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                          6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            geom_hline(yintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_hline(yintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 144877),
                      linetype="dashed", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(6570, 13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="solid", color = "black", linewidth=0.05) +
            geom_vline(xintercept=c(118, 574, 755, 1591, 1914, 2053, 2636, 2957, 3198, 3596, 3944, 4522, 5027, 5462, 6059,
                                    6570, 6683, 7134, 7337, 8161, 8493, 8638, 9245, 9562, 9798, 10201, 10568, 11128, 11648, 12080, 12685,
                                    13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487),
                      linetype="dashed", color = "black", linewidth=0.05) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks = element_blank()) +
            geom_abline(intercept = 0, slope = 1, color = "black", linetype = "solid", linewidth = 0.05) +
            labs(
              title = paste0("Inter_chromosomal discordant matrix no ORF no intergenic - ", strain_name, " - ", sample, "-", blast_option),
              colour = "Freq (%)")
          
          #paste0(subdir, "/plot_", chr_name, "_75nt_", gsub("\\.tsv$", "", suffix), ".svg")
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_matrix_reduced_plot_", strain_name, "_", sample, "_", blast_option, ".svg"),
            plot = matrix_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )
          
          


EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total R processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample: $file1 or $file2 or $file3" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done



##### Calculate % of discordant reads in each Category_A and plot bar plot with SD
# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
    for blast_option in option1 option2 option3 option4 option5 ; do
        echo "Processing directory: ${strain}" >> "$log_file"
            root_dir="${strain}"
            #echo "$root_dir"
                echo "$(basename "$strain")" >> "$log_file"
                echo "" >> "$log_file"  # Adds a blank line
                echo "Processing discordant reads distribution by Category_A" >> "$log_file"
                start_time=$SECONDS
                # Export variables for R access
                export ROOT_DIR="$root_dir"
                export STRAIN="$strain"
                export BLAST_OPTION="$blast_option"
                #echo "ROOT_DIR: $ROOT_DIR"
                #echo "STRAIN: $STRAIN"
                Rscript - <<'EOF'
                # load libraries
                
                library(ggplot2)
                library(extrafont)
                library(svglite)
                library(purrr)
                library(stringr)
                library(readr)
                library(tidyverse, warn.conflicts = FALSE)
                library(tidyr, warn.conflicts = FALSE)
                library(dplyr, warn.conflicts = FALSE)
                options(dplyr.summarise.inform = FALSE)

                # Read environment variables
                root_dir <- Sys.getenv("ROOT_DIR")
                strain <- Sys.getenv("STRAIN")
                blast_option <- Sys.getenv("BLAST_OPTION")
                strain <- sub("/$", "", strain)  # Remove trailing slash
                strain_name <- basename(strain)

                print(paste("ROOT_DIR:", root_dir))

                log_step <- function(message) {
                    timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
                    message(sprintf("[%s] %s", timestamp, message))
                }

                # Define a function to process tsv files
                process_valid_counts_files <- function(file_path) {
                    # Extract filename and directory parts
                    file_base <- basename(file_path)
                    strain_name <- basename(dirname(file_path))  # directory name above the file

                    # 
                    parts <- str_split(file_base, "_", simplify = TRUE)

                    # Validate and extract parts safely
                    if (ncol(parts) >= 3) {
                    sample_name <- parts[1]
                    experiment_name <- parts[2]
                    } else {
                    warning(paste("Filename does not match expected format:", file_base))
                    return(NULL)
                    }

                    # Read file
                    temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)

                    # Skip if empty
                    if (nrow(temp_file) == 0) {
                    return(NULL)
                    }

                    # Prepare counts distribution dataframe
                    counts_distribution_file <- temp_file %>%
                        group_by(strain, sample, experiment, Category_A) %>%
                        summarise(total_count = sum(count), .groups = "drop_last") %>%
                        mutate(
                        group_total = sum(total_count),
                        percent = 100 * (total_count / group_total)
                        ) %>%
                        ungroup()

                    return(counts_distribution_file)
                }
                

                log_step("Finding valid_counts files...")
                # Get all tsv files recursively in root folder
                valid_counts_files <- list.files(
                    path = root_dir,
                    pattern = paste0(blast_option,".*valid_counts\\.tsv$"),
                    recursive = TRUE,
                    full.names = TRUE
                )
                valid_counts_files
                log_step("Processing valid_counts files...")
                valid_counts_processed_df <- purrr::map_dfr(valid_counts_files, process_valid_counts_files)

                genomic_categories_order <- c(
                    "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
                    "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
                    "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
                )

                samples_order <- c("TSG", "TLG", "TLR")

                valid_counts_processed_df_summary <- valid_counts_processed_df %>%
                    group_by(strain, sample, Category_A) %>%
                    summarise(
                    mean_percent = mean(percent, na.rm = TRUE),
                    sd_percent = sd(percent, na.rm = TRUE),
                    .groups = "drop"
                    )

                valid_counts_processsed_df_summary_ordered <- valid_counts_processed_df_summary %>% mutate(Category_A = factor(Category_A, levels = genomic_categories_order)) %>%
                    arrange(strain, sample, Category_A)

                #write_tsv(valid_counts_processed_df_summary, file.path(root_dir, paste0(strain_name, "_valid_counts_summary.tsv")))
                write_tsv(valid_counts_processsed_df_summary_ordered, file.path(root_dir, paste0(strain_name, "_", blast_option, "_valid_counts_summary_ordered.tsv")))
                #write_tsv(valid_counts_processed_df, file.path(root_dir, paste0(strain_name, "_valid_counts.tsv")))

                log_step("Plotting...")
                # Generate plots

                valid_counts_processsed_df_summary_ordered <-  valid_counts_processsed_df_summary_ordered %>% 
                    mutate(Category_A = factor(Category_A, levels = genomic_categories_order)) %>% 
                    mutate(sample = factor(sample, levels = samples_order))

                bar_plot <- ggplot(valid_counts_processsed_df_summary_ordered, aes(x = Category_A, y = mean_percent, fill = sample)) +
                    geom_col(position = "dodge2") +
                    geom_errorbar(aes(ymin = mean_percent - sd_percent, ymax = mean_percent + sd_percent), 
                                linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
                    scale_fill_manual(values=c("#252159", "#469CD7", "#8BE0FC")) +
                    theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                                    panel.background = element_blank(), 
                                                                    plot.background = element_rect(fill = "transparent", colour = NA)) +
                    theme(legend.position="right") +  
                    coord_cartesian(expand=FALSE) +
                    #coord_cartesian(ylim = c(0, 6), expand=FALSE) +
                    coord_cartesian(ylim = c(0, 100), expand=FALSE) +
                    theme(aspect.ratio = 0.75) + 
                    scale_x_discrete(name = expression("Category"), 
                                    labels = c("ORF", "Intergenic","LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
                    scale_y_continuous(name = expression("Percentage"),
                                    limits = c(0, 100),
                                    breaks = seq(0,100,10)) +
                    theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                        axis.title.y = element_text(vjust = 1, size = 25)) + 
                    theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 20, angle = 90), 
                        axis.text.y = element_text(vjust = 0, size = 20)) +
                    labs(
                        title = paste0("Discordant reads distribution - ", strain_name, " - ", blast_option)
                    )
                
                ggsave(
                    filename = paste0(strain,"/", "Discordant_reads_distribution_plot_", strain_name, "_", blast_option, ".svg"),
                    plot = bar_plot,
                    #width = 8,
                    #height = 3.6,
                    device = svglite,
                    bg = "transparent"
                )

                bar_plot_reduced <- ggplot(valid_counts_processsed_df_summary_ordered, aes(x = Category_A, y = mean_percent, fill = sample)) +
                    geom_col(position = "dodge2") +
                    geom_errorbar(aes(ymin = mean_percent - sd_percent, ymax = mean_percent + sd_percent), 
                                linewidth = 0.8, width = 0.5, colour = "gray10", position = position_dodge(width = 0.9)) +
                    scale_fill_manual(values=c("#252159", "#469CD7", "#8BE0FC")) +
                    theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                                    panel.background = element_blank(), 
                                                                    plot.background = element_rect(fill = "transparent", colour = NA)) +
                    theme(legend.position="right") +  
                    coord_cartesian(expand=FALSE) +
                    coord_cartesian(ylim = c(0, 6), expand=FALSE) +
                    #coord_cartesian(ylim = c(0, 100), expand=FALSE) +
                    theme(aspect.ratio = 0.75) + 
                    scale_x_discrete(name = expression("Category"), 
                                    labels = c("ORF", "Intergenic","LTR","TEG", "Ty", "tRNA", "rRNA", "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
                    scale_y_continuous(name = expression("Percentage"),
                                    limits = c(0, 100),
                                    breaks = seq(0,100,2)) +
                    theme(axis.title.x = element_text(hjust = 1, vjust = 0, size = 25), 
                        axis.title.y = element_text(vjust = 1, size = 25)) + 
                    theme(axis.text.x = element_text(hjust = 1, vjust = 0.5, size = 20, angle = 90), 
                        axis.text.y = element_text(vjust = 0, size = 20)) +
                    labs(
                        title = paste0("Discordant reads distribution - reduced - ", strain_name, " - ", blast_option)
                    )
                
                ggsave(
                    filename = paste0(strain,"/", "Discordant_reads_distribution_plot_reduced_", strain_name, "_", blast_option, ".svg"),
                    plot = bar_plot_reduced,
                    #width = 8,
                    #height = 3.6,
                    device = svglite,
                    bg = "transparent"
                )

          
          
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total R processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
    done
done

# R processing for inter-chromosomal discordant read pairs hotspots (all experiments)

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
    for blast_option in option1 option2 option3 option4 option5 ; do
      file1="${strain}/${sample}_E1_${blast_option}_inter_discordant_pairs_unique_processed_valid_discordant_matrix.tsv"
      file2="${strain}/${sample}_E2_${blast_option}_inter_discordant_pairs_unique_processed_valid_discordant_matrix.tsv"
      file3="${strain}/${sample}_E3_${blast_option}_inter_discordant_pairs_unique_processed_valid_discordant_matrix.tsv"
      freqs="${strain}/${sample}_${blast_option}_inter_discordant_pairs_unique_processed_valid_discordant_matrix_allexperiments.tsv"
      
      if [[ -f "$file1" && -f "$file2" && -f "$file3" && -f "$freqs" ]]; then
        echo "$(basename "$strain") ${sample}" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Processing inter-discordant valid reads tsv files for $file1 , $file2 and $file3" >> "$log_file"
        start_time=$SECONDS
        Rscript - <<EOF
          # load libraries

          library(readr)
          library(stringr)
          library(svglite)
          library(extrafont)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          # Suppress summarise info
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          category_path <- "${CATEGORY_PATH}"
          strain <- "${strain}"
          sample <- "${sample}"
          blast_option <- "${blast_option}"
          strain <- sub("/\$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)  # Get the name of the strain directory
          path_to_file_1 <- "${file1}"
          path_to_file_2 <- "${file2}"
          path_to_file_3 <- "${file3}"
          path_to_freqs <- "${freqs}"

          # Functions
          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }

        
          log_step("Loading matrix files...")
          # Load valid reads
          file1 <- read_tsv(path_to_file_1, col_names = TRUE,
            col_select = c("Feature_name_A", "Category_A", "Chromosome_A", "Essential_A",
                                                    "Feature_name_B", "Category_B", "Chromosome_B", "Essential_B",
                                                    "strain", "sample", "experiment", "Read_name_ID")) 

          file2 <- read_tsv(path_to_file_2, col_names = TRUE,
            col_select = c("Feature_name_A", "Category_A", "Chromosome_A", "Essential_A",
                                                    "Feature_name_B", "Category_B", "Chromosome_B", "Essential_B",
                                                    "strain", "sample", "experiment", "Read_name_ID")) 
                                          
          file3 <- read_tsv(path_to_file_3, col_names = TRUE,
            col_select = c("Feature_name_A", "Category_A", "Chromosome_A", "Essential_A",
                                                    "Feature_name_B", "Category_B", "Chromosome_B", "Essential_B",
                                                    "strain", "sample", "experiment", "Read_name_ID")) 

          
          log_step("Finding recombination hotspots...")
          hotspots_feature_A <-  merge(file1, file2, by= c("Feature_name_A")) %>% 
            merge(., file3, by= c("Feature_name_A")) %>% select(1, 2, 3, 4) %>% rename("Category_A" = !!names(.[2]),
                                                                                      "Chromosome_A" = !!names(.[3]),
                                                                                      "Essential_A" = !!names(.[4])) %>% 
            unique()

          

          log_step("Loading freq file...")
          # Load control reads
          freq_1_2_3 <- read_tsv(path_to_freqs, col_names = TRUE) %>% select("Feature_name_A", "Position_A", "count_norm") %>% 
            group_by(Feature_name_A) %>% 
            mutate(global_freq = sum(count_norm)) %>%  select(!c("count_norm")) %>%  unique()

          hotspots_freq <- merge(hotspots_feature_A, freq_1_2_3, by = c("Feature_name_A")) %>% unique()

          log_step("Saving hotspots dataframe...")
          write_tsv(hotspots_freq, file = paste0(strain, "/", sample, "_", blast_option,"_inter_discordant_pairs_unique_processed_valid_discordant_hotspots.tsv"))
          
          log_step("Plotting hotspots...")
          hotspots_plot <- ggplot(hotspots_freq, aes(y = Position_A, x = 0)) +
            #geom_segment(aes(xend = 0.95, yend = Position_A, color = global_freq), alpha = 1)+
            geom_tile(aes(color = global_freq), alpha = 1)+
            scale_color_gradientn(
              colors = c("white", "#e31a1c", "#8b2500"),
              #values = scales::rescale(c(0, 25, 50)),
              na.value = "gray90",
              #limits = c(0, 50),
              limits = c(0, 25),
              oob = scales::squish) +
            guides (color = guide_colourbar(barwidth = 0.5, barheight = 10,
                                          frame.colour = "black", frame.linewidth = 0.25,
                                          ticks.colour = NA)) + 
            labs(color = "%") +
            theme_classic(base_family = "Arial") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(panel.background = element_rect(fill = "white")) +
            theme(legend.position="right") +
            #coord_cartesian(ylim = c(13195,14518), expand=FALSE) +
            #coord_cartesian(ylim = c(1, 14519), xlim = c(0,1), expand=FALSE) +
            coord_cartesian(ylim = c(1, 14519), xlim = c(0,0.1), expand=FALSE) +
            theme(aspect.ratio = 20) +
            scale_y_continuous(breaks = c(1, 6570,
                                          13195, 13578, 13669, 13719, 13994, 14019, 14036, 14042, 14119, 14471, 14487)) +
            theme(axis.text.y=element_text(size=0)) +
            theme(axis.text.x=element_text(size=0)) +
            theme(axis.title.x = element_text(size=0)) +
            theme(axis.title.y = element_text(size=0)) +
            theme(axis.ticks.x = element_blank()) +
            labs(
              title = paste0("Hotspots - ", strain_name, " - ", sample, " - ", blast_option)
            )

          
          ggsave(
            filename = paste0(strain,"/", "Inter_chromosomal_discordant_hotspots_plot_", strain_name, "_", sample, "_", blast_option, ".svg"),
            plot = hotspots_plot,
            #width = 8,
            #height = 3.6,
            device = svglite,
            bg = "transparent"
          )

          

EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total R processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
      else
      echo "Missing files for $strain/$sample: $file1 or $file2 or $file3" >> "$log_file"
      echo "" >> "$log_file"
      fi
    done
  done
done


##### Hotspots distribution TSG, TLG and TLR

root_dir="${MYWD}"
#echo "$root_dir"
    echo "" >> "$log_file"  # Adds a blank line
    echo "Plotting hotspots distribution..." >> "$log_file"
    start_time=$SECONDS
    # Export variables for R access
    export ROOT_DIR="$root_dir"
    #echo "ROOT_DIR: $ROOT_DIR"
    #echo "STRAIN: $STRAIN"
    Rscript - <<'EOF'
    # load libraries
    
    library(ggplot2)
    library(svglite)
    library(purrr)
    library(stringr)
    library(readr)
    library(scales)
    library(extrafont)
    library(tidyverse, warn.conflicts = FALSE)
    library(tidyr, warn.conflicts = FALSE)
    library(dplyr, warn.conflicts = FALSE)
    options(dplyr.summarise.inform = FALSE)

    # Read environment variables
    root_dir <- Sys.getenv("ROOT_DIR")

    print(paste("ROOT_DIR:", root_dir))

    log_step <- function(message) {
        timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
        message(sprintf("[%s] %s", timestamp, message))
    }

    TSG_hotspots_files <- list.files(
      path = root_dir,
      pattern ="TSG_option1_inter_discordant_pairs_unique_processed_valid_discordant_hotspots\\.tsv$",
      recursive = TRUE,
      full.names = TRUE
    )


    TLG_hotspots_files <- list.files(
      path = root_dir,
      pattern ="TLG_option1_inter_discordant_pairs_unique_processed_valid_discordant_hotspots\\.tsv$",
      recursive = TRUE,
      full.names = TRUE
    )

    TLR_hotspots_files <- list.files(
      path = root_dir,
      pattern ="TLR_option1_inter_discordant_pairs_unique_processed_valid_discordant_hotspots\\.tsv$",
      recursive = TRUE,
      full.names = TRUE
    )

    all_TSG_valid_hotspots_files <- lapply(TSG_hotspots_files, function(f) {
      df <- read_tsv(f, show_col_types = FALSE)
      option <- str_extract(basename(f), "option[0-9]+")
      strain_name <- basename(dirname(f))
      df <- df %>% mutate(blast_option = option,
                          strain = strain_name,
                          sample = "TSG") %>% 
        filter(global_freq > 4)
      
      return(df)
    }) %>%
      bind_rows()  

    all_TLG_valid_hotspots_files <- lapply(TLG_hotspots_files, function(f) {
      df <- read_tsv(f, show_col_types = FALSE)
      option <- str_extract(basename(f), "option[0-9]+")
      strain_name <- basename(dirname(f))
      df <- df %>% mutate(blast_option = option,
                          strain = strain_name,
                          sample = "TLG") %>% 
        filter(global_freq > 4)
      
      return(df)
    }) %>%
      bind_rows()  


    all_TLR_valid_hotspots_files <- lapply(TLR_hotspots_files, function(f) {
      df <- read_tsv(f, show_col_types = FALSE)
      option <- str_extract(basename(f), "option[0-9]+")
      strain_name <- basename(dirname(f))
      df <- df %>% mutate(blast_option = option,
                          strain = strain_name,
                          sample = "TLR") %>% 
        filter(global_freq > 4)
      
      return(df)
    }) %>%
      bind_rows()  



    all_hotspots <- bind_rows(all_TSG_valid_hotspots_files,
                              all_TLG_valid_hotspots_files,
                              all_TLR_valid_hotspots_files)

    sample_order <- c("TSG", "TLG", "TLR")

    all_hotspots_ordered <- all_hotspots %>% mutate(sample = factor(sample, levels = sample_order)) 


    p <- ggplot(all_hotspots_ordered, aes(x = global_freq, color = sample, fill = sample)) +
      geom_histogram(alpha = 0.25, position = "identity") +
      coord_cartesian(xlim = c(0,70), ylim = c(0, 60), expand=FALSE) +
      theme_classic(base_family = "Arial") +
      theme(panel.grid = element_line(color = "black", linewidth = 0.1),
            panel.background = element_blank(),
            plot.background = element_rect(fill = "transparent", colour = NA)) +
      theme(panel.background = element_rect(fill = "white")) +
      theme(legend.position="right") +
      labs(title = paste0("Hotspots distribution")) +
      facet_wrap(sample~ strain, nrow = 3, ncol = 5) 

    ggsave(
            filename = paste0(root_dir,"/", "Inter_chromosomal_discordant_hotspots_distribution.svg"),
            plot = p,
            width = 12,
            height = 8,
            device = svglite,
            bg = "transparent"
          )



EOF

##### Radar plot TSG,TLG,TLR same plot
# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for blast_option in option1 option2 option3 option4 option5 ; do
  echo "Processing directory: ${strain}" >> "$log_file"
      root_dir="${strain}"
      wd_dir="${MYWD}"
      #echo "$root_dir"
        echo "$(basename "$strain")" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line
        echo "Calculating radar plot for $blast_option" >> "$log_file"
        start_time=$SECONDS
        # Export variables for R access
        export ROOT_DIR="$root_dir"
        export STRAIN="$strain"
        export WD_DIR="$wd_dir"
        export BLAST_OPTION="$blast_option"
        #echo "ROOT_DIR: $ROOT_DIR"
        #echo "STRAIN: $STRAIN"
        Rscript - <<'EOF'
        # load libraries

        library(ggplot2)
        library(svglite)
        library(extrafont)
        library(purrr)
        library(stringr)
        library(readr)
        library(fmsb)
        #library(ggbreak)
        library(tidyverse, warn.conflicts = FALSE)
        library(tidyr, warn.conflicts = FALSE)
        library(dplyr, warn.conflicts = FALSE)
        options(dplyr.summarise.inform = FALSE)

        # Read environment variables
        root_dir <- Sys.getenv("ROOT_DIR")
        wd_dir <- Sys.getenv("WD_DIR")
        blast_option <- Sys.getenv("BLAST_OPTION")
        strain <- Sys.getenv("STRAIN")
        strain <- sub("/$", "", strain)  # Remove trailing slash
        strain_name <- basename(strain)

      




        print(paste("ROOT_DIR:", root_dir))

        log_step <- function(message) {
          timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
          message(sprintf("[%s] %s", timestamp, message))
        }

        # Define a function to process tsv files
        process_valid_counts_files <- function(file_path) {
          # Extract filename and directory parts
          file_base <- basename(file_path)
          strain_name <- basename(dirname(file_path))  # directory name above the file
          
          # 
          parts <- str_split(file_base, "_", simplify = TRUE)
          
          # Validate and extract parts safely
          if (ncol(parts) >= 3) {
            sample_name <- parts[1]
            experiment_name <- parts[2]
          } else {
            warning(paste("Filename does not match expected format:", file_base))
            return(NULL)
          }
          
          # Read file
          temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
          
          # Skip if empty
          if (nrow(temp_file) == 0) {
            return(NULL)
          }
          
          # Prepare counts distribution dataframe
          counts_distribution_file <- temp_file %>%
            mutate(blast_option = blast_option) %>% 
            group_by(strain, sample, experiment, blast_option,  Category_A) %>%
            summarise(total_count = sum(count), .groups = "drop_last") %>%
            mutate(
              group_total = sum(total_count),
              percent = 100 * (total_count / group_total)
            ) %>%
            ungroup()
          
          return(counts_distribution_file)
        }


        log_step("Finding valid_counts files...")
        # Get all _inter_discordant_pairs_unique_processed_valid_counts files recursively in root folder
          
          valid_counts_files <- list.files(
            path = root_dir,
            pattern = paste0(blast_option,"_inter_discordant_pairs_unique_processed_valid_counts\\.tsv$"),
            recursive = TRUE,
            full.names = TRUE
          )
          
        
        log_step("Processing valid_counts files...")
        valid_counts_processed_df <- purrr::map_dfr(valid_counts_files, process_valid_counts_files)



        log_step("Finding ratio control file...")

        ratio_control_file <- read_tsv(file.path(wd_dir, "control_count_ratio.tsv"), col_names = TRUE)



        complete_valid_counts_df <- left_join(valid_counts_processed_df, ratio_control_file) %>%  
          mutate(total_count_norm = total_count / Ratio_vs_Wt)

        genomic_categories_order <- c(
          "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
          "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
          "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
        )

        sample_order <- c("TSG" , "TLG", "TLR")


        complete_valid_counts_summary_df <- complete_valid_counts_df %>% 
          group_by(strain, sample, Category_A) %>% 
          summarise(mean_total_count_norm = mean(total_count_norm)) %>% 
          mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                sample = factor(sample, levels = sample_order)) %>% 
          arrange(strain, sample, Category_A) %>% 
          ungroup()





        ######
        # Define the transformation function
        transform_y <- function(y) {
          ifelse(
            y <= 100,
            y * (0.75 / 100),                     # scale 0-100 to 0-0.75
            0.75 + ((y - 100) * (0.25 / (5000 - 100))) # scale 100-5000 to 0.25-1
          )
        }

        transform_y_50 <- function(y) {
          ifelse(
            y <= 50,
            y * (0.75 / 50),                     # scale 0-50 to 0-0.75
            0.75 + ((y - 50) * (0.25 / (5000 - 50))) # scale 50-5000 to 0.25-1
          )
        }





        # Add a transformed y column
        complete_valid_counts_summary_df$mean_total_count_norm_trans <- transform_y(complete_valid_counts_summary_df$mean_total_count_norm)
        complete_valid_counts_summary_df$mean_total_count_norm_trans_50 <- transform_y_50(complete_valid_counts_summary_df$mean_total_count_norm)
        

        complete_valid_counts_summary_df_radar <- complete_valid_counts_summary_df %>% 
          select(Category_A, mean_total_count_norm_trans, sample) %>% 
          pivot_wider(names_from = "Category_A", values_from = "mean_total_count_norm_trans") %>% 
          as.data.frame() %>% 
          select(!c("sample"))

        rownames(complete_valid_counts_summary_df_radar) <- c("TSG", "TLG", "TLR")

        complete_valid_counts_summary_df_radar_50 <- complete_valid_counts_summary_df %>% 
          select(Category_A, mean_total_count_norm_trans_50, sample) %>% 
          pivot_wider(names_from = "Category_A", values_from = "mean_total_count_norm_trans_50") %>% 
          as.data.frame() %>% 
          select(!c("sample"))

        rownames(complete_valid_counts_summary_df_radar_50) <- c("TSG", "TLG", "TLR")




        max_min <- data.frame(
          ORF = c(1, 0), intergenic = c(1, 0), long_terminal_repeat = c(1, 0),
          transposable_element_gene = c(1, 0), LTR_retrotransposon = c(1, 0), tRNA_gene = c(1, 0),
          rRNA_gene = c(1, 0), ncRNA_gene = c(1, 0), snRNA_gene = c(1, 0),
          snoRNA_gene = c(1, 0), ARS = c(1, 0), centromere = c(1, 0),
          telomere = c(1, 0)
        )



        rownames(max_min) <- c("Max", "Min")


        # Bind the variable ranges to the data
        df_radar <- rbind(max_min, complete_valid_counts_summary_df_radar)
        df_radar_50 <- rbind(max_min, complete_valid_counts_summary_df_radar_50)




        log_step("Plotting...")
        # Generate plots

        svglite::svglite(file = paste0(strain,"/", "Radar_plot_", strain_name, "_", blast_option, "_TSG_TLG_TLR", ".svg"), width = 8, height = 8)
        radarchartcirc(df_radar, axistype = 1,
                      # Customize the polygon
                      pcol = c("#252159", "#469CD7", "#8BE0FC"), 
                      seg = 4,
                      pty = 32, #32
                      #pfcol = FALSE, 
                      #pfcol = scales::alpha("black", 0.0), 
                      plwd = 1.5, plty = 1,
                      # Customize the grid
                      cglcol = "grey", cglty = 2, cglwd = 0.8,
                      # Customize the axis
                      axislabcol = "grey9", calcex = 0.6,
                      title = paste0("radar plot", "-", strain, "-", blast_option),
                      # Variable labels
                      vlcex = 0.7, vlabels = colnames(df_radar),
                      caxislabels = c(0, 33.3, 66.6, 100, 5000)
        )
        dev.off()

        svglite::svglite(file = paste0(strain,"/", "Radar_plot_", strain_name, "_", blast_option, "_50_TSG_TLG_TLR", ".svg"), width = 8, height = 8)
        radarchartcirc(df_radar_50, axistype = 1,
                      # Customize the polygon
                      pcol = c("#252159", "#469CD7", "#8BE0FC"), 
                      seg = 4,
                      pty = 32, #32
                      #pfcol = FALSE, 
                      #pfcol = scales::alpha("black", 0.0), 
                      plwd = 1.5, plty = 1,
                      # Customize the grid
                      cglcol = "grey", cglty = 2, cglwd = 0.8,
                      # Customize the axis
                      axislabcol = "grey9", calcex = 0.6,
                      title = paste0("radar plot_50", "-", strain, "-", blast_option),
                      # Variable labels
                      vlcex = 0.7, vlabels = colnames(df_radar_50),
                      caxislabels = c(0, 16.6, 33.3, 50, 5000)
        )
        dev.off()
        


        

EOF
  done
done


##### Radar plots TSG, TLG and TLR (read_number)
# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
        echo "Processing directory: ${strain}" >> "$log_file"
            root_dir="${strain}"
            wd_dir="${MYWD}"
            #echo "$root_dir"
                echo "$(basename "$strain")" >> "$log_file"
                echo "" >> "$log_file"  # Adds a blank line
                echo "Plotting radar plots TSG, TLG and TLR - all blast options..." >> "$log_file"
                start_time=$SECONDS
                # Export variables for R access
                export ROOT_DIR="$root_dir"
                export WD_DIR="$wd_dir"
                export STRAIN="$strain"
                export BLAST_OPTION="$blast_option"
                #echo "ROOT_DIR: $ROOT_DIR"
                #echo "STRAIN: $STRAIN"
                Rscript - <<'EOF'
                # load libraries
                
                library(ggplot2)
                library(svglite)
                library(purrr)
                library(stringr)
                library(readr)
                library(scales)
                library(fmsb)
                library(extrafont)
                library(tidyverse, warn.conflicts = FALSE)
                library(tidyr, warn.conflicts = FALSE)
                library(dplyr, warn.conflicts = FALSE)
                options(dplyr.summarise.inform = FALSE)

                ###
                 # Read environment variables
                root_dir <- Sys.getenv("ROOT_DIR")
                wd_dir <- Sys.getenv("WD_DIR")

                strain <- Sys.getenv("STRAIN")
                strain <- sub("/$", "", strain)  # Remove trailing slash
                strain_name <- basename(strain)


                print(paste("ROOT_DIR:", root_dir))

                log_step <- function(message) {
                  timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
                  message(sprintf("[%s] %s", timestamp, message))
                }

                # Define a function to process tsv files
                process_valid_counts_files <- function(file_path) {
                  # Extract filename and directory parts
                  file_base <- basename(file_path)
                  strain_name <- basename(dirname(file_path))
                  option <- str_extract(basename(file_path), "option[0-9]+")
                  # directory name above the file
                  
                  # 
                  parts <- str_split(file_base, "_", simplify = TRUE)
                  
                  # Validate and extract parts safely
                  if (ncol(parts) >= 3) {
                    sample_name <- parts[1]
                    experiment_name <- parts[2]
                  } else {
                    warning(paste("Filename does not match expected format:", file_base))
                    return(NULL)
                  }
                  
                  # Read file
                  temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
                  
                  # Skip if empty
                  if (nrow(temp_file) == 0) {
                    return(NULL)
                  }
                  
                  # Prepare counts distribution dataframe
                  counts_distribution_file <- temp_file %>%
                    mutate(blast_option = option) %>% 
                    group_by(strain, sample, experiment, blast_option,  Category_A) %>%
                    summarise(total_count = sum(count), .groups = "drop_last") %>%
                    mutate(
                      group_total = sum(total_count),
                      percent = 100 * (total_count / group_total)
                    ) %>%
                    ungroup()
                  
                  return(counts_distribution_file)
                }


                log_step("Finding valid_counts files...")
                # Get all coverage.tsv files recursively in root folder

                valid_counts_files <- list.files(
                  path = root_dir,
                  pattern = "_inter_discordant_pairs_unique_processed_valid_counts\\.tsv$",
                  recursive = TRUE,
                  full.names = TRUE
                )


                log_step("Processing valid_counts files...")
                valid_counts_processed_df <- purrr::map_dfr(valid_counts_files, process_valid_counts_files)



                log_step("Finding ratio control file...")

                ratio_control_file <- read_tsv(file.path(wd_dir, "control_count_ratio.tsv"), col_names = TRUE)



                complete_valid_counts_df <- left_join(valid_counts_processed_df, ratio_control_file) %>%  
                  filter(blast_option != "NA") %>% 
                  mutate(total_count_norm = total_count / Ratio_vs_Wt)

                genomic_categories_order <- c(
                  "ORF", "intergenic", "long_terminal_repeat", "transposable_element_gene",
                  "LTR_retrotransposon", "tRNA_gene", "rRNA_gene", "ncRNA_gene",
                  "snRNA_gene", "snoRNA_gene", "ARS", "centromere", "telomere"
                )

                option_order <- c("option1" , "option2", "option3", "option4", "option5")
                sample_order <- c("TSG" , "TLG", "TLR")


                complete_valid_counts_summary_df <- complete_valid_counts_df %>% 
                  group_by(strain, sample, blast_option, Category_A) %>% 
                  summarise(mean_total_count_norm = mean(total_count_norm)) %>% 
                  mutate(Category_A = factor(Category_A, levels = genomic_categories_order),
                        blast_option = factor(blast_option, levels = option_order),
                        sample = factor(sample, levels =sample_order)) %>% 
                  arrange(strain, sample, blast_option, Category_A) %>% 
                  ungroup()





                ######
                # Define the transformation function
                transform_y <- function(y) {
                  ifelse(
                    y <= 100,
                    y * (0.75 / 100),                     # scale 0-100 to 0-0.75
                    0.75 + ((y - 100) * (0.25 / (5000 - 100))) # scale 100-5000 to 0.25-1
                  )
                }

                transform_y_50 <- function(y) {
                  ifelse(
                    y <= 50,
                    y * (0.75 / 50),                     # scale 0-50 to 0-0.75
                    0.75 + ((y - 50) * (0.25 / (5000 - 50))) # scale 50-5000 to 0.25-1
                  )
                }





                # Add a transformed y column
                complete_valid_counts_summary_df$mean_total_count_norm_trans <- transform_y(complete_valid_counts_summary_df$mean_total_count_norm)
                complete_valid_counts_summary_df$mean_total_count_norm_trans_50 <- transform_y_50(complete_valid_counts_summary_df$mean_total_count_norm)


                complete_valid_counts_summary_TSG_df_radar <- complete_valid_counts_summary_df %>% 
                  filter(sample == "TSG") %>% 
                  select(Category_A, mean_total_count_norm_trans, blast_option) %>% 
                  pivot_wider(names_from = "Category_A", values_from = "mean_total_count_norm_trans") %>% 
                  as.data.frame() %>% 
                  select(!c("blast_option"))

                rownames(complete_valid_counts_summary_TSG_df_radar) <- c("option1", "option2", "option3", "option4", "option5")

                complete_valid_counts_summary_TSG_df_radar_50 <- complete_valid_counts_summary_df %>% 
                  filter(sample == "TSG") %>% 
                  select(Category_A, mean_total_count_norm_trans_50, blast_option) %>% 
                  pivot_wider(names_from = "Category_A", values_from = "mean_total_count_norm_trans_50") %>% 
                  as.data.frame() %>% 
                  select(!c("blast_option"))

                rownames(complete_valid_counts_summary_TSG_df_radar_50) <- c("option1", "option2", "option3", "option4", "option5")


                complete_valid_counts_summary_TLG_df_radar <- complete_valid_counts_summary_df %>% 
                  filter(sample == "TLG") %>% 
                  select(Category_A, mean_total_count_norm_trans, blast_option) %>% 
                  pivot_wider(names_from = "Category_A", values_from = "mean_total_count_norm_trans") %>% 
                  as.data.frame() %>% 
                  select(!c("blast_option"))

                rownames(complete_valid_counts_summary_TLG_df_radar) <- c("option1", "option2", "option3", "option4", "option5")

                complete_valid_counts_summary_TLG_df_radar_50 <- complete_valid_counts_summary_df %>% 
                  filter(sample == "TLG") %>% 
                  select(Category_A, mean_total_count_norm_trans_50, blast_option) %>% 
                  pivot_wider(names_from = "Category_A", values_from = "mean_total_count_norm_trans_50") %>% 
                  as.data.frame() %>% 
                  select(!c("blast_option"))

                rownames(complete_valid_counts_summary_TLG_df_radar_50) <- c("option1", "option2", "option3", "option4", "option5")


                complete_valid_counts_summary_TLR_df_radar <- complete_valid_counts_summary_df %>% 
                  filter(sample == "TLR") %>% 
                  select(Category_A, mean_total_count_norm_trans, blast_option) %>% 
                  pivot_wider(names_from = "Category_A", values_from = "mean_total_count_norm_trans") %>% 
                  as.data.frame() %>% 
                  select(!c("blast_option"))

                rownames(complete_valid_counts_summary_TLR_df_radar) <- c("option1", "option2", "option3", "option4", "option5")

                complete_valid_counts_summary_TLR_df_radar_50 <- complete_valid_counts_summary_df %>% 
                  filter(sample == "TLR") %>% 
                  select(Category_A, mean_total_count_norm_trans_50, blast_option) %>% 
                  pivot_wider(names_from = "Category_A", values_from = "mean_total_count_norm_trans_50") %>% 
                  as.data.frame() %>% 
                  select(!c("blast_option"))

                rownames(complete_valid_counts_summary_TLR_df_radar_50) <- c("option1", "option2", "option3", "option4", "option5")




                max_min <- data.frame(
                  ORF = c(1, 0), intergenic = c(1, 0), long_terminal_repeat = c(1, 0),
                  transposable_element_gene = c(1, 0), LTR_retrotransposon = c(1, 0), tRNA_gene = c(1, 0),
                  rRNA_gene = c(1, 0), ncRNA_gene = c(1, 0), snRNA_gene = c(1, 0),
                  snoRNA_gene = c(1, 0), ARS = c(1, 0), centromere = c(1, 0),
                  telomere = c(1, 0)
                )



                rownames(max_min) <- c("Max", "Min")


                # Bind the variable ranges to the data
                df_radar_TSG <- rbind(max_min, complete_valid_counts_summary_TSG_df_radar)
                df_radar_50_TSG <- rbind(max_min, complete_valid_counts_summary_TSG_df_radar_50)

                df_radar_TLG <- rbind(max_min, complete_valid_counts_summary_TLG_df_radar)
                df_radar_50_TLG <- rbind(max_min, complete_valid_counts_summary_TLG_df_radar_50)

                df_radar_TLR <- rbind(max_min, complete_valid_counts_summary_TLR_df_radar)
                df_radar_50_TLR <- rbind(max_min, complete_valid_counts_summary_TLR_df_radar_50)


                svglite::svglite(file = paste0(strain,"/", "Radar_plot_", strain_name, "_TSG", "_blast_options_read_number", ".svg"), width = 8, height = 8)
                radarchartcirc(df_radar_TSG, axistype = 1,
                              # Customize the polygon
                              pcol = c("darkgreen", "chartreuse3", "darkorange", "red", "darkred"), 
                              seg = 4,
                              pty = 32, #32
                              #pfcol = FALSE, 
                              #pfcol = scales::alpha("black", 0.0), 
                              plwd = 1.5, plty = 1,
                              # Customize the grid
                              cglcol = "grey", cglty = 2, cglwd = 0.8,
                              # Customize the axis
                              axislabcol = "grey9", calcex = 0.6,
                              title = paste0("radar plot_read_number", "-", strain, "-", "TSG"),
                              # Variable labels
                              vlcex = 0.7, vlabels = colnames(df_radar_TSG),
                              caxislabels = c(0, 33.3, 66.6, 100, 5000)
                )
                dev.off()

                svglite::svglite(file = paste0(strain,"/", "Radar_plot_50_", strain_name, "_TSG", "_blast_options_read_number", ".svg"), width = 8, height = 8)
                radarchartcirc(df_radar_50_TSG, axistype = 1,
                              # Customize the polygon
                              pcol = c("darkgreen", "chartreuse3", "darkorange", "red", "darkred"), 
                              seg = 4,
                              pty = 32, #32
                              #pfcol = FALSE, 
                              #pfcol = scales::alpha("black", 0.0), 
                              plwd = 1.5, plty = 1,
                              # Customize the grid
                              cglcol = "grey", cglty = 2, cglwd = 0.8,
                              # Customize the axis
                              axislabcol = "grey9", calcex = 0.6,
                              title = paste0("radar plot_read_number_50", "-", strain, "-", "TSG"),
                              # Variable labels
                              vlcex = 0.7, vlabels = colnames(df_radar_50_TSG),
                              caxislabels = c(0, 16.6, 33.3, 50, 5000)
                )
                dev.off()


                svglite::svglite(file = paste0(strain,"/", "Radar_plot_", strain_name, "_TLG", "_blast_options_read_number", ".svg"), width = 8, height = 8)
                radarchartcirc(df_radar_TLG, axistype = 1,
                              # Customize the polygon
                              pcol = c("darkgreen", "chartreuse3", "darkorange", "red", "darkred"), 
                              seg = 4,
                              pty = 32, #32
                              #pfcol = FALSE, 
                              #pfcol = scales::alpha("black", 0.0), 
                              plwd = 1.5, plty = 1,
                              # Customize the grid
                              cglcol = "grey", cglty = 2, cglwd = 0.8,
                              # Customize the axis
                              axislabcol = "grey9", calcex = 0.6,
                              title = paste0("radar plot_read_number", "-", strain, "-", "TLG"),
                              # Variable labels
                              vlcex = 0.7, vlabels = colnames(df_radar_TLG),
                              caxislabels = c(0, 33.3, 66.6, 100, 5000)
                )
                dev.off()

                svglite::svglite(file = paste0(strain,"/", "Radar_plot_50_", strain_name, "_TLG", "_blast_options_read_number", ".svg"), width = 8, height = 8)
                radarchartcirc(df_radar_50_TLG, axistype = 1,
                              # Customize the polygon
                              pcol = c("darkgreen", "chartreuse3", "darkorange", "red", "darkred"), 
                              seg = 4,
                              pty = 32, #32
                              #pfcol = FALSE, 
                              #pfcol = scales::alpha("black", 0.0), 
                              plwd = 1.5, plty = 1,
                              # Customize the grid
                              cglcol = "grey", cglty = 2, cglwd = 0.8,
                              # Customize the axis
                              axislabcol = "grey9", calcex = 0.6,
                              title = paste0("radar plot_read_number_50", "-", strain, "-", "TLG"),
                              # Variable labels
                              vlcex = 0.7, vlabels = colnames(df_radar_50_TLG),
                              caxislabels = c(0, 16.6, 33.3, 50, 5000)
                )
                dev.off()


                svglite::svglite(file = paste0(strain,"/", "Radar_plot_", strain_name, "_TLR", "_blast_options_read_number", ".svg"), width = 8, height = 8)
                radarchartcirc(df_radar_TLR, axistype = 1,
                              # Customize the polygon
                              pcol = c("darkgreen", "chartreuse3", "darkorange", "red", "darkred"), 
                              seg = 4,
                              pty = 32, #32
                              #pfcol = FALSE, 
                              #pfcol = scales::alpha("black", 0.0), 
                              plwd = 1.5, plty = 1,
                              # Customize the grid
                              cglcol = "grey", cglty = 2, cglwd = 0.8,
                              # Customize the axis
                              axislabcol = "grey9", calcex = 0.6,
                              title = paste0("radar plot_read_number", "-", strain, "-", "TLR"),
                              # Variable labels
                              vlcex = 0.7, vlabels = colnames(df_radar_TLR),
                              caxislabels = c(0, 33.3, 66.6, 100, 5000)
                )
                dev.off()

                svglite::svglite(file = paste0(strain,"/", "Radar_plot_50_", strain_name, "_TLR", "_blast_options_read_number", ".svg"), width = 8, height = 8)
                radarchartcirc(df_radar_50_TLR, axistype = 1,
                              # Customize the polygon
                              pcol = c("darkgreen", "chartreuse3", "darkorange", "red", "darkred"), 
                              seg = 4,
                              pty = 32, #32
                              #pfcol = FALSE, 
                              #pfcol = scales::alpha("black", 0.0), 
                              plwd = 1.5, plty = 1,
                              # Customize the grid
                              cglcol = "grey", cglty = 2, cglwd = 0.8,
                              # Customize the axis
                              axislabcol = "grey9", calcex = 0.6,
                              title = paste0("radar plot_read_number_50", "-", strain, "-", "TLR"),
                              # Variable labels
                              vlcex = 0.7, vlabels = colnames(df_radar_50_TLR),
                              caxislabels = c(0, 16.6, 33.3, 50, 5000)
                )
                dev.off()

                         
          
EOF
      # Calculate elapsed time
        elapsed_time=$((( SECONDS - start_time )))
        echo "Total R processing completed in ${elapsed_time} seconds" >> "$log_file"
        echo "" >> "$log_file"  # Adds a blank line 
    
done

# Discordant networks

# Loop inside each subdirectory of MYWD
for strain in "${MYWD}"*/; do
  for sample in TSG TLG TLR; do
    echo "Processing network for sample: ${sample}" >> "$log_file"
        root_dir="${strain}"
        export ROOT_DIR="$root_dir"
        export SAMPLE="$sample"
        export STRAIN="$strain"
        #echo "$root_dir"
          echo "" >> "$log_file"  # Adds a blank line
          echo "Calculating discordant reads network" >> "$log_file"
          start_time=$SECONDS
          Rscript - <<'EOF'
          # load libraries

          library(ggplot2)
          library(svglite)
          library(purrr)
          library(stringr)
          library(readr)
          library(tidyverse, warn.conflicts = FALSE)
          library(tidyr, warn.conflicts = FALSE)
          library(dplyr, warn.conflicts = FALSE)
          options(dplyr.summarise.inform = FALSE)

          # Variables from Bash
          #sample <- "${sample}"
          sample <- Sys.getenv("SAMPLE")

          strain <- Sys.getenv("STRAIN")
          strain <- sub("/$", "", strain)  # Remove trailing slash
          strain_name <- basename(strain)


          root_dir <- Sys.getenv("ROOT_DIR")

          log_step <- function(message) {
            timestamp <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
            message(sprintf("[%s] %s", timestamp, message))
          }


          # Define a function to process tsv files
          process_hotspots_files <- function(file_path) {
            # Extract filename and directory parts
            file_base <- basename(file_path)
            strain_name <- basename(dirname(file_path))  # directory name above the file
            
            # Expect filename like T4_E07_MAT_filtered.tsv
            parts <- str_split(file_base, "_", simplify = TRUE)
            
            # Validate and extract parts safely
            if (ncol(parts) >= 3) {
              sample_name <- parts[1]
              option <- parts[2]
            } 
            else {
              warning(paste("Filename does not match expected format:", file_base))
              return(NULL)
            }
            
            # Read file
            temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
            
            # Skip if empty
            if (nrow(temp_file) == 0) {
              return(NULL)
            }
            
            
            # Process file
            hotspots_file <- temp_file %>% 
              mutate(strain = strain_name, 
                    sample = sample_name,
                    blast_option = option) %>% 
              filter(global_freq > 6)
            
            return(hotspots_file)
          }



          # Define a function to process tsv files
          process_matrix_files <- function(file_path) {
            # Extract filename and directory parts
            file_base <- basename(file_path)
            strain_name <- basename(dirname(file_path))  # directory name above the file
            
            # Expect filename like T4_E07_MAT_filtered.tsv
            parts <- str_split(file_base, "_", simplify = TRUE)
            
            # Validate and extract parts safely
            if (ncol(parts) >= 3) {
              sample_name <- parts[1]
              option <- parts[2]
            } 
            else {
              warning(paste("Filename does not match expected format:", file_base))
              return(NULL)
            }
            
            # Read file
            temp_file <- read_tsv(file_path, col_names = TRUE, show_col_types = FALSE)
            
            # Skip if empty
            if (nrow(temp_file) == 0) {
              return(NULL)
            }
            
            
            # Process file
            matrix_file <- temp_file %>% 
              mutate(strain = strain_name, 
                    sample = sample_name,
                    blast_option = option) %>% 
              select(Read_name_ID, 
                    Chromosome_A, Feature_name_A, Category_A, Position_A, Essential_A,
                    Chromosome_B, Feature_name_B, Category_B, Position_B, Essential_B,
                    strain, sample, blast_option)
            
            return(matrix_file)
          }


          # Get all inter_discordant_pairs_unique_processed_valid_discordant_matrix_allexperiments.tsv files recursively in root folder
          matrix_files <- list.files(
            path = root_dir,
            pattern = paste0(sample,".*option1_inter_discordant_pairs_unique_processed_valid_discordant_matrix_allexperiments\\.tsv$"),
            #pattern = "inter_discordant_pairs_unique_processed_valid_discordant_matrix_allexperiments\\.tsv$",
            recursive = TRUE,
            full.names = TRUE
          )

          log_step("Processing matrix files...")
          matrix_processed_df <- purrr::map_dfr(matrix_files, process_matrix_files) 




          log_step("Finding hotspots files...")

          # Get all hotspots.tsv files recursively in root folder
          hotspots_files <- list.files(
            path = root_dir,
            pattern = paste0(sample,".*option1_inter_discordant_pairs_unique_processed_valid_discordant_hotspots\\.tsv$"),
            #pattern = "inter_discordant_pairs_unique_processed_valid_discordant_hotspots\\.tsv$",
            recursive = TRUE,
            full.names = TRUE
          )

          log_step("Processing hotspots files...")
          hotspots_processed_df <- purrr::map_dfr(hotspots_files, process_hotspots_files) 

          write_tsv(hotspots_processed_df, file.path(root_dir, paste0(strain_name, "_", sample, "_hotspots_processed_df.tsv")))

          hotspots_counts <- hotspots_processed_df %>%
            count(Feature_name_A, name = "n_occurrences")

          #####

          # Select hotspots from full matrix

          hotspots_matrix <- left_join(hotspots_processed_df, matrix_processed_df, by = c("strain", "sample", "blast_option", "Feature_name_A")) %>% 
            select(Feature_name_A, Category_A.x, Chromosome_A.x, Essential_A.x, Position_A.x,
                  Feature_name_B, Category_B, Chromosome_B, Essential_B, Position_B,
                  strain, sample, blast_option, global_freq) %>% 
            rename("Category_A" = !!names(.[2]), "Chromosome_A" = !!names(.[3]),
                  "Essential_A" = !!names(.[4]), "Position_A" = !!names(.[5])) %>% 
            unique() %>% 
            mutate(id = 1:n()) 

          write_tsv(hotspots_matrix, file.path(root_dir, paste0(strain_name, "_", sample, "_hotspots_matrix.tsv")))



          hotspots_matrix_A <- hotspots_matrix %>% 
            select(Feature_name_A, Category_A, strain, sample, id)

          hotspots_matrix_B <- hotspots_matrix %>% 
            select(Feature_name_B, Category_B, strain, sample, id) %>% 
            rename(Category_A = Category_B)

          hotspots_matrix_size <- hotspots_matrix %>% 
            group_by(Feature_name_A) %>% 
            count(Feature_name_A, name = "n_occurrences") %>% 
            ungroup()


          hotspots_matrix_size_B <- hotspots_matrix %>% 
            group_by(Feature_name_B) %>% 
            count(Feature_name_B, name = "n_occurrences") %>% 
            ungroup()

          hotspots_matrix_size_B_no_A <- hotspots_matrix_size_B %>% 
            rename(Feature_name_A = Feature_name_B) %>% 
            anti_join(., hotspots_matrix_size , by = "Feature_name_A") %>% 
            rename(Feature_name_B = Feature_name_A)

          hotspots_matrix_A <- left_join(hotspots_matrix_A, hotspots_matrix_size) 

          hotspots_matrix_B <- left_join(hotspots_matrix_B, hotspots_matrix_size_B_no_A) %>% 
            rename(Feature_name_A = Feature_name_B)

          hotspots_matrix_A_B <- bind_rows(hotspots_matrix_A, hotspots_matrix_B)


          edges <- hotspots_matrix %>%  select(Feature_name_A, Feature_name_B, Category_A, strain, id) %>% 
            rename("Source" = !!names(.[1]), "Target" = !!names(.[2])) %>% 
            as.data.frame()


          ########## NETWORK

          library(tidyverse)
          library(igraph)
          library(ggraph)


          node_sizes <- hotspots_matrix_size %>% 
            rename("name" = !!names(.[1]), "Size" = !!names(.[2]))


          g <- graph_from_data_frame(edges, directed = FALSE)


          # Derive node data
          nodes <- data.frame(name = V(g)$name) %>%
            mutate(order = 1:n()) %>%
            left_join(hotspots_matrix_A_B %>% select(Feature_name_A, Category_A, strain, id, n_occurrences),
                      by = c("name" = "Feature_name_A")) %>% 
            arrange(order)

          nodes_def <- nodes %>% group_by(name) %>%
            slice(1) %>%
            ungroup() %>% 
            arrange(order)





          # Attach node attributes to igraph
          V(g)$Category_A <- nodes_def$Category_A
          V(g)$Size <- nodes_def$n_occurrences
          V(g)$strain <- nodes_def$strain
          #V(g)$name

          custom_palette <- c(
            "1_Wt" = "#00AFBB",   
            "2_exo1d" = "#293781",  
            "3_sgs1d" = "#AE2D2C",   
            "4_srs2d" = "#439645", 
            "5_rad51d" = "#5D297D",
            "1_Wt_2_exo1d" = "#15739e",
            "1_Wt_3_sgs1d" = "#576e74",
            "1_Wt_4_srs2d" = "#22a380",
            "1_Wt_5_rad51d" = "#2f6c9c",
            "2_exo1d_3_sgs1d " = "#6c3257",
            "2_exo1d_4_srs2d" = "#366763",
            "2_exo1d_5_rad51d" = "#43307f",
            "3_sgs1d_4_srs2d" = "#796239",
            "3_sgs1d_5_rad51d" = "#862b55",
            "4_srs2d_5_rad51d" = "#506061",
            "1_Wt_2_exo1d_3_sgs1d" = "#485c78",
            "1_Wt_2_exo1d_4_srs2d" = "#247f80",
            "1_Wt_2_exo1d_5_rad51d" = "#2d5a93",
            "1_Wt_3_sgs1d_4_srs2d" = "#507b64",
            "1_Wt_3_sgs1d_5_rad51d" = "#595777",
            "1_Wt_4_srs2d_5_rad51d" = "#357a7f",
            "2_exo1d_3_sgs1d_4_srs2d" = "#5e5351",
            "2_exo1d_3_sgs1d_5_rad51d" = "#672f63",
            "2_exo1d_4_srs2d_5_rad51d" = "#43526c",
            "3_sgs1d_4_srs2d_5_rad51d" = "#6f4f4f",
            "1_Wt_2_exo1d_3_sgs1d_4_srs2d" = "#476a6b",
            "1_Wt_2_exo1d_3_sgs1d_5_rad51d" = "#4d4f79",
            "1_Wt_2_exo1d_4_srs2d_5_rad51d" = "#326980",
            "1_Wt_3_sgs1d_4_srs2d_5_rad51d" = "#54676a",
            "2_exo1d_3_sgs1d_4_srs2d_5_rad51d" = "#5e495c",
            "1_Wt_2_exo1d_3_sgs1d_4_srs2d_5_rad51d" = "#4b5d6f"
              
          )

          custom_palette_categories = c("ORF" = "#4F71BE",
                                        "intergenic" = "#FF051D",
                                        "long_terminal_repeat" = "#DE8344",
                                        "transposable_element_gene" = "#A5A5A5",
                                        "LTR_retrotransposon" = "#F5C242",
                                        "tRNA_gene" = "#6A99D0",
                                        "rRNA_gene" = "#7EAB55",
                                        "ncRNA_gene" = "#2D4374",
                                        "snRNA_gene" = "#934D20",
                                        "snoRNA_gene" = "#636363",
                                        "ARS" = "#937424",
                                        "centromere" = "#355D8D",
                                        "telomere" = "#4B6733")

          svglite::svglite(file = paste0(root_dir, "/", strain_name, "_", sample, "_Network_plot", ".svg"), width = 13, height = 13)
          ggraph(g, layout = "fr") +  # "fr" = Fruchterman-Reingold layout
            geom_edge_link(alpha = 0.2, color = "black") +
            geom_node_point(aes(size = Size, color = Category_A), alpha = 1) +
            scale_color_manual(values = custom_palette_categories) +
            #geom_node_text(aes(label = name), repel = TRUE, size = 2) +
            geom_node_text(
              aes(label = ifelse(Size > 10 | name %in% hotspots_counts$Feature_name_A, name, "")),
              repel = TRUE,
              size = 3
            ) + 
            scale_size_continuous(range = c(3, 15)) +
            theme_void() +
            theme(legend.position = "none") +
            ggtitle(paste0(strain_name, " - ", sample, " - Network"))

          dev.off()



          hotspots_matrix_summary <- hotspots_matrix %>% 
            group_by(sample) %>% 
            mutate(total_sample = n()) %>% 
            ungroup() %>% 
            group_by(sample, strain) %>% 
            mutate(total_sample_strain = n()) %>% 
            ungroup() %>% 
            group_by(sample, Category_A) %>% 
            mutate(total_sample_category_A = n()) %>%
            ungroup() %>% 
            group_by(sample, Category_A, strain) %>% 
            mutate(total_sample_category_A_strain = n()) %>%
            ungroup() %>% 
            group_by(sample, Category_A, Category_B) %>% 
            mutate(total_sample_category_A_Category_B = n()) %>%
            ungroup() %>% 
            group_by(sample, Category_A, Category_B, strain) %>% 
            mutate(total_sample_category_A_Category_B_strain = n()) %>%
            ungroup() %>% 
            mutate(freq_category_A_100  = 100*(total_sample_category_A_Category_B_strain/total_sample_category_A),
                    freq_sample_100  = 100*(total_sample_category_A_Category_B_strain/total_sample),
                    freq_sample_100_soloA  = 100*(total_sample_category_A_strain/total_sample)) %>% 
            select(Category_A, Category_B,
                    total_sample,
                    total_sample_strain, 
                    total_sample_category_A,
                    total_sample_category_A_strain,
                    total_sample_category_A_Category_B,
                    total_sample_category_A_Category_B_strain,
                    freq_category_A_100, freq_sample_100,
                    freq_sample_100_soloA,
                    strain, sample) %>% 
            unique()


            hotspots_matrix_summary_positions_strain_sep <- hotspots_matrix_summary %>% 
            mutate(position_x = ifelse(Category_B == "ORF", 1,
                                        ifelse(Category_B == "intergenic", 2,
                                                ifelse(Category_B == "long_terminal_repeat", 3,
                                                    ifelse(Category_B == "transposable_element_gene", 4,
                                                            ifelse(Category_B == "LTR_retrotransposon", 5,
                                                                    ifelse(Category_B == "tRNA_gene", 6,
                                                                            ifelse(Category_B == "rRNA_gene", 7,
                                                                                ifelse(Category_B == "ncRNA_gene", 8,
                                                                                        ifelse(Category_B == "snRNA_gene", 9,
                                                                                                ifelse(Category_B == "snoRNA_gene", 10,
                                                                                                        ifelse(Category_B == "ARS", 11,
                                                                                                            ifelse(Category_B == "centromere", 12,
                                                                                                                    ifelse(Category_B == "telomere", 13,"_")))))))))))))) %>% 
            mutate(position_y = ifelse(Category_A == "ORF", 13,
                                        ifelse(Category_A == "intergenic", 12,
                                                ifelse(Category_A == "long_terminal_repeat", 11,
                                                    ifelse(Category_A == "transposable_element_gene", 10,
                                                            ifelse(Category_A == "LTR_retrotransposon", 9,
                                                                    ifelse(Category_A == "tRNA_gene", 8,
                                                                            ifelse(Category_A == "rRNA_gene", 7,
                                                                                ifelse(Category_A == "ncRNA_gene", 6,
                                                                                        ifelse(Category_A == "snRNA_gene", 5,
                                                                                                ifelse(Category_A == "snoRNA_gene", 4,
                                                                                                        ifelse(Category_A == "ARS", 3,
                                                                                                            ifelse(Category_A == "centromere", 2,
                                                                                                                    ifelse(Category_A == "telomere", 1,"_"))))))))))))))


            hotspots_matrix_summary_positions_strain_sep$position_x <- as.numeric(hotspots_matrix_summary_positions_strain_sep$position_x)
            hotspots_matrix_summary_positions_strain_sep$position_y <- as.numeric(hotspots_matrix_summary_positions_strain_sep$position_y)

            write_tsv(hotspots_matrix_summary_positions_strain_sep, file.path(root_dir, paste0(strain_name, "_", sample, "_Network_summary_positions_strain_sep.tsv")))

            hotspots_matrix_summary_positions_strain_sep_complete <- hotspots_matrix_summary_positions_strain_sep %>%
                complete(
                    strain,
                    sample,
                    position_x = 1:13,
                    position_y = 1:13,
                    fill = list(freq_sample_100 = NA)
                )

            p <- ggplot(hotspots_matrix_summary_positions_strain_sep_complete, aes(y = position_y, x = position_x)) +
            geom_tile(aes(fill = freq_sample_100), size = 1)+
            scale_fill_gradient2(low = "white",
                                mid = "#e31a1c",
                                high="blue2",
                                midpoint = 25,
                                na.value = "white",
                                limits = c(0, 50),
                                oob = scales::squish) +
            guides (fill = guide_colourbar(barwidth = 0.5, barheight = 10,
                                            frame.colour = "black", frame.linewidth = 0.25,
                                            ticks.colour = NA)) + 
            labs(fill = "%") +
            theme_classic(base_family = "Helvetica") + theme(panel.grid = element_line(color = "black", linewidth = 0.1),
                                                            panel.background = element_blank(), 
                                                            plot.background = element_rect(fill = "transparent", colour = NA)) +
            theme(legend.position="right") +
            coord_cartesian(expand = FALSE) +
            geom_hline(yintercept = 0.5 + 0:13, colour = "gray7", size = 0.15) +
            geom_vline(xintercept = 0.5 + 0:13, colour = "gray7", size = 0.15) +
            scale_x_continuous(breaks = seq(1,13,1),
                                labels = c("ORF","Intergenic", "LTR","TEG", "Ty", "tRNA", "rRNA", 
                                            "ncRNA", "snRNA", "snoRNA", "ARS", "Centromere", "Telomere")) +
            scale_y_continuous(breaks = seq(1,13,1),
                                labels = c("Telomere", "Centromere", "ARS", "snoRNA", "snRNA", "ncRNA", "rRNA", 
                                            "tRNA", "Ty", "TEG", "LTR", "Intergenic", "ORF")) +
            theme(aspect.ratio = 1) +
            theme(axis.text.x=element_text(size=8, angle = 90, hjust = 1)) +
            theme(axis.title.x = element_text(size = 0)) +
            theme(axis.title.y = element_text(size = 0)) +
            ggtitle("Network quantification") +
            theme(axis.ticks.x = element_line()) +
            facet_grid(strain ~ sample) 

            ggsave(
            filename = paste0(root_dir, "/", strain_name, "_", sample, "_Network_quantification_plot", ".svg"),
            plot = p,
            #width = 8,
            #height = 3,
            device = svglite,
            bg = "transparent"
            )

EOF
  done
done

########
# Calculate total elapsed time
elapsed_time_total=$((( SECONDS - start_time_total_R_valid )/60))
echo "================================" >> "$log_file"
echo "" >> "$log_file"
echo "TOTAL VALID INTER-CHROMOSOMAL DISCORDANT READ PAIRS R PROCESSING COMPLETED IN ${elapsed_time_total} MINUTES" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line   

##### MODULE WHOLE GENOME ANALYSIS - DATA ORGANIZATION #####
# Move data into subfolders
for subdir in "$MYWD"*/; do
  mkdir -p "${subdir}/Discordant_global_analysis" 
  mkdir -p "${subdir}/Discordant_global_analysis/Global_Data_75nt" "${subdir}/Discordant_global_analysis/Global_Plots_75nt" 
  
  
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_blast_center.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_blast_next.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_blast_prev.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_control.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique.sam "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_blast_center_combined_results.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_blast_next_combined_results.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_blast_prev_combined_results.tsv "${subdir}/Discordant_alignments/SAM_75nt/" 2> /dev/null


  mv "${subdir}"/*_recombination_df.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_recombination_summary.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_valid_counts_summary_ordered.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_concordant_pairs_unique_row_count.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_valid_category_distribution.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_valid_counts.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_valid_discordant_mat*.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_valid_error_rate.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_valid_global_distribution.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed_valid.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique_processed.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_inter_discordant_pairs_unique.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_category_A_valid_counts_summary_df.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_hotspots.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  
  mv "${subdir}"/Discordant_reads_distribution_plot_*.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/Inter_chromosomal_discordant_hotspots_*.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/Inter_chromosomal_discordant_matrix_*.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/Inter_chromosomal_discordant_pairs_*.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/Recombination_rate_plot_*.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/Recombination_rate_ratio_plot_*.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/Category_A_read_number_*.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/Radar_plot_*.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null

  mv "${subdir}"/*_Network_plot.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/*_Network_quantification_plot.svg  "${subdir}/Discordant_global_analysis/Global_Plots_75nt/" 2> /dev/null
  mv "${subdir}"/*_hotspots_matrix.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_hotspots_processed_df.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  mv "${subdir}"/*_Network_summary_positions_strain_sep.tsv  "${subdir}/Discordant_global_analysis/Global_Data_75nt/" 2> /dev/null
  

done


##### MODULE WHOLE GENOME ANALYSIS - END #####


# Calculate full script total elapsed time
elapsed_time_total_2=$((( SECONDS - start_time_total_script_2 )/3600))
echo "================================" >> "$log_file"
echo "" >> "$log_file"
echo "DISCORDANT ANALYSIS - COMPLETED IN ${elapsed_time_total_2} HOURS" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line

elapsed_time_total=$((( SECONDS - start_time_total_script )/3600))
echo "================================" >> "$log_file"
echo "" >> "$log_file"
echo "SCRIPT COMPLETED IN ${elapsed_time_total} HOURS" >> "$log_file"
echo "" >> "$log_file"  # Adds a blank line


##### REPORT GENERATION #####

# Generate report file
current_time=$(date "+%d-%m-%Y %H:%M:%S")
echo "Generating report file at: \"$current_time\"" 

# Paths
RMD_FILE="Di-GRAPH_report.Rmd"
R_SCRIPT="generate_report.R"

# Copy Rmd to folder2
cp "${MYREPORT}/${RMD_FILE}" "${MYWD}/"

# Move into folder2
cd "${MYWD}"

# Run R script
Rscript "${MYREPORT}/${R_SCRIPT}"

# Remove copied Rmd after successful render
rm "${RMD_FILE}"